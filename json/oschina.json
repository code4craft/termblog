{"contents":[{"contents":[{"contents":"<h2>CodeCraft</h2><div class=\"BlogContent\">\n <p> &nbsp;&nbsp;&nbsp;&nbsp;一直以来，都是发自内心的喜欢编程这一行。很赞同《人月神话》里的一句话，编程的快乐之一，来自于自己开发对别人有用的东西。我想，大多数程序员，平生最大的理想，就是能够做出改变世界的东西。 </p> \n <p> &nbsp;&nbsp;&nbsp;前几天看了《代码奔腾》，Netscape是Javascript这一web统治语言的缔造者，也制定了SSL标准和一些HTTP的事实规范。这些在如今的互联网无处不在，他们毫无疑问的改变了世界。网景就在Mozila项目放出不久，就被AOL收购了。CEO借此赚了一笔，工程师却不得不离开自己喜爱的公司和项目。这帮程序员可以说是世界顶尖的，但是他们却挽救不了公司失败的命运。 </p> \n <p> &nbsp;&nbsp;&nbsp;代码的世界是奇妙而公平的。程序员按照自己的想象构建世界，正确的代码总是能得到正确的结果。所以程序员总是有一种可以创造一切的心气，然而却最终受制于其他。 </p> \n <p> &nbsp;&nbsp;&nbsp;我想有些程序员会有一些低调的傲气。这个职业一夜暴富的故事听了太多太多，这个职业改变世界的故事也数不胜数。虽然我们都自称为屌丝码农，但是我们都觉得自己才是代码世界的创造者，我们掌握了别人不懂的知识。 </p> \n <p> &nbsp;&nbsp;&nbsp;我想还有些程序员会有一些悲观的态度。码农收入有限，发展不好，工作累，生活没有乐趣，每天受限于管理层。 </p> \n <p> &nbsp;&nbsp;&nbsp;小时候，巷子里经常路过卖糖艺的老人。这个老爷爷身边总是围满了小孩。他把糖熔化，摊在一张白板上，画出各种栩栩如生的动物。最常见的是十二生肖，两毛钱可以转一次轮盘，指向哪个，就把哪个给你。最精妙的是龙，不但有气势，而且分量多，如果转到了，可是要开心很久的。那时候真的觉得这个老爷爷是带着魔法的人，竟然可以把龙画的这么像。 </p> \n <p> &nbsp;&nbsp;&nbsp;后来大了，去旅游的时候，也看到一个糖艺人。这时的糖艺已经可以花几块钱定做了，我买了一个，看着糖艺人娴熟的画好一条龙，还是那么栩栩如生，做一个糖模也就几块钱，他一辈子都赚不了太多，可是我看到他熟练的动作，好像这门手艺已经成为了他人的一部分，分不开了。他雕琢这份糖模的时候，没有什么表情，却有一种安静的力量。 </p> \n <p> &nbsp;&nbsp;&nbsp;<span>&nbsp;</span><span>而在我看来，写代码，仅仅</span><span>是一门技艺，是一种谋生的工具，却又带来人生的乐趣。作为一个写代码的</span>手艺人，靠写代码混口饭吃，同时做着改变世界的梦，也就够了。 </p> \n <p> &nbsp;&nbsp; </p> \n <p> &nbsp;&nbsp;&nbsp; </p> \n <p> &nbsp;&nbsp;&nbsp;打个广告：买了一个域名codecraft.us，取“代码制造”之意，也是抄袭自最喜欢的&quot;Warcraft&quot;系列吧。准备做点好玩的东西。 </p>\n</div>","description":"2012-11-11 12:40","name":"CodeCraft","type":"text"},{"contents":"<h2>无责任励志一则-成功就是把你做的事做精致</h2><div class=\"BlogContent\">\n <p>我们常说，这个世界太浮躁。实际上也是如此，今年小孩出生，同时又买了房子，生活上的压力顿时压下来，差点趴下了。但是我是个老实人，急躁又有什么用呢，还不是每天上班下班，下班看书写代码，没有那个业余找钱的能力，于是也就算了，安心搞点好玩的。</p> \n <p>记得去年给自己定了个目标，今年要在技术上有所进步，并且能够在一流的开源项目里贡献代码。于是我尝试了读tomcat和spring的源码，结果根本没能坚持下去。因为根本没那么多时间去阅读代码，也坚持不下去，最后都是不了了之。现在想来，根本不是对这些项目感兴趣，其实平时用到的功能也不全，完全是因为觉得它们很牛逼。</p> \n <p>但是或许是无心插柳吧，之前写了一个爬虫框架webmagic，随便放到了github上。我这个人比较喜欢分享，因为都是自己趟过的坑，也不希望别人再进去，所以就写了一两篇文章介绍了下。结果喜欢的人不少，还有了一些粉丝了。后来收集了一些反馈意见，就开始了开源的旅程。我以前在点点做抓博客文章的事情，具体就是写正则去抽取网页内容，其实是很没意思的活，但是至少积累了不少领域经验，于是对写webmagic产生了很大的影响。webmagic现在star和fork都过百了，在github Java项目中排800名左右，虽然不算很厉害，但是对我来说已经是超出预料了。</p> \n <p>维护开源软件是枯燥的，因为有很多问题需要回答，无论是专业的不专业的，下至maven的使用，上至设计思想。但是我也知道用户的宝贵，所以基本上事无巨细，我都会一一回答。我把webmagic当成一个产品来做，希望更多人了解它和喜欢它。</p> \n <p>从个人角度，确实也希望树立自己的知名度(然后工资高点之类的=.=)，但是生活在这个时代，谁有那么崇高呢。你产生价值，得到回馈，也是应该的。</p> \n <p>意外的惊喜是，因为webmagic需要写一些demo，结果写demo时遇到一个HttpClient的bug，后来反馈到了Apache，并提交了patch，结果就这么被接收了。虽然这个项目不如Apache其他项目那么知名，但是就跟它名字一样，在Java界基本是Http客户端的不二之选。于是我终于在快年底完成了今年的目标了。</p> \n <p>今天在看Hadoop的东西，看到其实HDFS是Nutch为了保存海量文件而开发的，而Hadoop本身也是起源于项目需要。</p> \n <p>现在的工作，我一直在做一些跑job的事情，大家都觉得挺无聊。但是想想，其实那么高端大气的Hadoop也是从跑job开始的。何不好好干呢？</p>\n</div>","description":"2013-11-08 20:21","name":"无责任励志一则-成功就是把你做的事做精致","type":"text"},{"contents":"<h2>如何发起一个开源项目</h2><div class=\"BlogContent\">\n <p>最近有朋友问我，想要做一个开源项目，但是不知道做什么好。WebMagic虽然还很小，但是写的过程中总会有些感悟，提出来跟大家分享。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>开源要有需求</h2> \n <p>“创始人”、“作者”这样的光环吸引了不少人，就跟很多人吼着要去“创业”一样，于是大家加入了“重复发明轮子”大潮。最经典的大概算是“Web框架”了。</p> \n <p>我不反对大家为了学习自己写写框架，从菜鸟一步步走来嘛，为了考验下自己的能力，大家都可以理解的。这样的项目走远的几率很小，请放平心态，冷静看待，你要的是过程，不是结果。</p> \n <p>还有一种是真的想要结果的，想要成为“知名项目创始人”的，我觉得你可以用“创业”的思路去想想这件事。开源项目本质也是一种产品，一种给开发者的产品，所以一样要有需求。你抓住了需求，自然就有了参与者。Web框架有需求吗？我想是有的，但是要么是更特殊的场景，要么是更便捷的使用，要么是更高的性能，如果仅仅想证明“我代码比xxx写得好”，或者“我做了xxx”，我觉得还是趁早收手好。抓不住需求的创业是死路一条，开源项目也不例外。</p> \n <p>举个例子，我之前写过一个DNS服务器BlackHole，差不多就是为了提高自己的技术而写的。那段时间每天既写代码，又写博客，提高倒是非常快，但是项目本身积累不多，因为少有需求，所以也少有人参与。现在开发完了，我自己也懒得用了。这个项目对我自己来说是挺好的，但是价值产出就比较小了。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>开源请选择熟悉的领域</h2> \n <p>首先，把日常工作做好。如果日常工作实在不是你喜欢的领域，我觉得倒不如换一个工作，但是请分清什么是真的不喜欢，什么是懒得去工作的借口。</p> \n <p>在日常工作中，总会用到一些开源产品，工作中遇到问题，做到求甚解，乃至于深入进去，这样很可能会找到官方也不曾发现的东西，从而反馈官方，这样既做出了贡献，又对日常工作本身也有帮助。而且随着你对这个项目越来越熟悉，你成为核心commiter也并非不可能。这样创造的价值，可能比自己发起一个项目更大。</p> \n <p>另一个可能是日常工作中需要的东西，却没有开源产品作为替代，那么你倒是可以自己尝试做一个。你的需求也是别人的需求。《大教堂与集市》里就说过，好的开源项目都是挠到了自己的痒处。WebMagic应该属于此类。WebMagic可能不具有说服力，那么Github上star最高的Bootstrap，或者是Google的MapReduce技术，其实都是来源于工作中的需求，乃至于开发者自己的需求。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>开源与工作的关系</h2> \n <p>很多公司都支持员工参与开源项目，国外的不列了，国内的阿里是代表，其他大公司基本上也是不排斥的。好的公司甚至能申请到资源，组建一个小团队来做这个事情。</p> \n <p>当然如果你的项目跟工作关系不大，那么可能会过的难过一点，但是这不是绝对的。比如我日常工作是做Web开发，但是WebMagic是一个爬虫。但是我也会把WebMagic用在日常工作中，例如健康检查、自动化测试、简单的数据采集等地方。</p> \n <p>如果老板不满意你做开源，觉得你工作不饱和的话。首先，你确保不在工作时间做。其次，如果这样老板还有意见，我觉得可以考虑换一个老板，因为这样的老板见不得员工发展，对你长期来讲也没什么好处。如果时机不成熟，我觉得还是偷偷做吧，别放Github了，换个名字建私有库吧，<a href=\"http://git.oschina.net/\" rel=\"nofollow\">http://git.oschina.net/</a>是个不错的选择。</p> \n <span id=\"OSC_h2_4\"></span> \n <h2>开源贵在坚持</h2> \n <p>WebMagic从发布第一版到现在已经半年了。最开始功能比较简单，但是慢慢的完善起来。完善的过程中也有很多朋友参与，提出了不错的建议，从而促进产品的演化。</p> \n <p>WebMagic开源半年，发布了8个版本，已经有150多个star，差不多一天一个，并且基本是平稳增长。算个不负责任的数，坚持2年，那么能达到700个star，这算是一个中型项目的规模了。但是坚持绝非易事，相信大家都有体会。</p> \n <p>记得有人说，在国内做一个项目，如果作者不维护，基本上这个项目也就死掉了。就实际来看也差不多，大家自己感受一下。</p> \n <span id=\"OSC_h2_5\"></span> \n <h2>拥抱开源社区</h2> \n <p>Github是个非常不错的平台，但是缺乏对于小项目的推广。WebMagic能有一些用户，得感谢oschina这个社区。oschina关于软件的归类、搜索都很好，PR也挺高，还能将问答、博客和项目关联起来。</p> \n <p>经过我这半年的经验，转化率最高的是“投递新闻”，所以大家多多发布版本吧！</p>\n</div>","description":"2013-11-30 09:43","name":"如何发起一个开源项目","type":"text"}],"name":"codecraft","type":"dir"},{"contents":[{"contents":"<h2>Jsoup代码解读之一-概述</h2><div class=\"BlogContent\">\n <p>今天看到一个用python写的抽取正文的东东，美滋滋的用Java实现了一番，放到了webmagic里，然后发现Jsoup里已经有了…觉得自己各种不靠谱啊！算了，静下心来学学好东西吧！</p> \n <p>Jsoup是Java世界用作html解析和过滤的不二之选。支持将html解析为DOM树、支持CSS Selector形式选择、支持html过滤，本身还附带了一个Http下载器。从今天开始会写一个Jsoup源码解读系列，比起之前的博客，尽量会写的详尽一些。</p> \n <h2>概述</h2> \n <p>Jsoup的代码相当简洁，Jsoup总共53个类，且没有任何第三方包的依赖，对比最终发行包9.8M的SAXON，实在算得上是短小精悍了。</p> \n <pre class=\"brush: java; auto-links: false;\">jsoup\n├── examples #样例，包括一个将html转为纯文本和一个抽取所有链接地址的例子。    \n├── helper #一些工具类，包括读取数据、处理连接以及字符串转换的工具\n├── nodes #DOM节点定义\n├── parser #解析html并转换为DOM树\n├── safety #安全相关，包括白名单及html过滤\n└── select #选择器，支持CSS Selector以及NodeVisitor格式的遍历</pre> \n <h2>使用</h2> \n <p>Jsoup的入口是<code>Jsoup</code>类。examples包里提供了两个例子，解析html后，分别用CSS Selector以及NodeVisitor来操作Dom元素。</p> \n <p>这里用<code>ListLinks</code>里的例子来说明如何调用Jsoup：</p> \n <pre class=\"brush: java; auto-links: false;\">public static void main(String[] args) throws IOException {\n    Validate.isTrue(args.length == 1, &quot;usage: supply url to fetch&quot;);\n    String url = args[0];\n    print(&quot;Fetching %s...&quot;, url);\n\n    // 下载url并解析成html DOM结构\n    Document doc = Jsoup.connect(url).get();\n    // 使用select方法选择元素，参数是CSS Selector表达式\n    Elements links = doc.select(&quot;a[href]&quot;);\n\n    print(&quot;\\nLinks: (%d)&quot;, links.size());\n    for (Element link : links) {\n        //使用abs:前缀取绝对url地址\n        print(&quot; * a: &lt;%s&gt;  (%s)&quot;, link.attr(&quot;abs:href&quot;), trim(link.text(), 35));\n    }\n}</pre> \n <p>Jsoup使用了自己的一套DOM代码体系，这里的Elements、Element等虽然名字和概念都与Java XML API<code>org.w3c.dom</code>类似，但并没有代码层面的关系。就是说你想用XML的一套API来操作Jsoup的结果是办不到的，但是正因为如此，才使得Jsoup可以抛弃xml里一些繁琐的API，使得代码更加简单。</p> \n <p>还有一种方式是通过<code>NodeVisitor</code>来遍历DOM树，这个在对整个html做分析和替换时比较有用：</p> \n <pre class=\"brush: java; auto-links: false;\">public interface NodeVisitor {\n\n    //遍历到节点开始时，调用此方法\n    public void head(Node node, int depth);\n\n    //遍历到节点结束时(所有子节点都已遍历完)，调用此方法\n    public void tail(Node node, int depth);\n}</pre> \n <p><code>HtmlToPlainText</code>的例子说明了如何使用NodeVisitor来遍历DOM树，将html转化为纯文本，并将需要换行的标签替换为换行\\n：</p> \n <pre class=\"brush: java; auto-links: false;\">public static void main(String... args) throws IOException {\n    Validate.isTrue(args.length == 1, &quot;usage: supply url to fetch&quot;);\n    String url = args[0];\n\n    // fetch the specified URL and parse to a HTML DOM\n    Document doc = Jsoup.connect(url).get();\n\n    HtmlToPlainText formatter = new HtmlToPlainText();\n    String plainText = formatter.getPlainText(doc);\n    System.out.println(plainText);\n}\n\npublic String getPlainText(Element element) {\n    //自定义一个NodeVisitor - FormattingVisitor\n    FormattingVisitor formatter = new FormattingVisitor();\n    //使用NodeTraversor来装载FormattingVisitor\n    NodeTraversor traversor = new NodeTraversor(formatter);\n    //进行遍历\n    traversor.traverse(element);\n    return formatter.toString();\n}</pre> \n <p>下一节将从DOM结构开始对Jsoup代码进行分析。</p>\n</div>","description":"2013-08-25 21:13","name":"Jsoup代码解读之一-概述","type":"text"},{"contents":"<h2>Jsoup代码解读之二-DOM相关对象</h2><div class=\"BlogContent\">\n <p>之前在文章中说到，Jsoup使用了一套自己的DOM对象体系，和Java XML API互不兼容。这样做的好处是从XML的API里解脱出来，使得代码精炼了很多。这篇文章会说明Jsoup的DOM结构，DOM的遍历方式。在下一篇文章，我会并结合这两个基础，分析一下Jsoup的HTML输出功能。</p> \n <h2>DOM结构相关类</h2> \n <p>我们先来看看nodes包的类图：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0825/221021_wQvT_190591.png\" alt=\"node类图\" /></p> \n <p>这里可以看到，核心无疑是<code>Node</code>类。</p> \n <p>Node类是一个抽象类，它代表DOM树中的一个节点，它包含：</p> \n <ul> \n  <li>父节点<code>parentNode</code>以及子节点<code>childNodes</code>的引用</li> \n  <li>属性值集合<code>attributes</code></li> \n  <li>页面的uri<code>baseUri</code>，用于修正相对地址为绝对地址</li> \n  <li>在兄弟节点中的位置<code>siblingIndex</code>，用于进行DOM操作</li> \n </ul> \n <p>Node里面包含一些获取属性、父子节点、修改元素的方法，其中比较有意思的是<code>absUrl()</code>。我们知道，在很多html页面里，链接会使用相对地址，我们有时会需要将其转变为绝对地址。Jsoup的解决方案是在attr()的参数开始加&quot;abs:“，例如attr(“abs:href”)，而<code>absUrl()</code>就是其实现方式。我写的爬虫框架<a href=\"http://www.oschina.net/p/webmagic\" rel=\"nofollow\">webmagic</a>里也用到了类似功能，当时是自己手写的，看到Jsoup的实现，才发现自己是白费劲了，代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">URL base;\ntry {\n    try {\n        base = new URL(baseUri);\n    } catch (MalformedURLException e) {\n        // the base is unsuitable, but the attribute may be abs on its own, so try that\n        URL abs = new URL(relUrl);\n        return abs.toExternalForm();\n    }\n    // workaround: java resolves '//path/file + ?foo' to '//path/?foo', not '//path/file?foo' as desired\n    if (relUrl.startsWith(&quot;?&quot;))\n        relUrl = base.getPath() + relUrl;\n    // java URL自带的相对路径解析    \n    URL abs = new URL(base, relUrl);\n    return abs.toExternalForm();\n} catch (MalformedURLException e) {\n    return &quot;&quot;;\n}</pre> \n <p>Node还有一个比较值得一提的方法是<code>abstract String nodeName()</code>，这个相当于定义了节点的类型名(例如<code>Document</code>是'#Document'，<code>Element</code>则是对应的TagName)。</p> \n <p>Element也是一个重要的类，它代表的是一个HTML元素。它包含一个字段<code>tag</code>和<code>classNames</code>。classNames是&quot;class&quot;属性解析出来的集合，因为CSS规范里，“class&quot;属性允许设置多个，并用空格隔开，而在用Selector选择的时候，即使只指定其中一个，也能够选中其中的元素。所以这里就把&quot;class&quot;属性展开了。Element还有选取元素的入口，例如<code>select</code>、<code>getElementByXXX</code>，这些都用到了select包中的内容，这个留到下篇文章select再说。</p> \n <p>Document是代表整个文档，它也是一个特殊的Element，即根节点。Document除了Element的内容，还包括一些输出的方法。</p> \n <p>Document还有一个属性<code>quirksMode</code>，大致意思是定义处理非标准HTML的几个级别，这个留到以后分析parser的时候再说。</p> \n <h2>DOM树的遍历</h2> \n <p>Node还有一些方法，例如<code>outerHtml()</code>，用作节点及文档HTML的输出，用到了树的遍历。在DOM树的遍历上，用到了<code>NodeVisitor</code>和<code>NodeTraversor</code>来对树的进行遍历。<code>NodeVisitor</code>在上一篇文章提到过了，head()和tail()分别是遍历开始和结束时的方法，而<code>NodeTraversor</code>的核心代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">public void traverse(Node root) {\n    Node node = root;\n    int depth = 0;\n\n    //这里对树进行后序(深度优先)遍历\n    while (node != null) {\n        //开始遍历node\n        visitor.head(node, depth);\n        if (node.childNodeSize() &gt; 0) {\n            node = node.childNode(0);\n            depth++;\n        } else {\n            //没有下一个兄弟节点，退栈\n            while (node.nextSibling() == null &amp;&amp; depth &gt; 0) {\n                visitor.tail(node, depth);\n                node = node.parent();\n                depth--;\n            }\n            //结束遍历\n            visitor.tail(node, depth);\n            if (node == root)\n                break;\n            node = node.nextSibling();\n        }\n    }\n}</pre> \n <p>这里使用循环+回溯来替换掉了我们常用的递归方式，从而避免了栈溢出的风险。</p> \n <p>实际上，Jsoup的Selector机制也是基于<code>NodeVisitor</code>来实现的，可以说<code>NodeVisitor</code>是更加底层和灵活的API。</p> \n <p>在下一篇博客我会讲讲Document的输出。</p>\n</div>","description":"2013-08-26 08:13","name":"Jsoup代码解读之二-DOM相关对象","type":"text"},{"contents":"<h2>Jsoup代码解读之三-Document的输出</h2><div class=\"BlogContent\">\n <p>Jsoup官方说明里，一个重要的功能就是<strong><em>output tidy HTML</em></strong>。这里我们看看Jsoup是如何输出HTML的。</p> \n <h2>HTML相关知识</h2> \n <p>分析代码前，我们不妨先想想，“tidy HTML&quot;到底包括哪些东西：</p> \n <ul> \n  <li>换行，块级标签习惯上都会独占一行</li> \n  <li>缩进，根据HTML标签嵌套层数，行首缩进会不同</li> \n  <li>严格的标签闭合，如果是可以自闭合的标签并且没有内容，则进行自闭合</li> \n  <li>HTML实体的转义</li> \n </ul> \n <p>这里要补充一下HTML标签的知识。HTML Tag可以分为block和inline两类。关于Tag的inline和block的定义可以参考<a href=\"http://www.w3schools.com/html/html_blocks.asp\" rel=\"nofollow\">http://www.w3schools.com/html/html_blocks.asp</a>，而Jsoup的<code>Tag</code>类则是对Java开发者非常好的学习资料。</p> \n <pre class=\"brush: java; auto-links: false;\">// internal static initialisers:\n// prepped from http://www.w3.org/TR/REC-html40/sgml/dtd.html and other sources\n//block tags，需要换行\nprivate static final String[] blockTags = {\n        &quot;html&quot;, &quot;head&quot;, &quot;body&quot;, &quot;frameset&quot;, &quot;script&quot;, &quot;noscript&quot;, &quot;style&quot;, &quot;meta&quot;, &quot;link&quot;, &quot;title&quot;, &quot;frame&quot;,\n        &quot;noframes&quot;, &quot;section&quot;, &quot;nav&quot;, &quot;aside&quot;, &quot;hgroup&quot;, &quot;header&quot;, &quot;footer&quot;, &quot;p&quot;, &quot;h1&quot;, &quot;h2&quot;, &quot;h3&quot;, &quot;h4&quot;, &quot;h5&quot;, &quot;h6&quot;,\n        &quot;ul&quot;, &quot;ol&quot;, &quot;pre&quot;, &quot;div&quot;, &quot;blockquote&quot;, &quot;hr&quot;, &quot;address&quot;, &quot;figure&quot;, &quot;figcaption&quot;, &quot;form&quot;, &quot;fieldset&quot;, &quot;ins&quot;,\n        &quot;del&quot;, &quot;s&quot;, &quot;dl&quot;, &quot;dt&quot;, &quot;dd&quot;, &quot;li&quot;, &quot;table&quot;, &quot;caption&quot;, &quot;thead&quot;, &quot;tfoot&quot;, &quot;tbody&quot;, &quot;colgroup&quot;, &quot;col&quot;, &quot;tr&quot;, &quot;th&quot;,\n        &quot;td&quot;, &quot;video&quot;, &quot;audio&quot;, &quot;canvas&quot;, &quot;details&quot;, &quot;menu&quot;, &quot;plaintext&quot;\n};\n//inline tags，无需换行\nprivate static final String[] inlineTags = {\n        &quot;object&quot;, &quot;base&quot;, &quot;font&quot;, &quot;tt&quot;, &quot;i&quot;, &quot;b&quot;, &quot;u&quot;, &quot;big&quot;, &quot;small&quot;, &quot;em&quot;, &quot;strong&quot;, &quot;dfn&quot;, &quot;code&quot;, &quot;samp&quot;, &quot;kbd&quot;,\n        &quot;var&quot;, &quot;cite&quot;, &quot;abbr&quot;, &quot;time&quot;, &quot;acronym&quot;, &quot;mark&quot;, &quot;ruby&quot;, &quot;rt&quot;, &quot;rp&quot;, &quot;a&quot;, &quot;img&quot;, &quot;br&quot;, &quot;wbr&quot;, &quot;map&quot;, &quot;q&quot;,\n        &quot;sub&quot;, &quot;sup&quot;, &quot;bdo&quot;, &quot;iframe&quot;, &quot;embed&quot;, &quot;span&quot;, &quot;input&quot;, &quot;select&quot;, &quot;textarea&quot;, &quot;label&quot;, &quot;button&quot;, &quot;optgroup&quot;,\n        &quot;option&quot;, &quot;legend&quot;, &quot;datalist&quot;, &quot;keygen&quot;, &quot;output&quot;, &quot;progress&quot;, &quot;meter&quot;, &quot;area&quot;, &quot;param&quot;, &quot;source&quot;, &quot;track&quot;,\n        &quot;summary&quot;, &quot;command&quot;, &quot;device&quot;\n};\n//emptyTags是不能有内容的标签，这类标签都是可以自闭合的\nprivate static final String[] emptyTags = {\n        &quot;meta&quot;, &quot;link&quot;, &quot;base&quot;, &quot;frame&quot;, &quot;img&quot;, &quot;br&quot;, &quot;wbr&quot;, &quot;embed&quot;, &quot;hr&quot;, &quot;input&quot;, &quot;keygen&quot;, &quot;col&quot;, &quot;command&quot;,\n        &quot;device&quot;\n};\nprivate static final String[] formatAsInlineTags = {\n        &quot;title&quot;, &quot;a&quot;, &quot;p&quot;, &quot;h1&quot;, &quot;h2&quot;, &quot;h3&quot;, &quot;h4&quot;, &quot;h5&quot;, &quot;h6&quot;, &quot;pre&quot;, &quot;address&quot;, &quot;li&quot;, &quot;th&quot;, &quot;td&quot;, &quot;script&quot;, &quot;style&quot;,\n        &quot;ins&quot;, &quot;del&quot;, &quot;s&quot;\n};\n//在这些标签里，需要保留空格\nprivate static final String[] preserveWhitespaceTags = {\n        &quot;pre&quot;, &quot;plaintext&quot;, &quot;title&quot;, &quot;textarea&quot;\n};</pre> \n <p>另外，Jsoup的<code>Entities</code>类里包含了一些HTML实体转义的东西。这些转义的对应数据保存在<code>entities-full.properties</code>和<code>entities-base.properties</code>里。</p> \n <h2>Jsoup的格式化实现</h2> \n <p>在Jsoup里，直接调用<code>Document.toString()</code>(继承自Element)，即可对文档进行输出。另外<code>OutputSettings</code>可以控制输出格式，主要是<code>prettyPrint</code>(是否重新格式化)、<code>outline</code>(是否强制所有标签换行)、<code>indentAmount</code>(缩进长度)等。</p> \n <p>里面的继承和互相调用关系略微复杂，大概是这样子：</p> \n <p><code>Document.toString()</code>=&gt;<code>Document.outerHtml()</code>=&gt;<code>Element.html()</code>，最终<code>Element.html()</code>又会循环调用所有子元素的<code>outerHtml()</code>，拼接起来作为输出。</p> \n <pre class=\"brush: java; auto-links: false;\">private void html(StringBuilder accum) {\n    for (Node node : childNodes)\n        node.outerHtml(accum);\n}</pre> \n <p>而<code>outerHtml()</code>会使用一个<code>OuterHtmlVisitor</code>对所以子节点做遍历，并拼装起来作为结果。</p> \n <pre class=\"brush: java; auto-links: false;\">protected void outerHtml(StringBuilder accum) {\n    new NodeTraversor(new OuterHtmlVisitor(accum, getOutputSettings())).traverse(this);\n}</pre> \n <p>OuterHtmlVisitor会对所有子节点做遍历，并调用<code>node.outerHtmlHead()</code>和<code>node.outerHtmlTail</code>两个方法。</p> \n <pre class=\"brush: java; auto-links: false;\">private static class OuterHtmlVisitor implements NodeVisitor {\n    private StringBuilder accum;\n    private Document.OutputSettings out;\n\n    public void head(Node node, int depth) {\n        node.outerHtmlHead(accum, depth, out);\n    }\n\n    public void tail(Node node, int depth) {\n        if (!node.nodeName().equals(&quot;#text&quot;)) // saves a void hit.\n            node.outerHtmlTail(accum, depth, out);\n    }\n}</pre> \n <p>我们终于找到了真正工作的代码，<code>node.outerHtmlHead()</code>和<code>node.outerHtmlTail</code>。Jsoup里每种Node的输出方式都不太一样，这里只讲讲两种主要节点：<code>Element</code>和<code>TextNode</code>。<code>Element</code>是格式化的主要对象，它的两个方法代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">void outerHtmlHead(StringBuilder accum, int depth, Document.OutputSettings out) {\n    if (accum.length() &gt; 0 &amp;&amp; out.prettyPrint()\n            &amp;&amp; (tag.formatAsBlock() || (parent() != null &amp;&amp; parent().tag().formatAsBlock()) || out.outline()) )\n        //换行并调整缩进\n        indent(accum, depth, out);\n    accum\n            .append(&quot;&lt;&quot;)\n            .append(tagName());\n    attributes.html(accum, out);\n\n    if (childNodes.isEmpty() &amp;&amp; tag.isSelfClosing())\n        accum.append(&quot; /&gt;&quot;);\n    else\n        accum.append(&quot;&gt;&quot;);\n}\n\nvoid outerHtmlTail(StringBuilder accum, int depth, Document.OutputSettings out) {\n    if (!(childNodes.isEmpty() &amp;&amp; tag.isSelfClosing())) {\n        if (out.prettyPrint() &amp;&amp; (!childNodes.isEmpty() &amp;&amp; (\n                tag.formatAsBlock() || (out.outline() &amp;&amp; (childNodes.size()&gt;1 || (childNodes.size()==1 &amp;&amp; !(childNodes.get(0) instanceof TextNode))))\n        )))\n            //换行并调整缩进\n            indent(accum, depth, out);\n        accum.append(&quot;&lt;/&quot;).append(tagName()).append(&quot;&gt;&quot;);\n    }\n}</pre> \n <p>而ident方法的代码只有一行：</p> \n <pre class=\"brush: java; auto-links: false;\">protected void indent(StringBuilder accum, int depth, Document.OutputSettings out) {\n    //out.indentAmount()是缩进长度，默认是1\n    accum.append(&quot;\\n&quot;).append(StringUtil.padding(depth * out.indentAmount()));\n}</pre> \n <p>代码简单明了，就没什么好说的了。值得一提的是，<code>StringUtil.padding()</code>方法为了减少字符串生成，把常用的缩进保存到了一个数组中。</p> \n <p>好了，水了一篇文章，下一篇将比较有技术含量的parser部分。</p> \n <p>另外，通过本节的学习，我们学到了要把StringBuilder命名为<strong>accum</strong>，而不是<strong>sb</strong>。</p>\n</div>","description":"2013-08-26 20:23","name":"Jsoup代码解读之三-Document的输出","type":"text"},{"contents":"<h2>Jsoup代码解读之四-parser(上)</h2><div class=\"BlogContent\">\n <p>作为Java世界最好的HTML 解析库，Jsoup的parser实现非常具有代表性。这部分也是Jsoup最复杂的部分，需要一些数据结构、状态机乃至编译器的知识。好在HTML语法不复杂，解析只是到DOM树为止，所以作为编译器入门倒是挺合适的。这一块不要指望囫囵吞枣，我们还是泡一杯咖啡，细细品味其中的奥妙吧。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>基础知识</h2> \n <span id=\"OSC_h3_2\"></span> \n <h3>编译器</h3> \n <p>将计算机语言转化为另一种计算机语言(通常是更底层的语言，例如机器码、汇编、或者JVM字节码)的过程就叫做编译(compile)。编译器(Compiler)是计算机科学的一个重要领域，已经有很多年历史了，而最近各种通用语言层出不穷，加上跨语言编译的兴起、DSL概念的流行，都让编译器变成了一个很时髦的东西。</p> \n <p>编译器领域相关有三本公认的经典书籍，龙书<a href=\"http://book.douban.com/subject/1866231/\" rel=\"nofollow\">《Compilers: Principles, Techniques, and Tools 》</a>，虎书<a href=\"http://book.douban.com/subject/1923484/\" rel=\"nofollow\">《Modern Compiler Implementation in X (X表示各种语言)》</a>，鲸书<a href=\"http://book.douban.com/subject/1821532/\" rel=\"nofollow\">《Advanced Compiler Design and Implementation》</a>。其中龙书是编译理论方面公认的不二之选，而后面两本则对实践更有指导意义。另外<a href=\"http://www.cnblogs.com/Ninputer\" rel=\"nofollow\">@装配脑袋</a>有个很好的编译器入门系列博客：<a href=\"http://www.cnblogs.com/Ninputer/archive/2011/06/07/2074632.html\" rel=\"nofollow\">http://www.cnblogs.com/Ninputer/archive/2011/06/07/2074632.html</a></p> \n <p>编译器的基本流程如下：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0828/081055_j2Xy_190591.png\" alt=\"compiler\" /></p> \n <p>其中词法分析、语法分析、语义分析这部分又叫编译器的前端(front-end)，而此后的中间代码生成直到目标生成、优化等属于编译器的后端(back-end)。编译器的前端技术已经很成熟了，也有yacc这样的工具来自动进行词法、语法分析(Java里也有一个类似的工具ANTLR)，而后端技术更加复杂，也是目前编译器研究的重点。</p> \n <p>说了这么多，回到咱们的HTML上来。HTML是一种声明式的语言，可以理解它的最终的输出是浏览器里图形化的页面，而并非可执行的目标语言，因此我将这里的Translate改为了Render。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0828/103726_uejc_190591.png\" alt=\"html compiler\" /></p> \n <p>在Jsoup(包括类似的HTML parser)里，只做了Lex(词法分析)、Parse(语法分析)两步，而HTML parse最终产出结果，就是DOM树。至于HTML的语义解析以及渲染，不妨看看携程UED团队的这篇文章：<a href=\"http://ued.ctrip.com/blog/?p=3295\" rel=\"nofollow\">《浏览器是怎样工作的：渲染引擎，HTML解析》</a>。</p> \n <span id=\"OSC_h3_3\"></span> \n <h3>状态机</h3> \n <p>Jsoup的词法分析和语法分析都用到了状态机。状态机可以理解为一个特殊的程序模型，例如经常跟我们打交道的正则表达式就是用状态机实现的。</p> \n <p>它由状态(state)和转移(transition)两部分构成。根据状态转移的可能性，状态机又分为DFA(确定有限状态机)和NFA(非确定有限状态自动机)。这里拿一个最简单的正则表达式&quot;a[b]*“作为例子，我们先把它映射到一个状态机DFA，大概是这样子：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0828/131113_nyHh_190591.png\" alt=\"state machine\" /></p> \n <p>状态机本身是一个编程模型，这里我们尝试用程序去实现它，那么最直接的方式大概是这样：</p> \n <pre class=\"brush: java; auto-links: false;\">public void process(StringReader reader) throws StringReader.EOFException {\n    char ch;\n    switch (state) {\n        case Init:\n            ch = reader.read();\n            if (ch == 'a') {\n                state = State.AfterA;\n                accum.append(ch);\n            }\n            break;\n        case AfterA:\n            ...\n            break;\n        case AfterB:\n            ...\n            break;\n        case Accept:\n            ...\n            break;\n    }\n}</pre> \n <p>这样写简单的状态机倒没有问题，但是复杂情况下就有点难受了。还有一种标准的状态机解法，先建立状态转移表，然后使用这个表建立状态机。这个方法的问题就是，只能做纯状态转移，无法在代码级别操作输入输出。</p> \n <p>Jsoup里则使用了状态模式来实现状态机，初次看到时，确实让人眼前一亮。状态模式是设计模式的一种，它将状态和对应的行为绑定在一起。而在状态机的实现过程中，使用它来实现状态转移时的处理再合适不过了。</p> \n <p>“a[b]*“的例子的状态模式实现如下，这里采用了与Jsoup相同的方式，用到了枚举来实现状态模式：</p> \n <pre class=\"brush: java; auto-links: false;\">public class StateModelABStateMachine implements ABStateMachine {\n\n    State state;\n\n    StringBuilder accum;\n\n    enum State {\n        Init {\n            @Override\n            public void process(StateModelABStateMachine stateModelABStateMachine, StringReader reader) throws StringReader.EOFException {\n                char ch = reader.read();\n                if (ch == 'a') {\n                    stateModelABStateMachine.state = AfterA;\n                    stateModelABStateMachine.accum.append(ch);\n                }\n            }\n        },\n        Accept {\n            ...\n        },\n        AfterA {\n            ...\n        },\n        AfterB {\n            ...\n        };\n\n        public void process(StateModelABStateMachine stateModelABStateMachine, StringReader reader) throws StringReader.EOFException {\n        }\n    }\n\n    public void process(StringReader reader) throws StringReader.EOFException {\n        state.process(this, reader);\n    }\n}</pre> \n <p>PS:我在github上fork了一份Jsoup的代码，把这系列文章提交了上去，并且给一些代码增加了中文注释，有兴趣的可以看看<a href=\"https://github.com/code4craft/jsoup-learning\" rel=\"nofollow\">https://github.com/code4craft/jsoup-learning</a>。本文中提到的几种状态机的完整实现在这个仓库的<a href=\"https://github.com/code4craft/jsoup-learning/tree/master/src/main/java/us/codecraft/learning\" rel=\"nofollow\">https://github.com/code4craft/jsoup-learning/tree/master/src/main/java/us/codecraft/learning</a>路径下。</p> \n <p>下一篇文章将从Jsoup的词法分析器开始来讲状态机的使用。</p>\n</div>","description":"2013-08-28 14:17","name":"Jsoup代码解读之四-parser(上)","type":"text"},{"contents":"<h2>Jsoup代码解读之五-parser(中)</h2><div class=\"BlogContent\">\n <p>上一篇文章讲到了状态机和词法分析的基本知识，这一节我们来分析Jsoup是如何进行词法分析的。</p> \n <h2>代码结构</h2> \n <p>先介绍以下parser包里的主要类：</p> \n <ul> \n  <li><p><code>Parser</code></p> <p>Jsoup parser的入口facade，封装了常用的parse静态方法。可以设置<code>maxErrors</code>，用于收集错误记录，默认是0，即不收集。与之相关的类有<code>ParseError</code>,<code>ParseErrorList</code>。基于这个功能，我写了一个<a href=\"https://github.com/code4craft/jsoup/tree/master/src/main/java/us/codecraft/learning/parser\" rel=\"nofollow\"><code>PageErrorChecker</code></a>来对页面做语法检查，并输出语法错误。</p> </li> \n  <li><p><code>Token</code></p> <p>保存单个的词法分析结果。Token是一个抽象类，它的实现有<code>Doctype</code>,<code>StartTag</code>,<code>EndTag</code>,<code>Comment</code>,<code>Character</code>,<code>EOF</code>6种，对应6种词法类型。</p> </li> \n  <li><p><code>Tokeniser</code></p> <p>保存词法分析过程的状态及结果。比较重要的两个字段是<code>state</code>和<code>emitPending</code>，前者保存状态，后者保存输出。其次还有<code>tagPending</code>/<code>doctypePending</code>/<code>commentPending</code>，保存还没有填充完整的Token。</p> </li> \n  <li><p><code>CharacterReader</code></p> <p>对读取字符的逻辑的封装，用于Tokenize时候的字符输入。CharacterReader包含了类似NIO里ByteBuffer的<code>consume()</code>、<code>unconsume()</code>、<code>mark()</code>、<code>rewindToMark()</code>，还有高级的<code>consumeTo()</code>这样的用法。</p> </li> \n  <li><p><code>TokeniserState</code></p> <p>用枚举实现的词法分析状态机。</p> </li> \n  <li><p><code>HtmlTreeBuilder</code></p> <p>语法分析，通过token构建DOM树的类。</p> </li> \n  <li><p><code>HtmlTreeBuilderState</code></p> <p>语法分析状态机。</p> </li> \n  <li><p><code>TokenQueue</code></p> <p>虽然披了个Token的马甲，其实是在query的时候用到，留到select部分再讲。</p> </li> \n </ul> \n <h2>词法分析状态机</h2> \n <p>现在我们来讲讲HTML的词法分析过程。这里借用一下<a href=\"http://ued.ctrip.com/blog/?p=3295\" rel=\"nofollow\">http://ued.ctrip.com/blog/?p=3295</a>里的图，图中描述了一个Tag标签的状态转移过程，</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Ftaligarsiel.com%2FProjects%2Fimage019.png\" alt=\"lexer\" /></p> \n <p>这里忽略了HTML注释、实体以及属性，只保留基本的开始/结束标签，例如下面的HTML:</p> \n <pre class=\"brush: html; auto-links: false;\">&lt;div&gt;test&lt;/div&gt;</pre> \n <p>Jsoup里词法分析比较复杂，我从里面抽取出了对应的部分，就成了我们的miniSoupLexer(这里省略了部分代码，完整代码可以看这里<a href=\"https://github.com/code4craft/jsoup/blob/master/src/main/java/org/jsoup/parser/MiniSoupTokeniserState.java\" rel=\"nofollow\"><code>MiniSoupTokeniserState</code></a>)：</p> \n <pre class=\"brush: java; auto-links: false;\">enum MiniSoupTokeniserState implements ITokeniserState {\n    /**\n     * 什么层级都没有的状态\n     * ⬇\n     * &lt;div&gt;test&lt;/div&gt;\n     *      ⬇\n     * &lt;div&gt;test&lt;/div&gt;\n     */\n    Data {\n        // in data state, gather characters until a character reference or tag is found\n        public void read(Tokeniser t, CharacterReader r) {\n            switch (r.current()) {\n                case '&lt;':\n                    t.advanceTransition(TagOpen);\n                    break;\n                case eof:\n                    t.emit(new Token.EOF());\n                    break;\n                default:\n                    String data = r.consumeToAny('&amp;', '&lt;', nullChar);\n                    t.emit(data);\n                    break;\n            }\n        }\n    },\n    /**\n     * ⬇\n     * &lt;div&gt;test&lt;/div&gt;\n     */\n    TagOpen {\n        ...\n    },\n    /**\n     *           ⬇\n     * &lt;div&gt;test&lt;/div&gt;\n     */\n    EndTagOpen {\n        ...\n    },\n    /**\n     *  ⬇\n     * &lt;div&gt;test&lt;/div&gt;\n     */\n    TagName {\n        ...\n    };\n\n}</pre> \n <p>参考这个程序，可以看到Jsoup的词法分析的大致思路。分析器本身的编写是比较繁琐的过程，涉及属性值(区分单双引号)、DocType、注释、HTML实体，以及一些错误情况。不过了解了其思路，代码实现也是按部就班的过程。</p> \n <p>下一节开始介绍语法分析部分。</p> \n <p>最后还是附上我的Jsoup解读系列文章及代码地址：</p> \n <p><a href=\"https://github.com/code4craft/jsoup-learning\" rel=\"nofollow\">https://github.com/code4craft/jsoup-learning</a></p>\n</div>","description":"2013-08-28 22:57","name":"Jsoup代码解读之五-parser(中)","type":"text"},{"contents":"<h2>Jsoup代码解读之六-parser(下)</h2><div class=\"BlogContent\">\n <p>最近生活上有点忙，女儿老是半夜不睡，精神状态也不是很好。工作上的事情也谈不上顺心，有很多想法但是没有几个被认可，有些事情也不是说代码写得好就行的。算了，还是端正态度，毕竟资历尚浅，我还是继续我的。</p> \n <p>读Jsoup源码并非无聊，目的其实是为了将webmagic做的更好一点，毕竟parser也是爬虫的重要组成部分之一。读了代码后，收获也不少，对HTML的知识也更进一步了。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>DOM树产生过程</h2> \n <p>这里单独将<code>TreeBuilder</code>部分抽出来叫做语法分析过程可能稍微不妥，其实就是根据Token生成DOM树的过程，不过我还是沿用这个编译器里的称呼了。</p> \n <p><code>TreeBuilder</code>同样是一个facade对象，真正进行语法解析的是以下一段代码：</p> \n <pre class=\"brush: java; auto-links: false;\">protected void runParser() {\n    while (true) {\n        Token token = tokeniser.read();\n\n        process(token);\n\n        if (token.type == Token.TokenType.EOF)\n            break;\n    }\n}</pre> \n <p><code>TreeBuilder</code>有两个子类，<code>HtmlTreeBuilder</code>和<code>XmlTreeBuilder</code>。<code>XmlTreeBuilder</code>自然是构建XML树的类，实现颇为简单，基本上是维护一个栈，并根据不同Token插入节点即可：</p> \n <pre class=\"brush: java; auto-links: false;\">@Override\nprotected boolean process(Token token) {\n    // start tag, end tag, doctype, comment, character, eof\n    switch (token.type) {\n        case StartTag:\n            insert(token.asStartTag());\n            break;\n        case EndTag:\n            popStackToClose(token.asEndTag());\n            break;\n        case Comment:\n            insert(token.asComment());\n            break;\n        case Character:\n            insert(token.asCharacter());\n            break;\n        case Doctype:\n            insert(token.asDoctype());\n            break;\n        case EOF: // could put some normalisation here if desired\n            break;\n        default:\n            Validate.fail(&quot;Unexpected token type: &quot; + token.type);\n    }\n    return true;\n}</pre> \n <p><code>insertNode</code>的代码大致是这个样子(为了便于展示，对方法进行了一些整合)：</p> \n <pre class=\"brush: java; auto-links: false;\">Element insert(Token.StartTag startTag) {\n    Tag tag = Tag.valueOf(startTag.name());\n    Element el = new Element(tag, baseUri, startTag.attributes);\n    stack.getLast().appendChild(el);\n    if (startTag.isSelfClosing()) {\n        tokeniser.acknowledgeSelfClosingFlag();\n        if (!tag.isKnownTag()) // unknown tag, remember this is self closing for output. see above.\n            tag.setSelfClosing();\n    } else {\n        stack.add(el);\n    }\n    return el;\n}</pre> \n <span id=\"OSC_h2_2\"></span> \n <h2>HTML解析状态机</h2> \n <p>相比<code>XmlTreeBuilder</code>，<code>HtmlTreeBuilder</code>则实现较为复杂，除了类似的栈结构以外，还用到了<code>HtmlTreeBuilderState</code>来构建了一个状态机来分析HTML。这是为什么呢？不妨看看<code>HtmlTreeBuilderState</code>到底用到了哪些状态吧（在代码中中用&lt;!– State: –\\&gt;标明状态）：</p> \n <pre class=\"brush: html; auto-links: false;\">&lt;!-- State: Initial --&gt;\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;\n&lt;!-- State: BeforeHtml --&gt;\n&lt;html lang='zh-CN' xml:lang='zh-CN' xmlns='http://www.w3.org/1999/xhtml'&gt;\n&lt;!-- State: BeforeHead --&gt;\n&lt;head&gt;\n  &lt;!-- State: InHead --&gt;\n  &lt;script type=&quot;text/javascript&quot;&gt;\n  //&lt;!-- State: Text --&gt;\n    function xx(){\n    }\n  &lt;/script&gt;\n  &lt;noscript&gt;\n    &lt;!-- State: InHeadNoscript --&gt;\n    Your browser does not support JavaScript!\n  &lt;/noscript&gt;\n&lt;/head&gt;\n&lt;!-- State: AfterHead --&gt;\n&lt;body&gt;\n&lt;!-- State: InBody --&gt;\n&lt;textarea&gt;\n    &lt;!-- State: Text --&gt;\n    xxx\n&lt;/textarea&gt;\n&lt;table&gt;\n    &lt;!-- State: InTable --&gt;\n    &lt;!-- State: InTableText --&gt;\n    xxx\n    &lt;tbody&gt;\n    &lt;!-- State: InTableBody --&gt;\n    &lt;/tbody&gt;\n    &lt;tr&gt;\n        &lt;!-- State: InRow --&gt;\n        &lt;td&gt;\n            &lt;!-- State: InCell --&gt;\n        &lt;/td&gt;\n    &lt;/tr&gt;    \n&lt;/table&gt;\n&lt;/html&gt;</pre> \n <p>这里可以看到，HTML标签是有嵌套要求的，例如<code>&lt;tr&gt;</code>,<code>&lt;td&gt;</code>需要组合<code>&lt;table&gt;</code>来使用。根据Jsoup的代码，可以发现，<code>HtmlTreeBuilderState</code>做了以下一些事情：</p> \n <ul> \n  <li><span id=\"OSC_h3_3\"></span><h3>语法检查</h3> <p>例如<code>tr</code>没有嵌套在<code>table</code>标签内，则是一个语法错误。当<code>InBody</code>状态直接出现以下tag时，则出错。Jsoup里遇到这种错误，会发现这个Token的解析并记录错误，然后继续解析下面内容，并不会直接退出。</p> <pre class=\"brush: java; auto-links: false;\">InBody {\n    boolean process(Token t, HtmlTreeBuilder tb) {\n        if (StringUtil.in(name,\n        &quot;caption&quot;, &quot;col&quot;, &quot;colgroup&quot;, &quot;frame&quot;, &quot;head&quot;, &quot;tbody&quot;, &quot;td&quot;, &quot;tfoot&quot;, &quot;th&quot;, &quot;thead&quot;, &quot;tr&quot;)) {\n        tb.error(this);\n        return false;\n        }\n    }</pre> </li> \n  <li><span id=\"OSC_h3_4\"></span><h3>标签补全</h3> <p>例如<code>head</code>标签没有闭合，就写入了一些只有body内才允许出现的标签，则自动闭合<code>&lt;/head&gt;</code>。<code>HtmlTreeBuilderState</code>有的方法<code>anythingElse()</code>就提供了自动补全标签，例如<code>InHead</code>状态的自动闭合代码如下：</p> <pre class=\"brush: java; auto-links: false;\">private boolean anythingElse(Token t, TreeBuilder tb) {\n        tb.process(new Token.EndTag(&quot;head&quot;));\n        return tb.process(t);\n    }</pre> <p>还有一种标签闭合方式，例如下面的代码：</p> <pre class=\"brush: java; auto-links: false;\">private void closeCell(HtmlTreeBuilder tb) {\n    if (tb.inTableScope(&quot;td&quot;))\n        tb.process(new Token.EndTag(&quot;td&quot;));\n    else\n        tb.process(new Token.EndTag(&quot;th&quot;)); // only here if th or td in scope\n}</pre> </li> \n </ul> \n <span id=\"OSC_h2_5\"></span> \n <h2>实例研究</h2> \n <span id=\"OSC_h3_6\"></span> \n <h3>缺少标签时，会发生什么事？</h3> \n <p>好了，看了这么多parser的源码，不妨回到我们的日常应用上来。我们知道，在页面里多写一个两个未闭合的标签是很正常的事，那么它们会被怎么解析呢？</p> \n <p>就拿<code>&lt;div&gt;</code>标签为例：</p> \n <ol> \n  <li><p>漏写了开始标签，只写了结束标签</p> <pre class=\"brush: java; auto-links: false;\">case EndTag:\n    if (StringUtil.in(name,&quot;div&quot;,&quot;dl&quot;, &quot;fieldset&quot;, &quot;figcaption&quot;, &quot;figure&quot;, &quot;footer&quot;, &quot;header&quot;, &quot;pre&quot;, &quot;section&quot;, &quot;summary&quot;, &quot;ul&quot;)) {                \n        if (!tb.inScope(name)) {\n        tb.error(this);\n        return false;\n        } \n    }</pre> <p>恭喜你，这个<code>&lt;/div&gt;</code>会被当做错误处理掉，于是你的页面就毫无疑问的乱掉了！当然，如果单纯多写了一个<code>&lt;/div&gt;</code>，好像也不会有什么影响哦？(记得有人跟我讲过为了防止标签未闭合，而在页面底部多写了几个<code>&lt;/div&gt;</code>的故事)</p> </li> \n  <li><p>写了开始标签，漏写了结束标签</p> <p>这个情况分析起来更复杂一点。如果是无法在内部嵌套内容的标签，那么在遇到不可接受的标签时，会进行闭合。而<code>&lt;div&gt;</code>标签可以包括大多数标签，这种情况下，其作用域会持续到HTML结束。</p> </li> \n </ol> \n <p>好了，parser系列算是分析结束了，其间学到不少HTML及状态机内容，但是离实际使用比较远。下面开始select部分，这部分可能对日常使用更有意义一点。</p> \n <p>最后附上我的Jsoup系列博客及源码地址：<a href=\"http://github.com/code4craft/jsoup-learning\" rel=\"nofollow\">http://github.com/code4craft/jsoup-learning</a></p>\n</div>","description":"2013-08-30 15:58","name":"Jsoup代码解读之六-parser(下)","type":"text"},{"contents":"<h2>Jsoup代码解读之七-实现一个CSS Selector</h2><div class=\"BlogContent\">\n <p><img src=\"http://static.oschina.net/uploads/space/2013/0830/180244_r1Vb_190591.jpg\" alt=\"street fighter\" /></p> \n <p>当当当！终于来到了Jsoup的特色：CSS Selector部分。selector也是我写的爬虫框架<a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\">webmagic</a>开发的一个重点。附上一张street fighter的图，希望以后webmagic也能挑战Jsoup!</p> \n <h2>select机制</h2> \n <p>Jsoup的select包里，类结构如下：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0830/184337_j85b_190591.png\" alt=\"uml\" /></p> \n <p>在最开始介绍Jsoup的时候，就已经说过<code>NodeVisitor</code>和<code>Selector</code>了。<code>Selector</code>是select部分的对外facade，而<code>NodeVisitor</code>则是遍历树的底层API，CSS Selector也是根据<code>NodeVisitor</code>实现的遍历。</p> \n <p>Jsoup的select核心是<code>Evaluator</code>。Selector所传递的表达式，会经过<code>QueryParser</code>，最终编译成一个<code>Evaluator</code>。<code>Evaluator</code>是一个抽象类，它只有一个方法：</p> \n <pre class=\"brush: java; auto-links: false;\">public abstract boolean matches(Element root, Element element);</pre> \n <p>注意这里传入了root，是为了某些情况下对树进行遍历时用的。</p> \n <p>Evaluator的设计简洁明了，所有的Selector表达式单词都会编译到对应的Evaluator。例如<code>#xx</code>对应<code>Id</code>，<code>.xx</code>对应<code>Class</code>，<code>[]</code>对应<code>Attribute</code>。这里补充一下w3c的CSS Selector规范：<a href=\"http://www.w3.org/TR/CSS2/selector.html\" rel=\"nofollow\">http://www.w3.org/TR/CSS2/selector.html</a></p> \n <p>当然，只靠这几个还不够，Jsoup还定义了<code>CombiningEvaluator</code>(对Evaluator进行And/Or组合)，<code>StructuralEvaluator</code>(结合DOM树结构进行筛选)。</p> \n <p>这里我们可能最关心的是，“div ul li”这样的父子结构是如何实现的。这个的实现方式在<code>StructuralEvaluator.Parent</code>中，贴一下代码了：</p> \n <pre class=\"brush: java; auto-links: false;\">static class Parent extends StructuralEvaluator {\n    public Parent(Evaluator evaluator) {\n        this.evaluator = evaluator;\n    }\n\n    public boolean matches(Element root, Element element) {\n        if (root == element)\n            return false;\n\n        Element parent = element.parent();\n        while (parent != root) {\n            if (evaluator.matches(root, parent))\n                return true;\n            parent = parent.parent();\n        }\n        return false;\n    }\n}</pre> \n <p>这里Parent包含了一个<code>evaluator</code>属性，会根据这个evaluator去验证所有父节点。注意Parent是可以嵌套的，所以这个表达式&quot;div ul li&quot;最终会编译成<code>And(Parent(And(Parent(Tag(&quot;div&quot;))，Tag(&quot;ul&quot;)),Tag(&quot;li&quot;)))</code>这样的Evaluator组合。</p> \n <p>select部分比想象的要简单，代码可读性也很高。经过了parser部分的研究，这部分应该算是驾轻就熟了。</p> \n <h2>关于webmagic的后续打算</h2> \n <p>webmagic是一个爬虫框架，它的Selector是用于抓取HTML中指定的文本，其机制和Jsoup的Evaluator非常像，只不过webmagic暂时是将Selector封装成较简单的API，而Evaluator直接上了表达式。之前也考虑过自己定制DSL来写一个HTML，现在看了Jsoup的源码，实现能力算是有了，但是引入DSL，实现只是一小部分，如何让DSL易写易懂才是难点。</p> \n <p>其实看了Jsoup的源码，精细程度上比webmagic要好得多了，基本每个类都对应一个真实的概念抽象，可能以后会在这方面下点工夫。</p> \n <p>下篇文章将讲最后一部分：白名单及HTML过滤机制。</p> \n <p>最后依然附上这系列文章和代码的github地址：<a href=\"https://github.com/code4craft/jsoup-learning\" rel=\"nofollow\">https://github.com/code4craft/jsoup-learning</a></p>\n</div>","description":"2013-08-30 21:23","name":"Jsoup代码解读之七-实现一个CSS Selector","type":"text"},{"contents":"<h2>Jsoup代码解读之八-防御XSS攻击</h2><div class=\"BlogContent\">\n <p><img src=\"http://static.oschina.net/uploads/space/2013/0831/071752_RBZc_190591.png\" alt=\"hacker\" /></p> \n <span id=\"OSC_h2_1\"></span> \n <h2>防御XSS攻击的一般原理</h2> \n <p>cleaner是Jsoup的重要功能之一，我们常用它来进行富文本输入中的XSS防御。</p> \n <p>我们知道，XSS攻击的一般方式是，通过在页面输入中嵌入一段恶意脚本，对输出时的DOM结构进行修改，从而达到执行这段脚本的目的。对于纯文本输入，过滤/转义HTML特殊字符<code>&lt;</code>,<code>&gt;</code>,<code>&quot;</code>,<code>'</code>是行之有效的办法，但是如果本身用户输入的就是一段HTML文本(例如博客文章)，这种方式就不太有效了。这个时候，就是Jsoup大显身手的时候了。</p> \n <p>在前面，我们已经知道了，Jsoup里怎么将HTML变成一棵DOM树，怎么对DOM树进行遍历，怎么对DOM文档进行输出，那么其实cleaner的实现方式，也能猜出大概了。使用Jsoup进行XSS防御，大致分为三个步骤:</p> \n <ol> \n  <li><p>将HTML解析为DOM树</p> <p>这一步可以过滤掉一些企图搞破坏的非闭合标签、非正常语法等。例如一些输入，会尝试用<code>&lt;/textarea&gt;</code>闭合当前Tag，然后写入攻击脚本。而根据前面对Jsoup的parser的分析，这种时候，这些非闭合标签会被当做错误并丢弃。</p> </li> \n  <li><p>过滤高风险标签/属性/属性值</p> <p>高风险标签是指<code>&lt;script&gt;</code>以及类似标签，对属性/属性值进行过滤是因为某些属性值里也可以写入javascript脚本，例如<code>onclick='alert(&quot;xss!&quot;)'</code>。</p> </li> \n  <li><p>重新将DOM树输出为HTML文本</p> <p>DOM树的输出，在前面(Jsoup代码解读之三)已经提到过了。</p> </li> \n </ol> \n <span id=\"OSC_h2_2\"></span> \n <h2>Cleaner与Whitelist</h2> \n <p>对于上述的两个步骤，1、3都已经分别在parser和输出中完成，现在只剩下步骤 2：过滤高风险标签等。</p> \n <p>Jsoup给出的答案是白名单。下面是<code>Whitelist</code>的部分代码。</p> \n <pre class=\"brush: java; auto-links: false;\">public class Whitelist {\n    private Set&lt;TagName&gt; tagNames; // tags allowed, lower case. e.g. [p, br, span]\n    private Map&lt;TagName, Set&lt;AttributeKey&gt;&gt; attributes; // tag -&gt; attribute[]. allowed attributes [href] for a tag.\n    private Map&lt;TagName, Map&lt;AttributeKey, AttributeValue&gt;&gt; enforcedAttributes; // always set these attribute values\n    private Map&lt;TagName, Map&lt;AttributeKey, Set&lt;Protocol&gt;&gt;&gt; protocols; // allowed URL protocols for attributes\n    private boolean preserveRelativeLinks; // option to preserve relative links\n}</pre> \n <p>这里定义了标签名/属性名/属性值的白名单。</p> \n <p>而<code>Cleaner</code>是过滤的执行者。不出所料，Cleaner内部定义了<code>CleaningVisitor</code>来进行标签的过滤。CleaningVisitor的过滤过程并不改变原始DOM树的值，而是将符合条件的属性，加入到<code>Element destination</code>里去。</p> \n <pre class=\"brush: java; auto-links: false;\">private final class CleaningVisitor implements NodeVisitor {\n    private int numDiscarded = 0;\n    private final Element root;\n    private Element destination; // current element to append nodes to\n\n    private CleaningVisitor(Element root, Element destination) {\n        this.root = root;\n        this.destination = destination;\n    }\n\n    public void head(Node source, int depth) {\n        if (source instanceof Element) {\n            Element sourceEl = (Element) source;\n\n            if (whitelist.isSafeTag(sourceEl.tagName())) { // safe, clone and copy safe attrs\n                ElementMeta meta = createSafeElement(sourceEl);\n                Element destChild = meta.el;\n                destination.appendChild(destChild);\n\n                numDiscarded += meta.numAttribsDiscarded;\n                destination = destChild;\n            } else if (source != root) { // not a safe tag, so don't add. don't count root against discarded.\n                numDiscarded++;\n            }\n        } else if (source instanceof TextNode) {\n            TextNode sourceText = (TextNode) source;\n            TextNode destText = new TextNode(sourceText.getWholeText(), source.baseUri());\n            destination.appendChild(destText);\n        } else { // else, we don't care about comments, xml proc instructions, etc\n            numDiscarded++;\n        }\n    }\n\n    public void tail(Node source, int depth) {\n        if (source instanceof Element &amp;&amp; whitelist.isSafeTag(source.nodeName())) {\n            destination = destination.parent(); // would have descended, so pop destination stack\n        }\n    }\n}</pre> \n <span id=\"OSC_h2_3\"></span> \n <h2>结束语</h2> \n <p>至此，Jsoup的全部模块都已经写完了。Jsoup源码并不多，只有14000多行，但是实现非常精巧，在读代码的过程中，除了相关知识，还验证几个很重要的思想：</p> \n <ul> \n  <li><p>最好的代码抽象，是对现实概念的映射。</p> <p>这句话在看《代码大全》的时候印象很深刻。在Jsoup里，只要有相关知识，每个类的作用都能第一时间明白其作用。</p> </li> \n  <li><p>不要过度抽象</p> <p>在Jsoup里，只用到了两个接口，一个是<code>NodeVisitor</code>，一个是<code>Connection</code>，其他都是用抽象类或者直接用实现类代替。记得有次面试的时候被问到我们开发中每逢一个功能，都要先定义一个接口的做法是否必要？现在的答案是没有必要，过度的抽象反而会降低代码质量。</p> <p>另外，Jsoup的代码内聚性都很高，每个类的功能基本都定义在类的内部，这是一个典型的充血模型。同时有大量的facade使用，而避免了Factory、Configure等类的出现，个人感觉这点是非常好的。</p> </li> \n </ul> \n <p>最后继续贴上Jsoup解读系列的github地址：<a href=\"https://github.com/code4craft/jsoup-learning/\" rel=\"nofollow\">https://github.com/code4craft/jsoup-learning/</a></p>\n</div>","description":"2013-08-31 08:24","name":"Jsoup代码解读之八-防御XSS攻击","type":"text"}],"name":"jsoup","type":"dir"},{"contents":[{"contents":"<h2>freemarker源码解读之一--概述</h2><div class=\"BlogContent\">\n <p>最近在思考为如何xsoup添加自定义函数支持，基于这个目的，想起了最常用的模板引擎freemarker。于是down了源码下来，开始浏览一番。本文基于<a href=\"https://github.com/freemarker/freemarker\" rel=\"nofollow\">https://github.com/freemarker/freemarker</a>上的2.3.20版本。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>思考</h2> \n <p>看源码前，先思考一下，一个模板引擎，到底需要哪些东西？一门模板引擎其实是一个完整的语言，只不过它只具有单纯的输入/输出，不需要考虑其他的功能。</p> \n <ul> \n  <li><p>语法解析，转换为AST(抽象语法树)</p> </li> \n  <li><p>语义分析，为AST附加上执行语义</p> </li> \n  <li><p>上下文环境的注入</p> </li> \n  <li><p>内置函数及外部函数支持</p> </li> \n  <li><p>其他外围机制(与框架/工具的集成等)</p> </li> \n </ul> \n <span id=\"OSC_h2_2\"></span> \n <h2>源码结构</h2> \n <p>打开freemarker的代码，core包里110个类一字排开，还有以下划线开头的“建议不要看”的类，看的人眼花缭乱啊！这一切都是因为Java规范的大师们，设计了一个“包级可见“的概念，大概就是，我写给自己用的代码，不要让你用！这一来，别人用是用不了了，好像看起来也变得很困难了…</p> \n <p>还好现在的IDE都很强大，刷刷两下就给重构了，把一些类按照类型挪到多个包里，顿时清爽很多！可惜好多类/方法/字段都是包级可见，为了让这个重构版freemarker没那么多红叉，lz加了好几百个public，写到意识都模糊了…最后把自己的劳动成果共享出来吧：<a href=\"https://github.com/code4craft/freemarker-learning\" rel=\"nofollow\">https://github.com/code4craft/freemarker-learning</a>。主要是将<strong>freemarker.core</strong>包里内容拆开了，语法树相关的内容放到了<strong>freemarker.core.nodes</strong>包，异常放到了<strong>freemarker.core.exception</strong>包，一些模板内置功能放到了<strong>freemarker.core.buildin</strong>包，还有工具类放到了<strong>freemarker.core.util</strong>包。</p> \n <p>顺便将freemarker的流程整理了一下：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0911/223131_moAu_190591.png\" alt=\"流程\" /></p> \n <p>这是一个很经典的模板引擎的执行流程：</p> \n <ul> \n  <li><strong>Configuration</strong>可以理解为一个工厂，它负责产生一个对外接口<strong>Template</strong>类。它首先会从cache中查找是否已经有编译好的Template，如果不存在，则对模板进行编译。</li> \n  <li><strong>Template</strong>实际上是一个带执行语义的语法树，树的节点是TemplateObject。</li> \n  <li><strong>FMParser</strong>是javacc生成的语法解析类，它最终输出是以FMParser.root()为根的语法树。</li> \n  <li><strong>dataModel</strong>是外部对模板引擎的数据输入，它会被转化为<strong>TemplateModel</strong>，并代入模板的渲染过程。</li> \n  <li>最后的步骤是根据数据，遍历编译好的语法树，并输出结果，这一步的入口时TemplateElement.accept()。</li> \n </ul> \n <span id=\"OSC_h2_3\"></span> \n <h2>关于JavaCC</h2> \n <p>freemarker使用了JavaCC(Java Compiler Compiler)做parser。关于JavaCC，有一篇很好的入门帖，顺带复习一下编译原理：LL(0)文法，消除左递归等东西。<a href=\"http://cs.lmu.edu/~ray/notes/javacc/\" rel=\"nofollow\">http://cs.lmu.edu/~ray/notes/javacc/</a></p> \n <p>JavaCC的下载在这里：<a href=\"http://javacc.java.net/\" rel=\"nofollow\">http://javacc.java.net/</a>，不知是我操作失误还是怎样，下载JavaCC-6.0之后，bin目录只有lib/javacc.jar文件。下载JavaCC-5.0src之后，才找到javacc脚本。难道就这么几百K的东西，还要搞增量更新？</p> \n <p>总之下载成功之后，用javacc FTL.jj，即可生成一堆Parser文件。核心是FMParser，解析完的语法树在FMParser.root()里。</p>\n</div>","description":"2013-09-11 22:51","name":"freemarker源码解读之一--概述","type":"text"}],"name":"freemarker","type":"dir"},{"contents":[{"contents":"<h2>monkeysocks开发日志--动机</h2><div class=\"BlogContent\">\n <blockquote> \n  <p>monkeysocks的目标是为开发以及测试提供一个稳定的环境。</p> \n </blockquote> \n <p>前几天听说公司的测试团队在鼓捣数据固化的东西，说白了就是在测试启动时构建一个临时性的数据库，操作完之后再销毁，这样的好处是不造成测试副作用，同时屏蔽环境的差异。</p> \n <p>但是目前公司内部SOA用的太多了，仅仅靠数据库固化明显不现实，公司的架构团队做了一个将所有remote service放到本地启动的东西，但是这样子启动开销有点难以接受。有没有更可行的方案？</p> \n <p>之前也有人做过一个单测的东西，可以将所有RPC调用的结果序列化成文本文件，下次调用时再序列化出来，这样其实就屏蔽了远程调用。但是Java语言层面的机制导致要把千奇八怪的对象序列化下来，本来就是不可完成的任务(有些对象本身就不是POJO，还有在getter、setter写逻辑的)。</p> \n <p>于是我有一个大胆的设想：其实Java的外部依赖无非是网络IO，就是TCP/UDP包嘛，那我能不能做一个工具，录制一个稳定环境的网络流量，然后固化下来，最终在调用时进行重放，岂不是一劳永逸？</p> \n <p>但是TCP/UDP毕竟是系统底层的东西，而且我想对每个Java进程单独做重放，所以只能从Java内部机制入手了。</p> \n <p>有两个方法：</p> \n <p>用cglib改写所有网络IO相关的接口，改用固化调用。</p> \n <p>设置Java全局socks代理，并启动socks server，在socks server里做代理。</p> \n <p>显然第二种方法更简单，有四两拨千斤的感觉！</p> \n <p>找到一个Java socks server，jsocks，最初版本比较老，google code上有一个改进版，用的是ant，因为以后要集成肯定要用maven，于是就做了点maven化的处理，考虑以后单独做成一个项目，现在先改了测试下可行性吧。<a href=\"https://github.com/code4craft/jsocks\" rel=\"nofollow\">https://github.com/code4craft/jsocks</a></p> \n <p>Java里面设置全局socksProxy的方法见<a href=\"http://docs.oracle.com/javase/6/docs/technotes/guides/net/proxies.html\" rel=\"nofollow\">http://docs.oracle.com/javase/6/docs/technotes/guides/net/proxies.html</a>。</p> \n <p>鼓捣一下，成功启动起来，明天先对公司的项目进行试用。</p>\n</div>","description":"2013-07-06 13:03","name":"monkeysocks开发日志--动机","type":"text"},{"contents":"<h2>monkeysocks开发日志--TCP协议分析及架构规划</h2><div class=\"BlogContent\">\n <blockquote> \n  <p>monkeysocks的目标是为开发以及测试提供一个稳定的环境。它使用socks代理，将录制网络流量并本地保存，并在测试时将其重放。</p> \n </blockquote> \n <span id=\"OSC_h2_1\"></span> \n <h2>jsocks的改造</h2> \n <p>首先对公司一个项目进行了代理，测试结果：从开始启动到完成，只有4.7M的网络流量，本地空间开销不是问题。</p> \n <p>今天把jsocks修改了下，将build工具换成了maven，并独立成了项目<a href=\"https://github.com/code4craft/monkeysocks/jsocks\" rel=\"nofollow\">https://github.com/code4craft/jsocks</a>。后来算是把record和replay功能做完了，开始研究各种协议replay的可能性。</p> \n <p>replay时候，如何知道哪个请求对应响应包是个大问题。开始的方式是把request报文的md5作为key，response作为value。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>TCP协议分析</h2> \n <p>后来使用wiredshark结合程序日志来进行分析。</p> \n <p>TCP协议栈大概是这样子： <br /><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fwww.skullbox.net%2Fdiagrams%2Ftcppacket.gif%3Fdur%3D673\" alt=\"image\" /></p> \n <p>下面是wiredshark抓包的截图，从ea开始才是应用层协议的内容。</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fcode4craft.github.io%2Fimages%2Fposts%2Ftcp-wiredshark.png\" alt=\"image\" /></p> \n <span id=\"OSC_h2_3\"></span> \n <h2>应用层协议分析</h2> \n <p>实现replay后，拿HTTP协议做了测试，自己用程序写了个URLConnection，倒是能够实现replay，但是换到浏览器里就很难了，因为cookie总是会有些不一样(现在基本上所有站点都会写cookie吧)。如果不对应用层协议本身进行分析，那么进行包的伪造就很难了。</p> \n <p>https协议对于重放攻击做了处理，每次的请求包都不一样，也无法replay成功，暂时略过。</p> \n <p>后来对于测试中得重点协议–mysql的协议，进行了研究。</p> \n <p>这是一个有状态的协议，状态转移图如下：</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fdev.mysql.com%2Fdoc%2Finternals%2Fen%2Fimages%2Fgraphviz-db6c3eaf9f35f362259756b257b670e75174c29b.png\" alt=\"image\" /></p> \n <p>详细介绍<a href=\"http://dev.mysql.com/doc/internals/en/client-server-protocol.html\" rel=\"nofollow\">http://dev.mysql.com/doc/internals/en/client-server-protocol.html</a>，有点hold不住的感觉啊！</p> \n <p>看了Authentication部分，会由server端发送一个随机数，来避免重放攻击。这个东西启发了我，因为主动权一般都是在server端，而我们要对client进行欺骗，难度就小了很多。</p> \n <span id=\"OSC_h2_4\"></span> \n <h2>架构设计</h2> \n <p>后来决定把架构解耦了，fake server单独作为一个模块，可以单独启动成TCP server，也可以加入到jsocks里。最后架构是这样子：</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fcode4craft.github.io%2Fimages%2Fposts%2Fmonkeysocks-arch.png\" alt=\"image\" /></p> \n <p>fake servers的实现必定是个大坑，不过能把常用协议都了解一遍，本身也很有意思不是么？</p> \n <span id=\"OSC_h2_5\"></span> \n <h2>开发计划：</h2> \n <ul> \n  <li><p>实现fake servers的TCP框架。</p> </li> \n  <li><p>研究并实现常用协议的fake server。</p> </li> \n  <li><p>确定持久化以及报文对应的策略。</p> </li> \n </ul>\n</div>","description":"2013-07-07 21:28","name":"monkeysocks开发日志--TCP协议分析及架构规划","type":"text"},{"contents":"<h2>用OpenResty和redis写了一个短域名服务</h2><div class=\"BlogContent\">\n <p>作为一个Java程序员，一旦别人说到c什么的，就不由为自己的孤陋寡闻而可耻。听闻了一个极好的高性能服务器OpenResty，基于nginx和lua扩展的，于是就来研究研究罢！</p> \n <p>鼓捣了一下午，写了一个基于OpenResty的短域名服务<a href=\"https://github.com/code4craft/moonlink\" rel=\"nofollow\">https://github.com/code4craft/moonlink</a>，存储用的是redis。分享几点入门经验：</p> \n <ul> \n  <li><p>OpenResty其实是诸多nginx扩展的打包集合，例如用到了<a href=\"http://wiki.nginx.org/HttpLuaModule\" rel=\"nofollow\">HttpLuaModule</a>，<a href=\"https://github.com/agentzh/lua-resty-redis\" rel=\"nofollow\">lua-resty-redis</a>。单独查OpenResty是查不到的！但是查对应的扩展模块就很好查，<a href=\"http://wiki.nginx.org/\" rel=\"nofollow\">nginx官方wiki</a>真心是个好东西。</p> </li> \n  <li><p>lua的多值返回不错，但是没有异常机制真心让人憋屈(或许我没遇到？)。</p> </li> \n  <li><p>把这个程序在OSX上跑了一下ab，1300qps左右，没有达到期望的几千几万，是不支持epoll的原因？</p> </li> \n  <li><p>Intellij的lua插件不太靠谱，用用代码高亮就行了。</p> </li> \n </ul>\n</div>","description":"2013-07-28 15:50","name":"用OpenResty和redis写了一个短域名服务","type":"text"}],"name":"开发日记","type":"dir"},{"contents":[{"contents":"<h2>IntelliJ IDEA使用心得</h2><div class=\"BlogContent\">\n <p>最近尝鲜试用了一下IntelliJ，使用下来还是比较爽的，最后我这个很少花钱买软件的人，也在oschina上买了个人版。IDE毕竟是码农干活的家伙，想想也值了。使用的时候有一些心得，记录下来。</p> \n <h3>调整界面为酷酷的黑色</h3> \n <p>Preferences=&gt;Appearance=&gt;theme=&gt;Darcula</p> \n <h3>检出项目:</h3> \n <p>VCS=&gt;Checkout From Version Control，maven项目会被自动识别出来。</p> \n <h3>设置快捷键：</h3> \n <p>Preferences=&gt;keymaps，有很多套方案，当然即使选择Eclipse也还是有很多和Eclipse不同的地方。</p> \n <h3>自动补全：</h3> \n <p>Mac下默认是clt+space，可以使用keymaps=&gt;Main menu=&gt;Code=&gt;Competion设置。比Eclipse好的地方是Spring、Maven的xml，乃至freemarker模板以及iBatis的sqlmap都支持高亮和自动补全。</p> \n <h3>去除自动补全的大小写敏感：</h3> \n <p>不知道多少童鞋和我一样被Eclipse惯坏了，使用自动补全完全不注意大小写的，IntelliJ默认区分大小写，很是让人难过。不过在Editor=&gt;Code Completion里把Case sensitive completion设置为None就可以了。</p> \n <h3>自动展开目录</h3> \n <p>Eclipse有个打开文件就自动展开目录的功能，在IntelliJ里从Project左边栏的齿轮上选择Autoscroll to Source和Autoscroll from Source都勾选上即可。</p> \n <h3>使用Tomcat运行web项目：</h3> \n <p>需安装插件：Tomcat and TomEE intergration</p> \n <p>选择Run=&gt;Edit Configurations，点+，选tomcat server，Deloyment选择对应artifact。详细文章：<a href=\"http://my.oschina.net/tsl0922/blog/94621\" rel=\"nofollow\">http://my.oschina.net/tsl0922/blog/94621</a></p> \n <h3>项目间文件复制</h3> \n <p>IntelliJ里的工作空间是Project，不同Project之间是没有什么关系的。在一个Project里copy&amp;paste，会弹出对话框，让你选择<strong>目标文件夹</strong>。也就是说，并没有跨Project的复制，而是从源Project把文件复制出去。</p> \n <h3>自动编译</h3> \n <p>IntelliJ默认是不会自动编译项目的，所以在run之前会有个make的过程，习惯自动编译项目的可以在这里打开：Compiler=&gt;make project automatically。因为IntelliJ项目空间不大，所以开启之后也不会像Eclipse一样出现build workspace很久的情况。</p> \n <h3>Debug</h3> \n <p>debug最好不要使用method breakpoint，会导致启动异常缓慢，博主之前就不小心启动了method breakpoint，然后进入调试要花掉几分钟的时间。IntelliJ断点可以设置Condition，其实Eclipse也可以，只不过没有这么明显，同时IntelliJ可以在Condition进行代码提示。</p> \n <h3>远程Debug</h3> \n <p>Run=&gt;Edit Configurations，选择Add=&gt;remote，然后你懂的。</p> \n <h3>File Template</h3> \n <p>与Eclipse的Code Template类似，只不过IntelliJ内置变量全部为大写，例如：${NAME}。可以使用#parse(“File Header.java”)这种格式来导入另一个文件，跟jsp include的作用一样，实现复用的一种方式吧。没有导入/导出，有点不太方便。</p> \n <h3>Live Template</h3> \n <p>用惯了Eclipse快捷键的人可能会不习惯，sysout、foreach等快捷方式找不到了，main方法也无法自动补全了，其实这个在IntelliJ中有一个异常强大的模块Live Template来实现。</p> \n <p>例如，在class中尝试psvm+tab，则会发现main方法产生了；输入iter+tab，则生成了foreach语句。 <br />live template还有一个surround的用法，选中某个变量，键入ctl+alt+j两次，则会出现自动补全的菜单。</p> \n <p>此外，还可以自定义Live Template。Code Snippet技术应用也挺普遍的，IntelliJ的Live Template优点是内置了一些智能的变量和函数，可以做到一些语义级别的分析和运用。</p> \n <h3>几句牢骚</h3> \n <p>IDE的圣战从来没有停止过，Eclipse还是IntelliJ好？首先，IntelliJ某些更加体贴的功能，让我感叹一分钱一份货。比如选中括号的后面部分，即使滑动到了下一屏，也会将括号开始的部分浮动显示出来。更重要的，我想引用一下《大教堂与集市》中的比喻，Eclipse好比集市，有开放的环境，本身功能并不求全责备，通过插件来提供相应的功能(最基本的maven、VCS都需要第三方插件提供)。相对的，IntelliJ就像大教堂，内部整合了大多数功能，基本上是一体化的使用设计。</p> \n <p>庞大的插件机制和依赖也使得Eclipse出现一些混乱和不稳定。插件依赖/兼容性/稳定性都存在一些问题，而且Eclipse一味向可扩展设计的方式也使得使用起来会更复杂。例如，Eclipse的快捷键设置功能，全部是一字平铺，有一个&quot;when&quot;的选项，我理解这是使用快捷键的一个场景。问题是，所有插件都可以向它注册一个场景，当我真要选择when的时候，发现列表有两页之长，我哪知道选哪个？相反，IntelliJ的keymap采用了分类的方式，一级分类就是使用场景，然后再进入相应项设置快捷键，比Eclipse方便的多。再比如，有人说Eclipse慢，其实很可能并不是内核慢，而是一些插件(例如m2e)运行太慢导致的。而IntelliJ基本上都是很迅速的，很少出现失去响应的情况。</p> \n <p>这里我想引用一篇文章《有人负责，才有质量：写给在集市中迷失的一代》<a href=\"http://www.oschina.net/news/32190/a-generation-list-in-the-bazaar\" rel=\"nofollow\">http://www.oschina.net/news/32190/a-generation-list-in-the-bazaar</a>。Eclipse庞大的体系注定了插件管理的松散性，所以使用者就要忍受一些不稳定和不方便的因素。相比IntelliJ，因为是公司开发，大部分插件都在其管理范围之内，所以整体质量更好控制。</p> \n <p>说到这里好像就认定IntelliJ好了？其实也未必，因为《大教堂与集市》也提到，开源带来的生产力是教堂式开发远不能比的，所以IntelliJ要收费，而Eclipse可以免费。Eclipse庞大的插件群，功能的全面性，个人觉得也是IntelliJ比不了的。</p> \n <p>最后说一句，说到学习成本，其实IntelliJ是要比Eclipse低的，至少省去了很多配置插件、理清依赖、处理问题的功夫，同时设置也比Eclipse要简单不少。没有说越高级的IDE越复杂的说法，只是Eclipse作为最常用的Java IDE，让大家先入为主了罢了。</p>\n</div>","description":"2013-04-17 22:34","name":"IntelliJ IDEA使用心得","type":"text"},{"contents":"<h2>Intellij使用心得(二)</h2><div class=\"BlogContent\">\n <p>使用Intellij一段时间了，仍然遇到一些不顺手的地方，自己也做了一些定制。就启动内置的Web服务器来说吧(主要说用Tomcat作为容器)。</p> \n <span id=\"OSC_h3_1\"></span> \n <h3>关于停止Tomcat</h3> \n <p>停止Tomcat有两个选项：<code>Stop</code>(红块)和<code>Kill process</code>(骷髅)。熟悉Linux信号量的都懂的，一个是kill -term，一个是kill -9。但是<code>Kill process</code>是点击<code>Stop</code>之后才可选的，个人认为多此一举，测试环境呢直接<code>Kill process</code>也无所谓的。因为项目复杂的时候，有时<code>Stop</code>不掉也是挺正常的，还可能会留点坑。</p> \n <span id=\"OSC_h3_2\"></span> \n <h3>port 1099 already in bind</h3> \n <p>Intellij启动Tomcat的时候，会启动1099作为JMX端口。所以如果同时启动多个Tomcat实例，这个端口是会冲突的。如果确实要启动多个实例，倒是可以换用不同的端口，但是更多的情况是：我打开了两个Project，前面一个Project的Tomcat我没关掉，然后下一个自然启动不起来。跟前面说的一样，基本上要养成先Stop再Kill的好习惯，反正我是如此…</p> \n <span id=\"OSC_h3_3\"></span> \n <h3>修改静态资源实时生效</h3> \n <p> \n  <strike> \n   <br />用惯了Eclipse的Tomcat插件的同学都知道，在修改源代码后，如果修改的是静态文件，会自动拷贝到工作目录，从而避免重新打包和启动漫长的过程。而Intellij是不会动态拷贝的，只有手动重新启动。 \n  </strike></p> \n <strike> \n  <p>有一个办法可以解决这个问题。选择Project Structure=&gt;Artifacts=&gt;appname:war exploded，将Output Directory设置为项目的src/main/webapp目录，同时在Run=&gt;Edit Configuration，选择这个exploded的Artifact就行了！</p> \n </strike> \n <p> \n  <strike>\n    缺点是有时候配置会丢失，如果发现那次无法实时修改了，再去改一次吧！ \n  </strike></p> \n <p>其实有个更方便的方法，在Run=&gt;Edit Configuration里，选择<code>On Frame Deactivation</code>，Intellij会在窗口失去焦点的时候，重新部署静态文件！感受到了高科技有木有！</p>\n</div>","description":"2013-06-05 17:38","name":"Intellij使用心得(二)","type":"text"},{"contents":"<h2>Intellij使用心得(三)</h2><div class=\"BlogContent\">\n <p>有童鞋跟我说，他有强迫症，换到Intellij，各种<code>waring</code> <code>error</code>，红的黄的一堆，让人头大啊有没有！首先说一句，Intellij的错误检查更丰富更严格，有的时候确实是代码不规范引起的问题，这个时候检查一下代码是比较好的。但是有些错误，可能确实有点“智能过了头”。例如Intellij会对Spring的bean做检查，如果在xml或者注解里引用了不存在的bean，它会出错误提示，但是实际上我们的bean是runtime生成的(例如iBatis的dao)，这个时候它还会提示<code>error</code>，就有点让人讨厌了。怎么关掉这些东东？在<code>Inspections</code>菜单里可以对错误提示进行修改。</p> \n <p>下面列几个常用的修改：</p> \n <ul> \n  <li><p>取消未使用public方法的warning。用struts的都知道，Action里会有很多并不在代码里调用的getter和setter方法。Intellij默认会对这种方法做<code>warning</code>，这样子满满一瓶<code>warning</code>也挺焦虑的。可以在Inspections=&gt;Declaration redundancy里关掉Unused declaration。</p> </li> \n  <li><p>取消bean的检查。如上所说，有些runtime生成bean，Intellij会标记为<code>error</code>，这实在太奇怪了！Inspections=&gt;Spring Model=&gt;Autowiring for Bean Class，可以关掉@autowire的字段。xml里的可以通过Inspections=&gt;Spring Model=&gt;Spring Model关闭。</p> </li> \n </ul> \n <p>其他的大家可以点击<code>warning</code>提示，再对应到Inspections菜单去进行搜索，应该也不难找到。</p>\n</div>","description":"2013-06-07 13:19","name":"Intellij使用心得(三)","type":"text"},{"contents":"<h2>Intellij使用心得(四)</h2><div class=\"BlogContent\">\n <p>对于一个团队来说，使用统一的代码格式是非常重要的，否则在使用版本控制工具时，会出现大量的冲突。在Eclipse里，我们可以通过一些xml来进行代码格式的统一，但是这些文件要应用在Intellij里，还是要费一点周折的。不过如果你跟博主一样，有过合并一个文件出现200个冲突的惨痛经历之后，就会觉得这个工作是值得的了。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>方法</h2> \n <p>一般我们使用Eclipse会统一的<code>code-style.xml</code>文件。Intellij里无法直接导入这个文件，不过有一个插件<code>Eclipse Code Formatter</code>可以完成这个任务。</p> \n <ul> \n  <li><span id=\"OSC_h3_2\"></span><h3>安装插件：</h3> <p>选择Preferences=&gt;Plugins=&gt;Browse repositories，搜索Eclipse即可出现，点击左上角的<code>Download and Install</code>安装。安装之后重启Intellij，即可在Preferences=&gt;Eclipse Code Formatter找到配置项。</p> </li> \n  <li><span id=\"OSC_h3_3\"></span><h3>配置插件：</h3> <p>选择Preferences=&gt;Eclipse Code Formatter，勾选<code>Use the Eclipse-code-formatter</code>，并在<code>Eclipse Java Formatter config file</code>选择Eclipse用的<code>code-style.xml</code>文件，这个选项会决定格式化代码的方式。同时配置<code>Import order</code>的<code>From File</code>也为Eclipse用的<code>code-style.xml</code>文件，这个选项会决定组织import区域的方式。</p> </li> \n  <li><span id=\"OSC_h3_4\"></span><h3>使用插件</h3> <p>使用Intellij的格式化快捷键&quot;Ctrl+shift+F&quot;即可进行格式化。如果出错会输出提示到Event Log里，如果看到'xxx formatted sucessfully by Eclipse code formatter'则表示格式化成功！</p> <p><strong>补充一个小技巧，一般建议只格式化自己的代码，不进行全文件格式化，选择自己的代码块再使用&quot;Ctrl+shift+F&quot;即可部分格式化。</strong></p> </li> \n  <li><span id=\"OSC_h3_5\"></span><h3>测试</h3> <p>博主在Intellij IDEA12下测试<code>Eclipse Code Formatter</code>可用，并且和Eclipse 3.5同时使用一个code-template.xml，编辑同一个文件，没有出现冲突。</p> </li> \n </ul> \n <p>最后说一件稍微无关的事情，博主团队使用git作为版本控制工具，并且已经出现了这种格式化的惨剧，结果尝试使用<code>git merge alpha -Xignore-space-change</code>忽略空格差异进行merge，结果本地merge是成功了，提交之后其他人拉到本地都会出现冲突！最后只能回滚合并，人肉检查代码并重现解决，可见“解铃还须系铃人”这话是有道理的！任何小聪明都是有风险滴！</p>\n</div>","description":"2013-06-14 17:13","name":"Intellij使用心得(四)","type":"text"},{"contents":"<h2>初识Intellij 插件开发</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>走进IDE的世界</h2> \n <p>做Intellij插件开发是个比较麻烦的事，最大的问题就是社区不成熟，而插件开发本来也是松散的知识点居多，所以难免让人觉得举步维艰。</p> \n <p>比较好的参考资料是JetBrains官方的文档，但是内容仍然太少，如果想只依靠它开发，那是有相当的难度。</p> \n <p>所幸Intellij的community版本是开源的，这就表示：<strong>其实你可以通过看源码来了解如何开发！</strong>这听起来有点疯狂，但是如果付出足够的时间，这可能是最有效的方法。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>编译community代码</h2> \n <p>Intellij-community的源码在<a href=\"https://github.com/JetBrains/intellij-community\" rel=\"nofollow\">https://github.com/JetBrains/intellij-community</a>。没什么技巧，clone下来就可以了。这是个艰难的过程，我是半夜挂了一晚才下载好的。</p> \n <p>下载好源码，还需要编译才能使用。先<code>git tag</code>选择一个合适的版本，例如<code>idea/129.1521</code>，这是截止本文时候，IDEA 12的最新版。</p> \n <p>然后用Ant编译之：<code>ant</code>。过程依然很漫长。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>使用Intellij开发插件</h2> \n <p>编译完成，先不着急。这个编译好的Intellij会作为容器，这是我们开发插件的运行环境。但是我们插件的开发环境，我们依然可以使用平时使用顺手的Intellij版本。之后新编译好的community为SDK，并附加上源码，此时就可以顺畅的开发了。</p> \n <span id=\"OSC_h2_4\"></span> \n <h2>Intellij SDK一览</h2> \n <p>Intellij SDK由一系列依赖组成。Intellij里集成了一些常用的开源库，例如guava，httpclient，netty等等，而插件开发相关主要的API在<code>openapi.jar</code>里。openapi的结构是按照功能模块组织的，相应的概念比较多，但是大部分都不算太复杂。</p> \n <span id=\"OSC_h2_5\"></span> \n <h2>开发第一个插件</h2> \n <p>这里还是推荐一下官方的一个demo，是一个基于生成基于Guava API的compare方法的工具：</p> \n <p>视频： <br /><a href=\"http://blog.jetbrains.com/idea/2012/12/webinar-recording-live-coding-a-plugin-from-scratch/\" rel=\"nofollow\">http://blog.jetbrains.com/idea/2012/12/webinar-recording-live-coding-a-plugin-from-scratch/</a></p> \n <p>代码： <br /><a href=\"https://github.com/yole/comparisonChainGen\" rel=\"nofollow\">https://github.com/yole/comparisonChainGen</a></p> \n <span id=\"OSC_h3_6\"></span> \n <h3>Action</h3> \n <p>其实初学插件开发，80%时间都在做一件事：寻找扩展点。</p> \n <p>例如我要在菜单里加一个button，那么这个button按照什么规范写，放到什么地方？</p> \n <p><code>Action</code>是Intellij插件的入口，它可能是一个button，一个菜单项等等。用户操作了这部分控件，就会触发Action。开发第一个Action很简单，实现<code>AnAction</code>接口即可。Action的入口有一个<code>Group</code>，Group可以理解为插件留给其他插件的扩展点，每个group有一个<code>group-id</code>。例如菜单有<code>Menu</code>，工具栏有<code>MainToolBar</code>，等等。可惜这些个文档不太全，怎么办呢？</p> \n <p>这个时候源码就派上用场的了。假设我们想要在工具栏添加一个按钮，但是我们不知道group-id。那么可以先随便添加一个id，然后debug，不出意外就抛出异常了，然后我们通过断点，顺藤摸瓜，找到可用的Group，再分析可能的group-id，然后测试，如此往复…</p> \n <span id=\"OSC_h3_7\"></span> \n <h3>Extension</h3> \n <p>如果说Action是主动触发的扩展点，那么Extension则是在插件的运行过程中，被动插入的扩展点。</p> \n <p>例如execution模块负责Java程序的启动和debug，它预留了扩展点<code>java.programPatcher</code>，用于在启动之前，修改启动参数。</p> \n <pre class=\"brush: xml; auto-links: false;\">&lt;extensions defaultExtensionNs=&quot;com.intellij&quot;&gt;\n     &lt;java.programPatcher implementation=&quot;com.dianping.idea.mocksocks.MocksocksRunPatcher&quot;/&gt;\n  &lt;/extensions&gt;</pre> \n <p>就写到这吧，Intellij 插件开发资料实在太少，做东西有点艰难，写个文章记录一下。</p>\n</div>","description":"2014-02-28 18:18","name":"初识Intellij 插件开发","type":"text"}],"name":"Intellij","type":"dir"},{"contents":[{"contents":"<h2>使用JRebel进行Java Web项目的热部署</h2><div class=\"BlogContent\">\n <p>在日常的Java开发中，如果我们需要调试一个Java Web项目，就需要先将项目编译之后，打包并放入Web容器中运行。如果对Java代码进行了修改，那么必须重新编译并重启Web容器。在改动频繁、或者需要反复调试的项目中，重新编译和重启的过程就显得特别麻烦。那么Java是否能够像动态语言一样，修改即生效呢？JRebel(<a href=\"http://zeroturnaround.com/software/jrebel/\" rel=\"nofollow\">http://zeroturnaround.com/software/jrebel/</a>)就是这样的一个解决方案。JRebel是一个收费软件，可以申请14天的试用版。也有个免费的版本myRebel<a href=\"https://my.jrebel.com/plans\" rel=\"nofollow\">https://my.jrebel.com/plans</a>。可以绑定facebook或者twitter账号申请一个Social版本的，有一年的试用期。</p> \n <h2>原理</h2> \n <p>JRebel的原理大概是这样：</p> \n <p>它使用JDK 1.5新增的JVM参数-javaagent启动。代理 (agent) 是在你的main方法前的一个拦截器 (interceptor)，也就是在main方法执行之前，执行agent的代码。对javaagnet感兴趣的可以看看这篇官方说明<a href=\"http://docs.oracle.com/javase/6/docs/api/java/lang/instrument/package-summary.html\" rel=\"nofollow\">http://docs.oracle.com/javase/6/docs/api/java/lang/instrument/package-summary.html</a>，再此就不展开了。</p> \n <p>启动之后，JRebel会监控IDE里项目的目标编译目录和源码目录(这个需要在rebel.xml里配置，以下会讲到)，一旦发生改变，就重新装载类并替换。这就达到了动态生效的效果。与动态语言不同的是，它依然是先需要进行编译的，所以如果修改后编译不通过，那么也无法进行替换。</p> \n <h2>使用</h2> \n <p>下面以Eclipse和Tomcat为例，介绍如何在使用JRebel。 <br />首先下载Eclipse插件，这里推荐使用离线包<a href=\"http://www.zeroturnaround.com/update-site/update-site.zip\" rel=\"nofollow\">http://www.zeroturnaround.com/update-site/update-site.zip</a>。下载完后，使用Eclipse的&quot;Install New Software”，选择Add-&gt;Archive，并选择下载好的压缩包，即可安装。(这里介绍一个Eclipse安装的小技巧：如果使用Eclipse安装插件总是会很慢，这里将&quot;Contact all update sites during install to find required software&quot;勾选去掉，则省去了长时间的依赖检查过程。) <br /><img src=\"http://static.oschina.net/uploads/space/2013/0107/115143_OFhA_190591.jpg\" alt=\"在此输入图片描述\" /> <br />安装完后，下载JRebel核心包<a href=\"http://zeroturnaround.com/software/jrebel/download/prev-releases/\" rel=\"nofollow\">http://zeroturnaround.com/software/jrebel/download/prev-releases/</a>。下载后解压到一个文件夹，这里以E:\\jrebel为例。</p> \n <p>同时，打开Eclipse的Preferences，将JRebel的路径配置为E:\\jrebel\\jreble.jar(替换成你下载的地址)。 <br /><img src=\"http://static.oschina.net/uploads/space/2013/0107/115557_lGkW_190591.jpg\" alt=\"在此输入图片描述\" /></p> \n <h2>在项目中配置JRebel</h2> \n <p>使用JRebel Eclipse插件之后，在项目中使用JRebel基本是零配置的–在项目中选择JRebel-&gt;Add JRebel Nature就可以了。JRebel的核心配置文件是rebel.xml，这在最新版的Eclipse插件里已经可以自动生成，无需配置。如果需要手工配置，可以选择Advanced Properties，Generate XML，然后会生成rebel.xml到src/main/resouces目录下。这里有两个配置项，其中classpath对应编译好的文件的位置，web对应源码的位置，一般不需要更改。</p> \n <p> <br /> </p> \n <pre class=\"brush: java; auto-links: false;\">&lt;classpath&gt;\n    &lt;dir name=&quot;${rebel.workspace.path}/webapp/target/classes&quot;&gt;\n    &lt;/dir&gt;\n&lt;/classpath&gt;\n\n&lt;web&gt;\n    &lt;link target=&quot;/&quot;&gt;\n        &lt;dir name=&quot;${rebel.workspace.path}/webapp/src/main/webapp&quot;&gt;\n        &lt;/dir&gt;\n    &lt;/link&gt;\n&lt;/web&gt;</pre> \n <p></p> \n <p>最后，如果使用了Tomcat插件，则双击Server，打开Server Overview，同时在JRebel Integration里勾选&quot;Enable JRebel Agent&quot;即可。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0107/115616_THUO_190591.jpg\" alt=\"在此输入图片描述\" /></p> \n <p>如果单独部署Tomcat，则需要手动生成reble.xml，并且在Tomcat的JVM参数中加上以下参数：</p> \n <pre class=\"brush: java; auto-links: false;\">-Drebel.spring_plugin=true 支持spring框架\n-Drebel.aspectj_plugin=true 支持aspectj\n-Drebel.struts2_plugin=true 支持strut2\n-javaagent:E:\\jrebel\\jrebel.jar 这里自行修改jrebel.jar正确的路径\n-noverify</pre> \n <p>至此，配置完成。如果Tomcat启动时提示</p> \n <pre class=\"brush: java; auto-links: false;\">\\#######################################################\nJRebel xxx (201202291303)\n(c) Copyright ZeroTurnaround OU, Estonia, Tartu.</pre> \n <p>则表示配置成功。</p> \n <h2>性能</h2> \n <p>后来跟同事进行过一些交流，反应说，JRebel很早就有了，但是老版本使用之后，导致Tomcat启动时间增加了不止一倍，同时容易崩溃，后来就不用了。但是发展到JRebel5之后，性能和稳定性方面是否有提升？这里我做了一个测试，以一个实际开发的项目为例：</p> \n <table> \n  <tbody> \n   <tr> \n    <td>类型</td> \n    <td>Tomcat启动时间(ms)</td> \n   </tr> \n   <tr> \n    <td>jrebel 4.6</td> \n    <td>18538</td> \n   </tr> \n   <tr> \n    <td>jrebel 5.1.2</td> \n    <td>21836</td> \n   </tr> \n   <tr> \n    <td>直接启动</td> \n    <td>14367</td> \n   </tr> \n  </tbody> \n </table> \n <p>仍然是可以接受的。稳定性尚待考证。</p>\n</div>","description":"2013-01-07 13:41","name":"使用JRebel进行Java Web项目的热部署","type":"text"},{"contents":"<h2>qmail队列清理问题</h2><div class=\"BlogContent\">\n <p>今天跑测试的时候，发现qmail队列把磁盘写满了。删除/var/qmail/queue之后，发现无法正常运行。网上找到一个qmail-remove，运行之后发现也未删除成功。后来找到，原来是缺少/var/qmail/queue/lock/sendmutex文件。于是写了一个脚本，可自动删除qmail队列。</p> \n <pre class=\"brush: java; auto-links: false;\">#!/bin/sh\nfind /var/qmail/queue/ -type f -exec rm {} \\;\ntouch /var/qmail/queue/lock/sendmutex\nchown qmails.qmail /var/qmail/queue/lock/sendmutex</pre>\n</div>","description":"2013-01-09 14:17","name":"qmail队列清理问题","type":"text"},{"contents":"<h2>Struts2配置实践一则</h2><div class=\"BlogContent\">\n <p>之前一直使用spring-mvc，现在新公司改用struts2。因为hackthon项目要独自搭一套环境，不想引入一些公司的框架，于是尝试自己配置一套struts2，遇到了一些问题：</p> \n <h4>web.xml</h4> \n <p>这里/config/struts/struts.xml位于/WEB-INF/classes/目录下。值得注意的是，struts的配置似乎不支持spring的classpath*:风格的配置。</p> \n <pre class=\"brush: java; auto-links: false;\">&lt;filter&gt;\n        &lt;filter-name&gt;struts&lt;/filter-name&gt;\n        &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;\n        &lt;init-param&gt;\n            &lt;param-name&gt;config&lt;/param-name&gt;\n            &lt;param-value&gt;struts-default.xml,struts-plugin.xml,/config/struts/struts.xml&lt;/param-value&gt;\n        &lt;/init-param&gt;\n    &lt;/filter&gt;\n\n    &lt;filter-mapping&gt;\n        &lt;filter-name&gt;struts&lt;/filter-name&gt;\n        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n    &lt;/filter-mapping&gt;\n\n    &lt;listener&gt;\n        &lt;listener-class&gt;org.apache.struts2.dispatcher.ng.listener.StrutsListener&lt;/listener-class&gt;\n    &lt;/listener&gt;</pre> \n <h4>struts.xml：</h4> \n <pre class=\"brush: java; auto-links: false;\">&lt;?xml version=&quot;1.0&quot; encoding= &quot;UTF-8&quot;?&gt;\n&lt;!DOCTYPE struts PUBLIC\n    &quot;-//Apache Software Foundation//DTD Struts Configuration 2.0//EN&quot;\n    &quot;http://struts.apache.org/dtds/struts-2.0.dtd&quot; &gt;\n\n&lt;struts&gt;\n       &lt;!--\n            use in develop environment\n      --&gt;\n       &lt;constant name=&quot;struts.devMode&quot; value=&quot;false&quot; /&gt;\n       &lt;constant name=&quot;struts.enable.DynamicMethodInvocation&quot; value=&quot;false&quot; /&gt;\n       &lt;constant name=&quot;struts.ognl.allowStaticMethodAccess&quot; value=&quot;true&quot; /&gt;\n       &lt;constant name=&quot;struts.objectFactory&quot; value=&quot;org.apache.struts2.spring.StrutsSpringObjectFactory&quot; /&gt;\n        &lt;package name=&quot;imcaptcha&quot; namespace=&quot;/&quot; extends=&quot;json-default&quot;&gt;\n            &lt;default-action-ref name=&quot;index&quot; /&gt;\n            &lt;action name=&quot;validate&quot; class=&quot;us.codecraft.imcaptcha.action.ValidateAction&quot;&gt;\n                &lt;result name=&quot;success&quot; type=&quot;json&quot;&gt;&lt;/result&gt;\n                &lt;result name=&quot;error&quot; type=&quot;json&quot;&gt;&lt;/result&gt;\n            &lt;/action&gt;\n            &lt;action name=&quot;image&quot; class=&quot;us.codecraft.imcaptcha.action.ImageAction&quot;&gt;\n                &lt;result name=&quot;success&quot; type=&quot;json&quot;&gt;&lt;/result&gt;\n                &lt;result name=&quot;error&quot; type=&quot;json&quot;&gt;&lt;/result&gt;\n            &lt;/action&gt;\n       &lt;/package&gt;\n&lt;/struts&gt;</pre> \n <p>这里介绍一下，struts是完全插件化的设计，例如我需要引入struts-spring-plugin，只需将struts.xml中加入一行 <br />就可以了。但是struts有个不太人性化的地方：如果只进行了配置，而没有引入相关jar包(对应类不存在)，它不会像spring一样提示ClassNotFoundError，而是会和一般配置出错一样，抛出如下异常：</p> \n <pre class=\"brush: java; auto-links: false;\">at java.lang.Thread.run(Thread.java:722)\n13-01-17 10:13:14,650 ERROR org.apache.struts2.dispatcher.Dispatcher(CommonsLogger.java:27) ## Dispatcher initialization failed\nUnable to load configuration. - [unknown location]\n    at com.opensymphony.xwork2.config.ConfigurationManager.getConfiguration(ConfigurationManager.java:58)\n    at org.apache.struts2.dispatcher.Dispatcher.init_PreloadConfiguration(Dispatcher.java:374)\n    at org.apache.struts2.dispatcher.Dispatcher.init(Dispatcher.java:418)\n    at org.apache.struts2.dispatcher.ng.InitOperations.initDispatcher(InitOperations.java:69)\n    at org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter.init(StrutsPrepareAndExecuteFilter.java:51)\n    at org.apache.catalina.core.ApplicationFilterConfig.initFilter(ApplicationFilterConfig.java:273)\n    at org.apache.catalina.core.ApplicationFilterConfig.getFilter(ApplicationFilterConfig.java:254)\n    at org.apache.catalina.core.ApplicationFilterConfig.setFilterDef(ApplicationFilterConfig.java:372)\n    at org.apache.catalina.core.ApplicationFilterConfig.&lt;init&gt;(ApplicationFilterConfig.java:98)\n    at org.apache.catalina.core.StandardContext.filterStart(StandardContext.java:4584)\n    at org.apache.catalina.core.StandardContext$2.call(StandardContext.java:5262)\n    at org.apache.catalina.core.StandardContext$2.call(StandardContext.java:5257)\n    at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n    at java.lang.Thread.run(Thread.java:722)</pre> \n <p>下面的信息表示某个Action没有配置，如果你真的没有配action，那么是正常的，否则就是配置文件没有读取到。</p> \n <pre class=\"brush: java; auto-links: false;\">at java.lang.Thread.run(Thread.java:722)\nThere is no Action mapped for namespace / and action name . - [unknown location]\n    at com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:178)\n    at org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:61)\n    at org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)\n    at com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:47)\n    at org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:478)\n    at org.apache.struts2.dispatcher.ng.ExecuteOperations.executeAction(ExecuteOperations.java:77)\n    at org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter.doFilter(StrutsPrepareAndExecuteFilter.java:91)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:240)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:164)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:462)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:164)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:100)\n    at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:563)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:403)\n    at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:301)\n    at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:162)\n    at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:140)\n    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:309)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n    at java.lang.Thread.run(Thread.java:722)</pre>\n</div>","description":"2013-01-17 10:27","name":"Struts2配置实践一则","type":"text"},{"contents":"<h2>ftp服务器pure-ftpd配置心得</h2><div class=\"BlogContent\">\n <p>今天弄了个VPS，总是使用scp上传文件也麻烦，就想搭个FTP服务器。貌似广泛应用的是vsftpd，但是我安装后运行老是出错，不得已，换了另外一个：pure-ftpd。</p> \n <p>还好基本是零配置的，只要加用户就行了，配置如下：</p> \n <pre class=\"brush: java; auto-links: false;\">groupadd ftpgroup\n\nuseradd -g ftpgroup -d /dev/null -s /etc ftpuser\n\npure-pw useradd test1 -u ftpuser -d /home/ftpusers/test1\n\npure-pw mkdb\n\npure-pw passwd test1\n\npure-pw mkdb\n\npure-pw show test1</pre> \n <p>添加用户后，仍不生效。后来发现，需要将db文件软连接过去。</p> \n <pre class=\"brush: java; auto-links: false;\">cd /etc/pure-ftpd/auth\n\nln -s /etc/pure-ftpd/conf/PureDB 50pure</pre> \n <p>至此配置完成！</p>\n</div>","description":"2013-01-21 17:06","name":"ftp服务器pure-ftpd配置心得","type":"text"},{"contents":"<h2>【整理】国内一些大公司的开源项目</h2><div class=\"BlogContent\">\n <p>昨天看阿里的MetaQ文档，感觉对于消息系统的理解，比起大多数文章都要出色得多了，有些分析也非常的有实用性。估计还有很多优秀的项目没被发掘，于是就调研了一下，国内一些大公司的开源项目。</p> \n <h3>阿里</h3> \n <p>阿里的开源项目很多，这也跟@淘宝正明的开源态度密不可分。有很多重量级的项目，例如LVS、Tengine，或者很有实践价值的中间件，例如MetaQ(分布式消息系统)、dubbo(RPC框架)、cobar(数据库中间件)，或者是Java世界的工具，例如druid、fastjson。都说国内Java公司的技术架构大部分来自阿里系，我觉得一方面来自阿里员工，一方面也可以来自阿里的开源项目。</p> \n <p>地址有几个：</p> \n <p><a href=\"http://code.alibabatech.com/wiki/dashboard.action\" rel=\"nofollow\">http://code.alibabatech.com/wiki/dashboard.action</a></p> \n <p><a href=\"https://github.com/alibaba\" rel=\"nofollow\">https://github.com/alibaba</a></p> \n <p>阿里的前端也挺活跃的，比较有名的就是seajs和kissy了。</p> \n <h3>腾讯</h3> \n <p>腾讯和百度都只有前端团队有不少的开源项目(可能有个人或者一些团队的项目，没有找到)。</p> \n <p>js我也不熟悉，这个是腾讯前端团队的github，比较活跃： <br /><a href=\"https://github.com/AlloyTeam\" rel=\"nofollow\">https://github.com/AlloyTeam</a></p> \n <p>有webqq的前端框架jx，一个图片处理工具AlloyPhoto，还有一个跨平台的抓包工具Rythem。</p> \n <h3>百度</h3> \n <p><a href=\"https://github.com/baidufe\" rel=\"nofollow\">https://github.com/baidufe</a></p> \n <p>主要是百度的前端框架Tangram。这个github近一年没有提交了，我提过一个issue，没有人理我，应该是没人维护的了。</p> \n <p><a href=\"https://github.com/ecomfe\" rel=\"nofollow\">https://github.com/ecomfe</a></p> \n <p>最近开源的<a href=\"https://github.com/ecomfe/echarts\" rel=\"nofollow\">echarts</a>。ecomfe这个团队倒是在github挺活跃的，包括一些开发的管理都在上面。</p> \n <h3>网易</h3> \n <p>网易有一些挺不错的开源项目，例如<a href=\"https://github.com/wangbin579/tcpcopy\" rel=\"nofollow\">tcpcopy</a>。</p> \n <p>最近比较火的是基于node的游戏框架pomelo。</p> \n <p>官方的github：<a href=\"https://github.com/netease\" rel=\"nofollow\">https://github.com/netease</a></p> \n <h3>新浪</h3> \n <p>新浪好像官方对待开源的态度比较不明确，连个官方地址都没有，但是有几个比较有名的开源项目都来自新浪，比如<a href=\"https://github.com/stvchu\" rel=\"nofollow\">memcachedb</a>和鸟哥的<a href=\"https://github.com/laruence/php-yaf\" rel=\"nofollow\">yaf</a>。新浪在国内的技术产出还是挺多的，推进了php和redis的应用。</p> \n <h3>搜狐</h3> \n <p>搜狐最近这几年技术方面的声音比较少，特别拉出来是因为最近在看的<a href=\"https://github.com/adyliu/jafka\" rel=\"nofollow\">Jafka</a>，项目写的不错，包名用的是com.sohu。看到这个，才知道搜狐也是Java阵营的一员。</p> \n <h3>豆瓣</h3> \n <p>作为一个文艺公司，豆瓣的开源项目相当多。豆瓣的主基因是python，有一个spark(类似hadoop的框架)的python实现dpark(感谢<a href=\"http://my.oschina.net/u/150292\" rel=\"nofollow\"></a><a href=\"http://my.oschina.net/u/150292\" target=\"_blank\" rel=\"nofollow\">@吴延赞</a> 纠正)。</p> \n <p><a href=\"https://github.com/douban\" rel=\"nofollow\">https://github.com/douban</a></p> \n <h3>大众点评</h3> \n <p>说到最后，不妨说说我在的公司大众点评(先厚颜无耻的认为是大公司吧！)。点评架构中间件的代码都托管到了github上<a href=\"https://github.com/dianping\" rel=\"nofollow\">https://github.com/dianping</a>，可以说是开源的，但是不怎么更新文档，也有些没有从公司业务中脱离出来，几个框架之间属于完全耦合的关系。直接拿来用是不用想了，如果有兴趣，倒是可以从中掘到点有价值的东西。</p> \n <p>比较重要的是RPC框架pigeon，消息队列swallow，基于zookeeper的配置管理平台lion，还有Java业务监控工具cat，还有前端框架<a href=\"https://github.com/kaelzhang/neuron\" rel=\"nofollow\">neuron</a>。</p> \n <p>还有一些新加入到开源行列的公司，例如58的Argo、360的Atlas、包括DNSpod的DNSpod-sr，虽然来头很大，动辄每天处理几亿请求，但是看github上的commits，寥寥无几，更多的是摆姿态而已。看源码学习学习可以，应用到生产环境，估计是不太敢的。</p> \n <p>统计下来，很多公司其实都只有前端项目开源比较活跃。这个能理解，毕竟前端相对来说，开源成本比较低。但另一个角度来看，虽然大公司的前端也很厉害，但是其实前端强不强跟公司规模没有必然的关系，小公司的前端也可能做的很棒。而支撑如此大的用户群和访问量的后端项目，这是没到一定规模的公司没法比的，这些东西可能更有学习价值一点。</p> \n <p>当然，公司的任务总是埋头赚钱，开不开源都无可厚非。我在这里不过是整理一些学习资料而已。因为之前关注不多，难免会有疏漏，以后会继续补充。</p>\n</div>","description":"2013-08-25 09:24","name":"【整理】国内一些大公司的开源项目","type":"text"},{"contents":"<h2>试用了一下腾讯出品的抓包工具Rythem</h2><div class=\"BlogContent\">\n <p>Mac下一直没有fiddler这样好用的抓包工具，Charles要收费，难免不爽，昨天调研国内项目的时候，看到腾讯开源了一款抓包工具Rythem，试用了一下，基本配置无问题，但是通配符方面不太搞的定。官方文档说支持通配符，但是测试了一下不太起作用，给提了一个issue，非常快就有人回复了，挺不错。<a href=\"https://github.com/AlloyTeam/Rythem/issues/43\" rel=\"nofollow\">https://github.com/AlloyTeam/Rythem/issues/43</a></p> \n <p>通配符格式是这样子:</p> \n <pre class=\"brush: java; auto-links: false;\">regex:*.yourdomain.com/cgi-bin/get_info*</pre> \n <p>虽然没有Charles那么丰富的功能，不过基本功能已是够用了。确实是良心开源。</p>\n</div>","description":"2013-08-26 22:10","name":"试用了一下腾讯出品的抓包工具Rythem","type":"text"},{"contents":"<h2>淘宝的TProfiler使用日记</h2><div class=\"BlogContent\">\n <p>因为最近做项目迁移，迁移之后发现有些地方竟然变慢了！需要一个好的Profiler工具，定位最为耗时的地方。在翻淘宝中间件团队博客<a href=\"http://rdc.taobao.com/team/jm/\" rel=\"nofollow\">http://rdc.taobao.com/team/jm/</a> 的时候发现了TProfiler，于是试用了一下。</p> \n <p>总体来说使用还算简单，文档虽然说不上面面俱到，但是仍然是能让人上手了。</p> \n <p>比较重要的是配置文件，有几个注意点：</p> \n <p>配置文件需要所有属性完整，不然会报&quot;IllegalArgumentException source can't be null”。</p> \n <p><code>profile.properties</code>有一个样例，在man/resources目录下。</p> \n <p>eachProfUseTime = 5 #表示每次profiler的时间，一次profiler结束后，写入到tprofiler.log文件中 <br />eachProfIntervalTime = 50 #profiler的间隔</p> \n <p>TProfiler是一个线上profile工具，之所以profiler间隔很大，是为了不影响线上业务。建议在测试环境，将eachProfIntervalTime设置成1或者0，eachProfUseTime尽量调大，这样比较好看结果。</p> \n <p>还有一个client，可以做flushmethod等操作。如果不主动flush，会等到时间周期结束后才写tmethod.log文件。</p> \n <p>topmethod和topobject是比较有用的，使用以下命令生成：</p> \n <pre class=\"brush: shell; auto-links: false;\">./tprofiler-log-analysis /data/tprofiler/logs/tprofiler.log /data/tprofiler/logs/tmethod.log /data/tprofiler/logs/topmethod.log /data/tprofiler/logs/topobject.log</pre>\n</div>","description":"2013-09-30 11:53","name":"淘宝的TProfiler使用日记","type":"text"}],"name":"工作日志","type":"dir"},{"contents":[{"contents":"<h2>使用webmagic抓取页面并保存为wordpress文件</h2><div class=\"BlogContent\">\n <p>之前做过一年的爬虫，当年功力不够，写的代码都是一点一点往上加。后来看了下据说是最优秀的爬虫<a href=\"http://www.oschina.net/p/scrapy\" rel=\"nofollow\"><code>scrapy</code></a>的结构，山寨了一个Java版的爬虫框架<a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\"><code>webmagic</code></a>。</p> \n <p>这个框架也分为Spider、Schedular、Downloader、Pipeline几个模块。此外有一个Selector，整合了常用的抽取技术(正则、xpath)，支持链式调用以及单复数切换，因为受够了各种抽取的正则，在抽取上多下了一点功夫。</p> \n <p>废话不多，上代码。在webmagic里直接实现PageProcessor接口，即可实现一个爬虫。例如对我的点点博客<a href=\"http://progressdaily.diandian.com/\" rel=\"nofollow\">http://progressdaily.diandian.com/</a>进行抓取：</p> \n <pre class=\"brush: java; auto-links: false;\">public class DiandianBlogProcessor implements PageProcessor {\n\n        private Site site;\n\n        @Override\n        public void process(Page page) {\n            //a()表示提取链接，as()表示提取所有链接\n            //getHtml()返回Html对象，支持链式调用\n            //r()表示用正则表达式提取一条内容，rs()表示提取多条内容\n            //toString()表示取单条结果，toStrings()表示取多条\n            List&lt;String&gt; requests = page.getHtml().as().rs(&quot;(.*/post/.*)&quot;).toStrings();\n            //使用page.addTargetRequests()方法将待抓取的链接加入队列\n            page.addTargetRequests(requests);\n            //page.putField(key,value)将抽取的内容加入结果Map\n            //x()和xs()使用xpath进行抽取\n            page.putField(&quot;title&quot;, page.getHtml().x(&quot;//title&quot;).r(&quot;(.*?)\\\\|&quot;));\n            //sc()使用readability技术直接抽取正文，对于规整的文本有比较好的抽取正确率\n            page.putField(&quot;content&quot;, page.getHtml().sc());\n            page.putField(&quot;date&quot;, page.getUrl().r(&quot;post/(\\\\d+-\\\\d+-\\\\d+)/&quot;));\n            page.putField(&quot;id&quot;, page.getUrl().r(&quot;post/\\\\d+-\\\\d+-\\\\d+/(\\\\d+)&quot;));\n        }\n\n        @Override\n        public Site getSite() {\n            //site定义抽取配置，以及开始url等\n            if (site == null) {\n                site = Site.me().setDomain(&quot;progressdaily.diandian.com&quot;).setStartUrl(&quot;http://progressdaily.diandian.com/&quot;).\n                        setUserAgent(&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_2) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.65 Safari/537.31&quot;);\n            }\n            return site;\n        }\n    }</pre> \n <p>然后实现抓取代码：</p> \n <pre class=\"brush: java; auto-links: false;\">public class DiandianProcessorTest {\n\n        @Test\n        public void test() throws IOException {\n            DiandianBlogProcessor diandianBlogProcessor = new DiandianBlogProcessor();\n            //pipeline是抓取结束后的处理\n            //ftl文件放到classpath:ftl/文件夹下\n            //输出默认放到/data/temp/webmagic/ftl/[domain]目录下\n            FreemarkerPipeline pipeline = new FreemarkerPipeline(&quot;wordpress.ftl&quot;);\n            //Spider.me()是简化写法，其实就是new一个啦\n            //Spider.pipeline()设定一个pipeline，支持设置多个pipeline，多个pipeline会进行链式调用\n            //FileCacheQueueSchedular保存url，支持断点续传，临时文件输出到/data/temp/webmagic/cache目录\n            //Spider.run()执行\n            Spider.me().pipeline(pipeline).schedular(new FileCacheQueueSchedular(diaoyuwengProcessor.getSite(), &quot;/data/temp/webmagic/cache/&quot;)).\n                    processor(diaoyuwengProcessor).run();\n        }\n    }</pre> \n <p>跑一遍之后，将所有输出的文件，合并到一起，并加上wp的<a href=\"https://github.com/code4craft/webmagic/tree/master/webmagic-samples/src/main/resources\" rel=\"nofollow\">头尾</a>，就是wordpress-backup.xml了！</p> \n <p>代码已开源<a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\">https://github.com/code4craft/webmagic</a> \n  <strike>\n    有什么邪恶用途你懂的… \n  </strike></p>\n</div>","description":"2013-06-09 18:09","name":"使用webmagic抓取页面并保存为wordpress文件","type":"text"},{"contents":"<h2>webmagic的设计机制及原理-如何开发一个Java爬虫</h2><div class=\"BlogContent\">\n <p><img src=\"http://static.oschina.net/uploads/space/2013/1110/200709_oP1e_190591.jpg\" alt=\"image\" /></p> \n <blockquote> \n  <p>此文章是webmagic 0.1.0版的设计手册，后续版本的入门及用户手册请看这里：<a href=\"https://github.com/code4craft/webmagic/blob/master/user-manual.md\" rel=\"nofollow\">https://github.com/code4craft/webmagic/blob/master/user-manual.md</a></p> \n </blockquote> \n <p>之前就有网友在博客里留言，觉得webmagic的实现比较有意思，想要借此研究一下爬虫。最近终于集中精力，花了三天时间，终于写完了这篇文章。之前垂直爬虫写了一年多，webmagic框架写了一个多月，这方面倒是有一些心得，希望对读者有帮助。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>webmagic的目标</h2> \n <p>一般来说，一个爬虫包括几个部分：</p> \n <ul> \n  <li><p>页面下载</p> <p>页面下载是一个爬虫的基础。下载页面之后才能进行其他后续操作。</p> </li> \n  <li><p>链接提取</p> <p>一般爬虫都会有一些初始的种子URL，但是这些URL对于爬虫是远远不够的。爬虫在爬页面的时候，需要不断发现新的链接。</p> </li> \n  <li><p>URL管理</p> <p>最基础的URL管理，就是对已经爬过的URL和没有爬的URL做区分，防止重复爬取。</p> </li> \n  <li><p>内容分析和持久化</p> <p>一般来说，我们最终需要的都不是原始的HTML页面。我们需要对爬到的页面进行分析，转化成结构化的数据，并存储下来。</p> </li> \n </ul> \n <p>不同的爬虫，对这几部分的要求是不一样的。</p> \n <p>对于通用型的爬虫，例如搜索引擎蜘蛛，需要指对互联网大部分网页无差别进行抓取。这时候难点就在于页面下载和链接管理上–如果要高效的抓取更多页面，就必须进行更快的下载；同时随着链接数量的增多，需要考虑如果对大规模的链接进行去重和调度，就成了一个很大的问题。一般这些问题都会在大公司有专门的团队去解决，比如这里有一篇来自淘宝的<a href=\"http://www.searchtb.com/2011/07/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96%E9%9B%86%E7%BE%A4.html?spm=0.0.0.0.hHzGxv\" rel=\"nofollow\">快速构建实时抓取集群</a>。对Java来说，如果你要研究通用爬虫，那么可以看一下<a href=\"http://www.oschina.net/p/heritrix\" rel=\"nofollow\"><strong>heritrix</strong></a>或者<a href=\"http://www.oschina.net/p/nutch\" rel=\"nofollow\"><strong>nutch</strong></a>。</p> \n <p>而垂直类型的爬虫要解决的问题则不一样，比如想要爬取一些网站的新闻、博客信息，一般抓取数量要求不是很大，难点则在于如何高效的定制一个爬虫，可以精确的抽取出网页的内容，并保存成结构化的数据。这方面需求很多，webmagic就是为了解决这个目的而开发的。</p> \n <p>使用Java语言开发爬虫是比较复杂的。虽然Java有很强大的页面下载、HTML分析工具，但是每个都有不小的学习成本，而且这些工具本身都不是专门为爬虫而生，使用起来也没有那么顺手。我曾经有一年的时间都在开发爬虫，重复的开发让人头痛。Java还有一个比较成熟的框架<a href=\"https://code.google.com/p/crawler4j/\" rel=\"nofollow\"><strong>crawler4j</strong></a>，但是它是为通用爬虫而设计的，扩展性差一些，满足不了我的业务需要。我也有过自己开发框架的念头，但是终归觉得抽象的不是很好。直到发现python的爬虫框架<a href=\"http://scrapy.org/\" rel=\"nofollow\"><strong>scrapy</strong></a>，它将爬虫的生命周期拆分的非常清晰，我参照它进行了模块划分，并用Java的方式去实现了它，于是就有了webmagic。</p> \n <p>代码已经托管到github，地址是<a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\">https://github.com/code4craft/webmagic</a>，Javadoc：<a href=\"http://code4craft.github.io/webmagic/docs/\" rel=\"nofollow\">http://code4craft.github.io/webmagic/docs/</a></p> \n <p>webmagic的实现还参考了另一个Java爬虫<a href=\"https://gitcafe.com/laiweiwei/Spiderman\" rel=\"nofollow\"><strong>SpiderMan</strong></a>。SpiderMan是一个全栈式的Java爬虫，它的设计思想跟webmagic稍有不同，它希望将Java语言的实现隔离，仅仅让用户通过配置就完成一个垂直爬虫。理论上，SpiderMan功能更强大，很多功能已经内置，而webmagic则比较灵活，适合熟悉Java语法的开发者，可以比较非常方便的进行扩展和二次开发。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>webmagic的模块划分</h2> \n <p>webmagic目前的核心代码都在<strong>webmagic-core</strong>中，<strong>webmagic-samples</strong>里有一些定制爬虫的例子，可以作为参考。而<strong>webmagic-plugin</strong>目前还不完善，后期准备加入一些常用的功能。下面主要介绍webmagic-core的内容。</p> \n <p>前面说到，webmagic参考了scrapy的模块划分，分为Spider(整个爬虫的调度框架)、Downloader(页面下载)、PageProcessor(链接提取和页面分析)、Scheduler(URL管理)、Pipeline(离线分析和持久化)几部分。只不过scrapy通过middleware实现扩展，而webmagic则通过定义这几个接口，并将其不同的实现注入主框架类Spider来实现扩展。</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fcode4craft.github.io%2Fimages%2Fposts%2Fwebmagic.png\" alt=\"image\" /></p> \n <span id=\"OSC_h3_3\"></span> \n <h3>Spider类-核心调度</h3> \n <p>Spider是爬虫的入口类，Spider的接口调用采用了链式的API设计，其他功能全部通过接口注入Spider实现，下面是启动一个比较复杂的Spider的例子。</p> \n <pre class=\"brush: java; auto-links: false;\">Spider.create(sinaBlogProcessor)\n.scheduler(new FileCacheQueueScheduler(&quot;/data/temp/webmagic/cache/&quot;))\n.pipeline(new FilePipeline())\n.thread(10).run();</pre> \n <p>Spider的核心处理流程非常简单，代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">private void processRequest(Request request) {\n    Page page = downloader.download(request, this);\n    if (page == null) {\n        sleep(site.getSleepTime());\n        return;\n    }\n    pageProcessor.process(page);\n    addRequest(page);\n    for (Pipeline pipeline : pipelines) {\n        pipeline.process(page, this);\n    }\n    sleep(site.getSleepTime());\n}</pre> \n <span id=\"OSC_h3_4\"></span> \n <h3>Downloader-页面下载</h3> \n <p>页面下载是一切爬虫的开始。</p> \n <p>大部分爬虫都是通过模拟http请求，接收并分析响应来完成。这方面，JDK自带的<strong>HttpURLConnection</strong>可以满足最简单的需要，而<strong>Apache HttpClient</strong>(4.0后整合到HttpCompenent项目中)则是开发复杂爬虫的不二之选。它支持自定义HTTP头(对于爬虫比较有用的就是User-agent、cookie等)、自动redirect、连接复用、cookie保留、设置代理等诸多强大的功能。</p> \n <p>webmagic使用了HttpClient 4.2，并封装到了<strong>HttpClientDownloader</strong>。学习HttpClient的使用对于构建高性能爬虫是非常有帮助的，官方的<a href=\"http://hc.apache.org/httpcomponents-client-ga/tutorial/html/\" rel=\"nofollow\">Tutorial</a>就是很好的学习资料。目前webmagic对HttpClient的使用仍在初步阶段，不过对于一般抓取任务，已经够用了。</p> \n <p>下面是一个使用HttpClient最简单的例子：</p> \n <pre class=\"brush: java; auto-links: false;\">HttpClient httpClient = new DefaultHttpClient();\nHttpGet httpGet = new HttpGet(&quot;http://youhost/xxx&quot;);\nHttpResponse httpResponse = httpClient.execute(httpGet);\nSystem.out.println(EntityUtils.toString(httpResponse.getEntity().getContent()));</pre> \n <p>对于一些Javascript动态加载的网页，仅仅使用http模拟下载工具，并不能取到页面的内容。这方面的思路有两种：一种是抽丝剥茧，分析js的逻辑，再用爬虫去重现它(比如在网页中提取关键数据，再用这些数据去构造Ajax请求，最后直接从响应体获取想要的数据)； <br />另一种就是：内置一个浏览器，直接获取最后加载完的页面。这方面，js可以使用<strong>PhantomJS</strong>，它内部集成了webkit。而Java可以使用<strong>Selenium</strong>，这是一个非常强大的浏览器模拟工具。考虑以后将它整理成一个独立的Downloader，集成到webmagic中去。</p> \n <p>一般没有必要去扩展Downloader。</p> \n <span id=\"OSC_h3_5\"></span> \n <h3>PageProcessor-页面分析及链接抽取</h3> \n <p>这里说的页面分析主要指HTML页面的分析。页面分析可以说是垂直爬虫最复杂的一部分，在webmagic里，PageProcessor是定制爬虫的核心。通过编写一个实现PageProcessor接口的类，就可以定制一个自己的爬虫。</p> \n <p>页面抽取最基本的方式是使用正则表达式。正则表达式好处是非常通用，解析文本的功能也很强大。但是正则表达式最大的问题是，不能真正对HTML进行语法级别的解析，没有办法处理关系到HTML结构的情况(例如处理标签嵌套)。例如，我想要抽取一个&lt;div&gt;里的内容，可以这样写：“&lt;div&gt;(.*?)&lt;/div&gt;“。但是如果这个div内部还包含几个子div，这个时候使用正则表达式就会将子div的”&lt;/div&gt;“作为终止符截取。为了解决这个问题，我们就需要进行HTML的分析。</p> \n <p>HTML分析是一个比较复杂的工作，Java世界主要有几款比较方便的分析工具：</p> \n <span id=\"OSC_h4_6\"></span> \n <h4>Jsoup</h4> \n <p>Jsoup是一个集强大和便利于一体的HTML解析工具。它方便的地方是，可以用于支持用jquery中css selector的方式选取元素，这对于熟悉js的开发者来说基本没有学习成本。</p> \n <pre class=\"brush: java; auto-links: false;\">String content = &quot;blabla&quot;;\nDocument doc = JSoup.parse(content);\nElements links = doc.select(&quot;a[href]&quot;);</pre> \n <p>Jsoup还支持白名单过滤机制，对于网站防止XSS攻击也是很好的。</p> \n <span id=\"OSC_h4_7\"></span> \n <h4>HtmlParser</h4> \n <p>HtmlParser的功能比较完备，也挺灵活，但谈不上方便。这个项目很久没有维护了，最新版本是2.1。HtmlParser的核心元素是Node，对应一个HTML标签，支持getChildren()等树状遍历方式。HtmlParser另外一个核心元素是NodeFilter，通过实现NodeFilter接口，可以对页面元素进行筛选。这里有一篇HtmlParser的使用文章：<a href=\"https://www.ibm.com/developerworks/cn/opensource/os-cn-crawler/\" rel=\"nofollow\">使用 HttpClient 和 HtmlParser 实现简易爬虫</a>。</p> \n <span id=\"OSC_h4_8\"></span> \n <h4>Apache tika</h4> \n <p>tika是专为抽取而生的工具，还支持PDF、Zip甚至是Java Class。使用tika分析HTML，需要自己定义一个抽取内容的Handler并继承<code>org.xml.sax.helpers.DefaultHandler</code>，解析方式就是xml标准的方式。crawler4j中就使用了tika作为解析工具。SAX这种流式的解析方式对于分析大文件很有用，我个人倒是认为对于解析html意义不是很大。</p> \n <pre class=\"brush: java; auto-links: false;\">InputStream inputStream = null;\nHtmlParser htmlParser = new HtmlParser();\nhtmlParser.parse(new ByteArrayInputStream(page.getContentData()), \ncontentHandler, metadata, new ParseContext());</pre> \n <span id=\"OSC_h4_9\"></span> \n <h4>HtmlCleaner与XPath</h4> \n <p>HtmlCleaner最大的优点是：支持XPath的方式选取元素。XPath是一门在XML中查找信息的语言，也可以用于抽取HTML元素。XPath与CSS Selector大部分功能都是重合的，但是CSS Selector专门针对HTML，写法更简洁，而XPath则是通用的标准，可以精确到属性值。XPath有一定的学习成本，但是对经常需要编写爬虫的人来说，这点投入绝对是值得的。</p> \n <p>学习XPath可以参考w3school的<a href=\"http://www.w3school.com.cn/xpath/\" rel=\"nofollow\">XPath 教程</a>。下面是使用HtmlCleaner和xpath进行抽取的一段代码：</p> \n <pre class=\"brush: java; auto-links: false;\">HtmlCleaner htmlCleaner = new HtmlCleaner();\nTagNode tagNode = htmlCleaner.clean(text);\nObject[] objects = tagNode.evaluateXPath(&quot;xpathStr&quot;);</pre> \n <span id=\"OSC_h4_10\"></span> \n <h4>几个工具的对比</h4> \n <p>在这里评价这些工具的主要标准是“方便”。就拿抽取页面所有链接这一基本任务来说，几种代码分别如下：</p> \n <p>XPath:</p> \n <pre class=\"brush: java; auto-links: false;\">tagNode.evaluateXPath(&quot;//a/@href&quot;)</pre> \n <p>CSS Selector:</p> \n <pre class=\"brush: java; auto-links: false;\">//使用类似js的实现\n$(&quot;a[href]&quot;).attr(&quot;href&quot;)</pre> \n <p>HtmlParser：</p> \n <pre class=\"brush: java; auto-links: false;\">Parser p = new Parser(value);\nNodeFilter aFilter = new TagNameFilter(&quot;a&quot;);\nNodeList nodes = p.extractAllNodesThatMatch(aFilter);\nfor (int i = 0; i &lt; nodes.size(); i++) {\n    Node eachNode = nodes.elementAt(i);\n    if (eachNode instanceof LinkTag) {\n        LinkTag linkTag = (LinkTag) eachNode;\n        System.out.println(linkTag.extractLink());\n    }\n}</pre> \n <p>XPath是最简单的，可以精确选取到href属性值；而CSS Selector则次之，可以选取到HTML标签，属性值需要调用函数去获取；而HtmlParser和SAX则需要手动写程序去处理标签了，比较麻烦。</p> \n <span id=\"OSC_h4_11\"></span> \n <h4>webmagic的Selector</h4> \n <p><strong>Selector</strong>是webmagic为了简化页面抽取开发的独立模块，是整个项目中我最得意的部分。这里整合了CSS Selector、XPath和正则表达式，并可以进行链式的抽取，很容易就实现强大的功能。即使你使用自己开发的爬虫工具，webmagic的Selector仍然值得一试。</p> \n <p>例如，我已经下载了一个页面，现在要抽取某个区域的所有包含&quot;blog&quot;的链接，我可以这样写：</p> \n <pre class=\"brush: java; auto-links: false;\">//content是用别的爬虫工具抽取到的正文\nString content = &quot;blabla&quot;;\nList&lt;String&gt; links = Html.create(content)\n.$(&quot;div.title&quot;)  //css 选择，Java里虽然很少有$符号出现，不过貌似$作为方法名是合法的\n.xpath(&quot;//@href&quot;)  //提取链接\n.regex(&quot;.*blog.*&quot;) //正则匹配过滤\n.all(); //转换为string列表</pre> \n <p>另外，webmagic的抓取链接需要显示的调用<code>Page.addTargetRequests()</code>去添加，这也是为了灵活性考虑的(很多时候，下一步的URL不是单纯的页面href链接，可能会根据页面模块进行抽取，甚至可能是自己拼凑出来的)。</p> \n <p>补充一个有意思的话题，就是对于页面正文的自动抽取。相信用过Evernote Clearly都会对其自动抽取正文的技术印象深刻。这个技术又叫<strong>Readability</strong>，webmagic对readability有一个粗略的实现<strong>SmartContentSelector</strong>，用的是P标签密度计算的方法，在测试oschina博客时有不错的效果。</p> \n <span id=\"OSC_h3_12\"></span> \n <h3>Scheduler-URL管理</h3> \n <p>URL管理的问题可大可小。对于小规模的抓取，URL管理是很简单的。我们只需要将待抓取URL和已抓取URL分开保存，并进行去重即可。使用JDK内置的集合类型Set、List或者Queue都可以满足需要。如果我们要进行多线程抓取，则可以选择线程安全的容器，例如LinkedBlockingQueue以及ConcurrentHashMap。</p> \n <p>因为小规模的URL管理非常简单，很多框架都并不将其抽象为一个模块，而是直接融入到代码中。但是实际上，抽象出Scheduler模块，会使得框架的解耦程度上升一个档次，并非常容易进行横向扩展，这也是我从scrapy中学到的。</p> \n <p>在webmagic的设计中，除了Scheduler模块，其他的处理-从下载、解析到持久化，每个任务都是互相独立的，因此可以通过多个Spider共用一个Scheduler来进行扩展。排除去重的因素，URL管理天生就是一个队列，我们可以很方便的用分布式的队列工具去扩展它，也可以基于mysql、redis或者mongodb这样的存储工具来构造一个队列，这样构建一个多线程乃至分布式的爬虫就轻而易举了。</p> \n <p>URL去重也是一个比较复杂的问题。如果数据量较少，则使用hash的方式就能很好解决。数据量较大的情况下，可以使用Bloom Filter或者更复杂的方式。</p> \n <p>webmagic目前有两个Scheduler的实现，<strong>QueueScheduler</strong>是一个简单的内存队列，速度较快，并且是线程安全的，<strong>FileCacheQueueScheduler</strong>则是一个文件队列，它可以用于耗时较长的下载任务，在任务中途停止后，下次执行仍然从中止的URL开始继续爬取。</p> \n <span id=\"OSC_h3_13\"></span> \n <h3>Pipeline-离线处理和持久化</h3> \n <p>Pipeline其实也是容易被忽略的一部分。大家都知道持久化的重要性，但是很多框架都选择直接在页面抽取的时候将持久化一起完成，例如crawer4j。但是Pipeline真正的好处是，将页面的在线分析和离线处理拆分开来，可以在一些线程里进行下载，另一些线程里进行处理和持久化。</p> \n <p>你可以扩展Pipeline来实现抽取结果的持久化，将其保存到你想要保存的地方-本地文件、数据库、mongodb等等。Pipeline的处理目前还是在线的，但是修改为离线的也并不困难。</p> \n <p>webmagic目前只支持控制台输出和文件持久化，但是持久化到数据库也是很容易的。</p> \n <span id=\"OSC_h2_14\"></span> \n <h2>结语</h2> \n <p>webmagic确实是一个山寨的框架，本身也没有太多创新的东西，但是确实对Java爬虫的实现有了一些简化。在强大便利的功能和较高的灵活性中间，webmagic选择了后者，目标就是要打造一个熟练的Java开发者也用的比较顺手的工具，并且可以集成到自己的业务系统中，这一点我自己开发了不少这样的业务，对其灵活性还是比较有信心的。webmagic目前的代码实现还比较简单(不到2000行)，如果有兴趣的阅读代码可能也会有一些收获，也非常欢迎建议和指正。</p> \n <p>最后再次附上代码地址：<a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\">https://github.com/code4craft/webmagic</a></p>\n</div>","description":"2013-07-20 14:19","name":"webmagic的设计机制及原理-如何开发一个Java爬虫","type":"text"},{"contents":"<h2>使用webmagic构建一个分布式的爬虫</h2><div class=\"BlogContent\">\n <p>之前说过，使用webmagic的架构，很容易就可以通过扩展Scheduler构建一个分布式的爬虫。 <br />参考淘宝官方博客的文章<a href=\"http://www.searchtb.com/2011/07/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96%E9%9B%86%E7%BE%A4.html?spm=0.0.0.0.hHzGxv\" rel=\"nofollow\">快速构建实时抓取集群</a>，构建了一个基于redis的分布式爬虫实现，代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">public class RedisScheduler implements Scheduler{\n\n    private JedisPool pool;\n\n    private static final String QUEUE_PREFIX = &quot;queue_&quot;;\n\n    private static final String SET_PREFIX = &quot;set_&quot;;\n\n    public RedisScheduler(String host){\n        pool = new JedisPool(new JedisPoolConfig(), host);\n    }\n\n    @Override\n    public void push(Request request, Task task) {\n        Jedis jedis = pool.getResource();\n          //使用SortedSet进行url去重\n        if (jedis.zrank(SET_PREFIX+task.getUUID(),request.getUrl())==null){\n            //使用List保存队列\n            jedis.rpush(QUEUE_PREFIX+task.getUUID(),request.getUrl());\n            jedis.zadd(SET_PREFIX+task.getUUID(),System.currentTimeMillis(),request.getUrl());\n        }\n    }\n\n    @Override\n    public Request poll(Task task) {\n        Jedis jedis = pool.getResource();\n        String url = jedis.lpop(QUEUE_PREFIX+task.getUUID());\n            if (url==null) {\n                return null;\n            }\n        return new Request(url);\n    }\n}</pre>\n</div>","description":"2013-07-25 08:24","name":"使用webmagic构建一个分布式的爬虫","type":"text"},{"contents":"<h2>使用Selenium来抓取动态加载的页面</h2><div class=\"BlogContent\">\n <p>一般的爬虫都是直接使用http协议，下载指定url的html内容，并对内容进行分析和抽取。在我写的爬虫框架<a href=\"http://www.oschina.net/p/webmagic\" rel=\"nofollow\">webmagic</a>里也使用了HttpClient来完成这样的任务。</p> \n <p>但是有些页面是通过js以及ajax动态加载的，例如：<a href=\"http://huaban.com/\" rel=\"nofollow\">花瓣网</a>。这时如果我们直接分析原始页面的html，是得不到有效的信息的。当然，因为无论怎样动态加载，基础信息总归是包含在初始页面中得，所以我们可以用爬虫代码来模拟js代码，js读取页面元素值，我们也读取页面元素值;js发送ajax，我们就拼凑参数、发送ajax并解析返回的json。这样总归是能做的，但是比较麻烦，有没有比较省力的方法呢？比较好的方法大概是内嵌一个浏览器了。</p> \n <p><a href=\"http://docs.seleniumhq.org/projects/\" rel=\"nofollow\"><strong>Selenium</strong></a>是一个模拟浏览器，进行自动化测试的工具，它提供一组API可以与真实的浏览器内核交互。Selenium是跨语言的，有Java、C#、python等版本，并且支持多种浏览器，chrome、firefox以及IE都支持。</p> \n <p>在Java项目中使用Selenium，需要做两件事：</p> \n <ul> \n  <li><p>在项目中引入Selenium的Java模块，以Maven为例：</p> <pre class=\"brush: java; auto-links: false;\">&lt;dependency&gt;\n    &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt;\n    &lt;artifactId&gt;selenium-java&lt;/artifactId&gt;\n    &lt;version&gt;2.33.0&lt;/version&gt;\n&lt;/dependency&gt;</pre> </li> \n  <li><p>下载对应的driver，以chrome为例：<a href=\"http://code.google.com/p/chromedriver/downloads/list\" rel=\"nofollow\">http://code.google.com/p/chromedriver/downloads/list</a></p> <p>下载后，需要将driver的位置写到Java的环境变量里，例如我在mac下将其下载到了<code>/Users/yihua/Downloads/chromedriver</code>，则需要在程序里添加以下代码(当然在JVM参数里写-Dxxx=xxx也是可以的)：</p> System.getProperties().setProperty(&quot;webdriver.chrome.driver&quot;,&quot;/Users/yihua/Downloads/chromedriver&quot;); </li> \n </ul> \n <p>Selenium的API挺简单的，核心是WebDriver，下面是动态渲染页面，并获取最终html的代码：</p> \n <pre class=\"brush: java; auto-links: false;\">@Test\n    public void testSelenium() {\n        System.getProperties().setProperty(&quot;webdriver.chrome.driver&quot;, &quot;/Users/yihua/Downloads/chromedriver&quot;);\n        WebDriver webDriver = new ChromeDriver();\n        webDriver.get(&quot;http://huaban.com/&quot;);\n        WebElement webElement = webDriver.findElement(By.xpath(&quot;/html&quot;));\n        System.out.println(webElement.getAttribute(&quot;outerHTML&quot;));\n        webDriver.close();\n    }</pre> \n <p>值得注意的是，每次<code>new ChromeDriver()</code>，Selenium都会建立一个Chrome进程，并使用一个随机端口在Java中与chrome进程进行通信来交互。由此可见有两个问题：</p> \n <ul> \n  <li><p>因此如果直接关闭Java程序，Chrome进程可能是无法关闭的。这里需要显示的调用<code>webDriver.close()</code>来关闭进程。</p> </li> \n  <li><p>创建进程的开销还是比较大的，尽量对webDriver进行复用会比较好。可惜根据官方的文档，webDriver不是线程安全的，所以我们需要建立一个webDriver池来保存它们。不清楚Selenium是否有这样的接口，反正我是自己写了一个<strong>WebDriverPool</strong>来完成这个任务。</p> </li> \n </ul> \n <p>我已经将<strong>Selenium</strong>整合到了我的爬虫框架<a href=\"http://www.oschina.net/p/webmagic\" rel=\"nofollow\">webmagic</a>中，目前还是试用版本，有兴趣的可以一起学习交流。</p> \n <p>最后说说效率问题。嵌入浏览器之后，不但要多花CPU去渲染页面，还要下载页面附加的资源。似乎单个webDriver中的静态资源是有缓存的，初始化之后，访问速度会加快。我试用ChromeDriver加载了100次花瓣的首页<a href=\"http://huaban.com/\" rel=\"nofollow\">(http://huaban.com/)</a>，共耗时263秒，平均每个页面2.6秒。</p> \n <p>为了测试效果，我写了一个花瓣抽取器，抽取花瓣网的分享图片url，用了咱自己的<a href=\"http://www.oschina.net/p/webmagic\" rel=\"nofollow\">webmagic</a>框架，集成了Selenium。</p> \n <pre class=\"brush: java; auto-links: false;\">/**\n * 花瓣网抽取器。&lt;br&gt;\n * 使用Selenium做页面动态渲染。&lt;br&gt;\n */\npublic class HuabanProcessor implements PageProcessor {\n\n    private Site site;\n\n    @Override\n    public void process(Page page) {\n        page.addTargetRequests(page.getHtml().links().regex(&quot;http://huaban\\\\.com/.*&quot;).all());\n        if (page.getUrl().toString().contains(&quot;pins&quot;)) {\n            page.putField(&quot;img&quot;, page.getHtml().xpath(&quot;//div[@id='pin_img']/img/@src&quot;).toString());\n        } else {\n            page.getResultItems().setSkip(true);\n        }\n    }\n\n    @Override\n    public Site getSite() {\n        if (site == null) {\n            site = Site.me().setDomain(&quot;huaban.com&quot;).addStartUrl(&quot;http://huaban.com/&quot;).setSleepTime(1000);\n        }\n        return site;\n    }\n\n    public static void main(String[] args) {\n        Spider.create(new HuabanProcessor()).thread(5)\n                .scheduler(new RedisScheduler(&quot;localhost&quot;))\n                .pipeline(new FilePipeline(&quot;/data/webmagic/test/&quot;))\n                .downloader(new SeleniumDownloader(&quot;/Users/yihua/Downloads/chromedriver&quot;))\n                .run();\n    }\n}</pre> \n <p>sample地址：<a href=\"https://github.com/code4craft/webmagic/blob/master/webmagic-selenium/src/test/java/us/codecraft/webmagic/samples/HuabanProcessor.java\" rel=\"nofollow\">HuabanProcessor.java</a></p>\n</div>","description":"2013-07-26 16:48","name":"使用Selenium来抓取动态加载的页面","type":"text"},{"contents":"<h2>给webmagic加上了注解支持</h2><div class=\"BlogContent\">\n <p>今天有个网友在博客回帖，能不能用注解来写一个爬虫？想了想，因为Javaer总习惯结果有个对象Model(我在自己用的时候也是这样)，ResultItems的key-value形式难免会有点麻烦，何不将抽取和Model合为一体呢？好了！现在爬osc博客只有这点代码了！而且这个对象本身是可以继续使用的！</p> \n <pre class=\"brush: java; auto-links: false;\">@TargetUrl(&quot;http://my.oschina.net/flashsword/blog/*&quot;)\npublic class OschinaBlog {\n\n    @ExtractBy(&quot;//title&quot;)\n    private String title;\n\n    @ExtractBy(value = &quot;div.BlogContent&quot;,type = Fetcher.Type.Css)\n    private String content;\n\n    @ExtractBy(value = &quot;//div[@class='BlogTags']/a/text()&quot;, multi = true)\n    private List&lt;String&gt; tags;\n\n}</pre> \n <p>这里这个TargetUrl有两个意思：一个是符合这个url的交由这个Page处理，另一个是符合这样的url都会被抓取。怎么样？是不是很巧妙？另外为了方便，这里使用了类似正则的通配符形式(其实最终会编译成正则，只不过把”.“转义成了”\\.“)。</p> \n <p>考虑到一些更复杂的情况，例如：一个页面可能对应多个实体类(列表页视图)，后面又做了一些更新，比如下面是一段抽取oschina问答的所有回答的代码：</p> \n <pre class=\"brush: java; auto-links: false;\">@TargetUrl(&quot;http://www.oschina.net/question/\\\\d+_\\\\d+*&quot;)\n@HelpUrl(&quot;http://www.oschina.net/question/*&quot;)\n@ExtractBy(value = &quot;//ul[@class='list']/li[@class='Answer']&quot;, multi = true)\npublic class OschinaAnswer{\n\n    @ExtractBy(&quot;//img/@title&quot;)\n    private String user;\n\n    @ExtractBy(&quot;//div[@class='detail']&quot;)\n    private String content;\n\n    public static void main(String[] args) {\n        OOSpider.create(Site.me().addStartUrl(&quot;http://www.oschina.net/question/567527_120597&quot;), OschinaAnswer.class).run();\n    }\n}</pre> \n <p>咦？当自己写完这堆处理代码的时候，才发现webmagic完全变成了<a href=\"http://www.oschina.net/p/spiderman\" rel=\"nofollow\"><code>Spiderman</code></a>的一个注解版本。再看了一下Spiderman的<a href=\"http://my.oschina.net/laiweiwei/blog/100866\" rel=\"nofollow\">sample</a>，人家还内置了一套表达式引擎！</p> \n <p>没关系，回到设计的初衷上来。Spiderman的设计是一个All-in-one的框架，提倡不写代码；而webmagic则是一个easy to build-in的框架，目标就是用代码实现爬虫，只不过少写点代码。不支持表达式引擎？没关系！复杂的逻辑，咱们可以写代码嘛！于是很简单的定义了一个<code>AfterExtractor</code>接口，在抽取完后，会调用这个接口：</p> \n <pre class=\"brush: java; auto-links: false;\">@TargetUrl(&quot;http://my.oschina.net/flashsword/blog/*&quot;)\npublic class OschinaBlog implements AfterExtractor {\n\n    @ExtractBy(&quot;//title&quot;)\n    private String title;\n\n    @ExtractBy(value = &quot;div.BlogContent&quot;, type = ExtractBy.Type.Css)\n    private String content;\n\n    @ExtractBy(value = &quot;//div[@class='BlogTags']/a/text()&quot;, multi = true)\n    private List&lt;String&gt; tags;\n\n    @Override\n    public void afterProcess(Page page) {\n        System.out.println(&quot;title:\\t&quot;+title);\n        System.out.println(&quot;content:\\t&quot;+content);\n        System.out.println(&quot;tags:\\t&quot; + tags);\n    }\n\n    public static void main(String[] args) {\n        OOSpider.create(Site.me().addStartUrl(&quot;http://my.oschina.net/flashsword/blog/145796&quot;), OschinaBlog.class).run();\n    }\n}</pre> \n <p>public void afterProcess(Page page) 这个函数能做PageProcessor所有能做的事情。我想这段代码也不用咱说明了吧。个人还是比较满意的。</p> \n <p>使用这个方式，结合<a href=\"http://www.oschina.net/p/jfinal\" rel=\"nofollow\"><code>JFinal</code></a>，轻易实现了结果持久化到数据库的任务，代码：<a href=\"http://www.oschina.net/code/snippet_190591_23456\" rel=\"nofollow\">http://www.oschina.net/code/snippet_190591_23456</a>。</p> \n <p>值得一提的是，以上代码都没有修改底层的核心模块划分，以前手写PageProcessor的方式依然是有效的。看来一个良好的前期规划是很有必要的！</p> \n <p>代码目前在<a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\">https://github.com/code4craft/webmagic</a> annotation分支上，后续测试稳定后回合并到主干。</p>\n</div>","description":"2013-08-01 22:58","name":"给webmagic加上了注解支持","type":"text"},{"contents":"<h2>关于爬虫实现分页的一些思考</h2><div class=\"BlogContent\">\n <p>在抓取一些新闻、博客类页面时，我们会遇到这样的需求：有些文章会分成几页显示，每页都是不同的HTML页面，而我们最终想要的数据，肯定是一个整合好的结果。那么，如何把这些分页显示的文章整合起来呢？</p> \n <p>这个功能在<a href=\"http://my.oschina.net/laiweiwei/blog/100866\" rel=\"nofollow\"><code>Spiderman</code></a>中已经实现，使用的方式是：一旦发现分页，则进入递归下载和解析模式，直到下载完成，然后合并、保存！但是在<a href=\"http://www.oschina.net/p/webmagic\" rel=\"nofollow\"><code>webmagic</code></a>中，所有的页面解析都是独立的，解析器没有办法去调用一个下载方法，并返回结果。替代方案是：可以在Request里保存上一次抽取的结果，然后在最后的页面把它们拼装起来。</p> \n <p>但是这种方式并不是那么完美：这里假定了爬取的顺序，而如果第一次进入的不是第一页，而是中间某个页面呢？那么会不会存在部分抓取或者重复抓取？同时在抽取过程中，又重新递归的启动一个爬虫，也让整个爬虫的生命周期管理变得更困难。</p> \n <p>秉承每个抽取器互相独立的目标，最后决定不要在抽取逻辑中进行处理，而放到抽取之后。每个抽取仍然相互独立，但是在最后输出时有一道“把关”，它等待知道分页的所有结果都返回后，再进行输出。</p> \n <p>在webmagic里，Pipeline是可以嵌套的，于是就有了<a href=\"https://github.com/code4craft/webmagic/blob/annotation/webmagic-plugin/webmagic-misc/src/main/java/us/codecraft/webmagic/pipeline/PagedPipeline.java\" rel=\"nofollow\"><code>PagedPipeline</code></a>。这里会收集所有带分页的数据，延迟直到数据整合完成，再统一输出。虽然稍微绕了点，但是保证了模块独立性(Pipeline之前的模块无须知道分页逻辑)。目前是用内存中Map实现的，如果要分布式的话，用远程存储就可以了。</p> \n <p>这里面有几个问题：</p> \n <ul> \n  <li><p>哪些分页该聚合到一起？</p> <p>可以根据页面元素抽取出一个公共ID作为key。</p> </li> \n  <li><p>如何知道分页有没有都抓取到？</p> <p>每个页面都列出自己还要抓取哪些页面，当待抓取集合和已抓取结合重合时，则结束并合并到一条记录中输出。</p> </li> \n  <li><p>页面顺序如何？</p> <p>一般根据page数字从小到大排列。</p> </li> \n  <li><p>结果如何拼接？</p> <p>实现一个combine方法吧。</p> </li> \n </ul> \n <p>于是设计了这么一个接口：</p> \n <pre class=\"brush: java; auto-links: false;\">public interface PagedModel {\n\n    public String getPageKey();\n\n    public Collection&lt;String&gt; getOtherPages();\n\n    public String getPage();\n\n    public PagedModel combine(PagedModel pagedModel);\n\n}</pre> \n <p>需要分页的对象，实现这个接口就相当于回答了这几个问题。</p> \n <p>拿网易新闻做了一个例子：</p> \n <pre class=\"brush: java; auto-links: false;\">@TargetUrl(&quot;http://news.163.com/\\\\d+/\\\\d+/\\\\d+/\\\\w+*.html&quot;)\npublic class News163 implements PagedModel, AfterExtractor {\n\n    @ExtractByUrl(&quot;http://news\\\\.163\\\\.com/\\\\d+/\\\\d+/\\\\d+/(\\\\w+)*\\\\.html&quot;)\n    private String pageKey;\n\n    @ExtractByUrl(value = &quot;http://news\\\\.163\\\\.com/\\\\d+/\\\\d+/\\\\d+/\\\\w+_(\\\\d+)\\\\.html&quot;, notNull = false)\n    private String page;\n\n    private List&lt;String&gt; otherPage;\n\n    @ExtractBy(&quot;//h1[@id=\\&quot;h1title\\&quot;]/text()&quot;)\n    private String title;\n\n    @ExtractBy(&quot;//div[@id=\\&quot;epContentLeft\\&quot;]&quot;)\n    private String content;\n\n    @Override\n    public String getPageKey() {\n        return pageKey;\n    }\n\n    @Override\n    public Collection&lt;String&gt; getOtherPages() {\n        return otherPage;\n    }\n\n    @Override\n    public String getPage() {\n        if (page == null) {\n            return &quot;1&quot;;\n        }\n        return page;\n    }\n\n    @Override\n    public PagedModel combine(PagedModel pagedModel) {\n        News163 news163 = new News163();\n        News163 pagedModel1 = (News163) pagedModel;\n        news163.content = this.content + pagedModel1.content;\n        return news163;\n    }\n\n    @Override\n    public String toString() {\n        return &quot;News163{&quot; +\n                &quot;content='&quot; + content + '\\'' +\n                &quot;, title='&quot; + title + '\\'' +\n                &quot;, otherPage=&quot; + otherPage +\n                '}';\n    }\n\n    public static void main(String[] args) {\n        OOSpider.create(Site.me().addStartUrl(&quot;http://news.163.com/13/0802/05/958I1E330001124J_2.html&quot;), News163.class)\n                .clearPipeline().pipeline(new PagedPipeline()).pipeline(new ConsolePipeline()).run();\n    }\n\n    @Override\n    public void afterProcess(Page page) {\n        Selectable xpath = page.getHtml().xpath(&quot;//div[@class=\\&quot;ep-pages\\&quot;]//a/@href&quot;);\n        otherPage = xpath.regex(&quot;http://news\\\\.163\\\\.com/\\\\d+/\\\\d+/\\\\d+/\\\\w+_(\\\\d+)\\\\.html&quot;).all();\n    }\n}</pre> \n <p>算不上简单，看看以后怎么优化吧。</p>\n</div>","description":"2013-08-04 21:54","name":"关于爬虫实现分页的一些思考","type":"text"},{"contents":"<h2>折腾Javadoc笔记</h2><div class=\"BlogContent\">\n <p>webmagic在代码里用到了大量的中文注释，其实最大的目的是想生成中文的Javadoc。但是中文注释实在太不高级了，在各种编码下还会变成乱码。本着高端大气国际化的思路，还是想把它换成英文，但是又不想放弃中文的Javadoc，怎么办呢？</p> \n <p><a href=\"http://stackoverflow.com/questions/1482392/how-to-be-multi-language-to-javadoc\" rel=\"nofollow\">stackoverflow</a>上有个帖子，说是在源码里写两种语言的注释，然后用过css切换。还有日本人用freemarker的语法来写Javadoc的<a href=\"http://www.ruimo.com/howto/java/javadoc-i18n/index_en.html\" rel=\"nofollow\">http://www.ruimo.com/howto/java/javadoc-i18n/index_en.html</a>。但是看到代码里一堆翻译文本也挺烦的，不符合咱们无重复代码的宗旨，是吧？</p> \n <p>又搜到一个日本人做的工具<a href=\"http://sourceforge.net/projects/l10ndoclet/\" rel=\"nofollow\">l10ndoclet</a>。不得不说日本人这方面确实比较严谨。这个工具可以抽出代码中的Javadoc，单独保存成xml，下次直接修改这个xml即可。</p> \n <pre class=\"brush: java; auto-links: false;\">javadoc -docfilessubdirs -sourcepath ./webmagic-core/src/main/java/:./webmagic-extension/src/main/java/ us.codecraft.webmagic -subpackages us.codecraft.webmagic -docletpath ~/Downloads/l10ndoclet.jar -doclet com.sun.tools.doclets.l10n.PreProcess -d /data/webmagic/doc\n\njavadoc -docfilessubdirs -sourcepath ./webmagic-core/src/main/java/:./webmagic-extension/src/main/java/ us.codecraft.webmagic -docletpath ~/Downloads/l10ndoclet.jar -subpackages us.codecraft.webmagic -cmntpath /data/webmagic/doc -doclet com.sun.tools.doclets.l10n.PostProcess -d /data/webmagic/doc</pre>\n</div>","description":"2013-08-17 14:11","name":"折腾Javadoc笔记","type":"text"},{"contents":"<h2>玩转webmagic代码之Scheduler</h2><div class=\"BlogContent\">\n <p>webmagic上线之后，因为灵活性很强，得到了一些爬虫老手的欢迎，但是对于新手来说可能稍微摸不着头脑，我的需求是这样子，什么模块化，什么灵活性，但是看了半天，我也不知道怎么解决我的问题啊？</p> \n <p>这里先谈谈Scheduler，不单关乎框架，更多是一些爬虫通用的思想，希望对大家有帮助。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>为什么要有Scheduler</h2> \n <p>其实Scheduler并非webmagic独创，在scrapy以及其他成熟爬虫中都有类似模块。Scheduler管理了所有待抓取的url，单个爬虫自己是无法控制要抓取什么的，抓什么都由Scheduler决定。</p> \n <p>这样子最大的好处就是，爬虫本身没有状态，给一个url，处理一个，非常容易进行水平扩展(就是加线程、或者加机器)，而且即使单台爬虫宕机，也不会有什么损失。这跟我们在应用开发中，所说的&quot;服务无状态&quot;的思想是很像的。而相反，如果在单个爬虫线程内部，循环甚至递归的进行抓取，那么这部分工作是无法扩展的，而且宕机之后恢复会很困难。</p> \n <pre class=\"brush: java; auto-links: false;\">public interface Scheduler {\n\n    public void push(Request request, Task task);\n\n    public Request poll(Task task);\n\n}</pre> \n <p>webmagic里的Scheduler只有两个接口，一个放入url，一个取出url。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>玩转Scheduler</h2> \n <span id=\"OSC_h3_3\"></span> \n <h3>层级关系及上下文信息</h3> \n <p>我们这里举一个较复杂的例子。例如，我们要从<a href=\"http://www.ip138.com/post/\" rel=\"nofollow\">http://www.ip138.com/post/</a>上抓取全国的邮编地址，最后我们想要得到一个树状结构的结果，这个结果包括<strong>省 市 县 村/街道 邮编</strong>。这里有两个需求：一个是优先抓最终页面，一个是要带上所有前面页面的信息。如果随便手写一个爬虫，可能我们就会用递归的形式写了，那么在webmagic里如何做呢？</p> \n <p>从0.2.1起，webmagic的<code>Request</code>，也就是保存待抓取url的对象，有两个大的改动：</p> \n <p>一个是支持优先级，这样子要深度优先还是广度优先，都可以通过给不同层次设置不同值完成。</p> \n <p>二是可以在<code>Request</code>里附加额外信息<code>request.putExtra(key,value)</code>，这个额外信息会带到下次页面抓取中去。</p> \n <p>于是，我们可以通过给最终页面增加高优先级，达到优先抓取的目的；同时可以把之前抓取的信息保存到<code>Request</code>里去，在最终结果中，附加上前面页面的信息。</p> \n <p>最终代码在<a href=\"https://github.com/code4craft/webmagic/blob/master/webmagic-samples/src/main/java/us/codecraft/webmagic/samples/scheduler/ZipCodePageProcessor.java\" rel=\"nofollow\">这里</a>，当然，其实这个例子里，最终页面是包含“省”、“市”信息的，这里只是讨论附加信息的可能性。</p> \n <pre class=\"brush: java; auto-links: false;\">public class ZipCodePageProcessor implements PageProcessor {\n\n    private Site site = Site.me().setCharset(&quot;gb2312&quot;)\n            .setSleepTime(100).addStartUrl(&quot;http://www.ip138.com/post/&quot;);\n\n    @Override\n    public void process(Page page) {\n        if (page.getUrl().toString().equals(&quot;http://www.ip138.com/post/&quot;)) {\n            processCountry(page);\n        } else if (page.getUrl().regex(&quot;http://www\\\\.ip138\\\\.com/post/\\\\w+[/]?$&quot;).toString() != null) {\n            processProvince(page);\n        } else {\n            processDistrict(page);\n        }\n\n    }\n\n    private void processCountry(Page page) {\n        List&lt;String&gt; provinces = page.getHtml().xpath(&quot;//*[@id=\\&quot;newAlexa\\&quot;]/table/tbody/tr/td&quot;).all();\n        for (String province : provinces) {\n            String link = xpath(&quot;//@href&quot;).select(province);\n            String title = xpath(&quot;/text()&quot;).select(province);\n            Request request = new Request(link).setPriority(0).putExtra(&quot;province&quot;, title);\n            page.addTargetRequest(request);\n        }\n    }\n\n    private void processProvince(Page page) {\n        //这里仅靠xpath没法精准定位，所以使用正则作为筛选，不符合正则的会被过滤掉\n        List&lt;String&gt; districts = page.getHtml().xpath(&quot;//body/table/tbody/tr/td&quot;).regex(&quot;.*http://www\\\\.ip138\\\\.com/post/\\\\w+/\\\\w+.*&quot;).all();\n        for (String district : districts) {\n            String link = xpath(&quot;//@href&quot;).select(district);\n            String title = xpath(&quot;/text()&quot;).select(district);\n            Request request = new Request(link).setPriority(1).putExtra(&quot;province&quot;, page.getRequest().getExtra(&quot;province&quot;)).putExtra(&quot;district&quot;, title);\n            page.addTargetRequest(request);\n        }\n    }\n\n    private void processDistrict(Page page) {\n        String province = page.getRequest().getExtra(&quot;province&quot;).toString();\n        String district = page.getRequest().getExtra(&quot;district&quot;).toString();\n        List&lt;String&gt; counties = page.getHtml().xpath(&quot;//body/table/tbody/tr&quot;).regex(&quot;.*&lt;td&gt;\\\\d+&lt;/td&gt;.*&quot;).all();\n        String regex = &quot;&lt;td[^&lt;&gt;]*&gt;([^&lt;&gt;]+)&lt;/td&gt;&lt;td[^&lt;&gt;]*&gt;([^&lt;&gt;]+)&lt;/td&gt;&lt;td[^&lt;&gt;]*&gt;([^&lt;&gt;]+)&lt;/td&gt;&lt;td[^&lt;&gt;]*&gt;([^&lt;&gt;]+)&lt;/td&gt;&quot;;\n        for (String county : counties) {\n            String county0 = regex(regex, 1).select(county);\n            String county1 = regex(regex, 2).select(county);\n            String zipCode = regex(regex, 3).select(county);\n            page.putField(&quot;result&quot;, StringUtils.join(new String[]{province, district,\n                    county0, county1, zipCode}, &quot;\\t&quot;));\n        }\n        List&lt;String&gt; links = page.getHtml().links().regex(&quot;http://www\\\\.ip138\\\\.com/post/\\\\w+/\\\\w+&quot;).all();\n        for (String link : links) {\n            page.addTargetRequest(new Request(link).setPriority(2).putExtra(&quot;province&quot;, province).putExtra(&quot;district&quot;, district));\n        }\n\n    }\n\n    @Override\n    public Site getSite() {\n        return site;\n    }\n\n    public static void main(String[] args) {\n        Spider.create(new ZipCodePageProcessor()).scheduler(new PriorityScheduler()).run();\n    }\n}</pre> \n <p>这段代码略复杂，因为我们其实进行了了3种页面的抽取，论单个页面，还是挺简单的:)</p> \n <p>同样的，我们可以实现一个最多抓取n层的爬虫。通过在request.extra里增加一个&quot;层数&quot;的概念即可做到，而Scheduler只需做少量定制：</p> \n <pre class=\"brush: java; auto-links: false;\">public class LevelLimitScheduler extends PriorityScheduler {\n\n    private int levelLimit = 3;\n\n    public LevelLimitScheduler(int levelLimit) {\n        this.levelLimit = levelLimit;\n    }\n\n    @Override\n    public synchronized void push(Request request, Task task) {\n        if (((Integer) request.getExtra(&quot;_level&quot;)) &lt;= levelLimit) {\n            super.push(request, task);\n        }\n    }\n}</pre> \n <span id=\"OSC_h3_4\"></span> \n <h3>按照指定URL查询</h3> \n <p>例如我想要抓取百度某些关键词查询的结果，这个需求再简单不过了，你可以先新建一个Scheduler，将想要查询的URL全部放入Scheduler之后，再启动Spider即可：</p> \n <pre class=\"brush: java; auto-links: false;\">PriorityScheduler scheduler = new PriorityScheduler();\nSpider spider = Spider.create(new ZipCodePageProcessor()).scheduler(scheduler);\nscheduler.push(new Request(&quot;http://www.baidu.com/s?wd=webmagic&quot;),spider);\n//这里webmagic是关键词\n...//其他地址\nspider.run();</pre> \n <span id=\"OSC_h3_5\"></span> \n <h3>定期轮询</h3> \n <p>有一类需求是，定期检查页面是否更新，如果更新，则抓取最新数据。这里包括两个问题：</p> \n <p>定期抓取和更新持久化数据。后者在Pipeline分享时候再说。</p> \n <p>而定期轮询，最简单的方法就是定期去启动Spider.run()。这样子没什么问题，只是不够优雅，还有一种方法是用Scheduler做定期分发，一次性把URL放进去，然后隔一段时间间隔后，再把url取出来。我这里基于<code>DelayQueue</code>进行了一个实现：<a href=\"https://github.com/code4craft/webmagic/blob/master/webmagic-samples/src/main/java/us/codecraft/webmagic/samples/scheduler/DelayQueueScheduler.java\" rel=\"nofollow\"><code>DelayQueueScheduler</code></a>，大致思路就是这样。</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>分布式</h2> \n <p>webmagic里有一个基于redis的RedisScheduler，可以实现较简单的分布式功能。选用redis是因为redis比较轻量，同时有强大的数据结构支持。实际上更为通用的方法是：将队列管理和url去重拆分开来，用对应的工具去做。</p> \n <p>url队列，实际上很适合的载体工具就是各种消息队列，例如JMS的实现ActiveMQ。当然如果你对关系数据库比较熟悉，用它们来处理也是没有问题的。</p> \n <p>关于去重，就现成的工具来说的话，倒是没有什么比redis更合适了。当然，你也可以自己构建一个去重服务，利用bloom filter等算法减少内存开销。</p> \n <p><strong>玩转webmagic系列</strong>以后会不定期更新，希望对大家有帮助。</p> \n <p>最后依然附上 webmagic的github地址：</p> \n <p><a href=\"https://github.com/code4craft/webmagic\" rel=\"nofollow\">https://github.com/code4craft/webmagic</a></p>\n</div>","description":"2013-08-21 23:54","name":"玩转webmagic代码之Scheduler","type":"text"},{"contents":"<h2>想要在webmagic中自定义一门爬虫语言</h2><div class=\"BlogContent\">\n <p>早在开始开发webmagic之前，就一直在思考，如何让爬虫的描述变得简单？</p> \n <p>单条表达式描述一个抽取规则的诱惑是相当大的，这样子注解、配置、动态生成，都非常容易展开了。有个朋友做过一个管理后台，就是指定一个抽取字段，填一条XPath，一个抽取器就产生了。可惜XPath有些时候不那么灵活，还得用上正则这些东西。</p> \n <p>自己写一个DSL始终太费劲，而XPath某种程度已经够好了。CSS Selector看起来很美，但是其语法的简单性使得描述一些复杂结构不太得心应手。</p> \n <p>写了Xsoup之后，在这方面做了一点小小的尝试，Xsoup内置了一些XPath规范没有的函数，例如：<code>regex()</code>，<code>tidyText()</code>，个人觉得都是非常有用的功能。</p> \n <p>在跟@搜索小虫讨论之后，觉得在XPath里加入自定义函数功能，是个很酷的想法！这样虽然不标准，但是因为是自定义的，所以也不会跟XPath标准离得很远。如何规范自定义函数及编写，是个很有意思的问题。</p>\n</div>","description":"2013-09-04 15:17","name":"想要在webmagic中自定义一门爬虫语言","type":"text"},{"contents":"<h2>webmagic 0.4.0的特性</h2><div class=\"BlogContent\">\n <blockquote> \n  <p>0.4.0已发布，新闻：<a href=\"http://www.oschina.net/news/45720/webmagic-0-4-0\" rel=\"nofollow\">http://www.oschina.net/news/45720/webmagic-0-4-0</a></p> \n </blockquote> \n <p>webmagic 0.4.0将于本周内发布，新增特性：</p> \n <span id=\"OSC_h3_1\"></span> \n <h3>大幅优化下载效率</h3> \n <ul> \n  <li>升级HttpClient到4.3.1，重写了HttpClientDownloader的代码 <a href=\"https://github.com/code4craft/webmagic/issues/32\" rel=\"nofollow\">#32</a>。</li> \n  <li>在http请求中主动开启gzip，降低传输开销 <a href=\"https://github.com/code4craft/webmagic/issues/31\" rel=\"nofollow\">#31</a>。</li> \n  <li>修复0.3.2及之前版本连接池不生效的问题 <a href=\"https://github.com/code4craft/webmagic/issues/30\" rel=\"nofollow\">#30</a>，使用新的连接池机制，实现连接复用功能。</li> \n </ul> \n <p>经测试，下载速度可达到90%左右的提升。</p> \n <span id=\"OSC_h3_2\"></span> \n <h3>新增同步下载模式，对于简单任务更方便</h3> \n <pre class=\"brush: java; auto-links: false;\">OOSpider ooSpider = OOSpider.create(Site.me().setSleepTime(100), BaiduBaike.class);\n    BaiduBaike baike = ooSpider.&lt;BaiduBaike&gt;get(&quot;http://baike.baidu.com/search/word?word=httpclient&amp;pic=1&amp;sug=1&amp;enc=utf8&quot;);\n    System.out.println(baike);</pre> \n <span id=\"OSC_h3_3\"></span> \n <h3>Spider部分:</h3> \n <ul> \n  <li>重构了多线程的代码，修复几个线程安全问题。</li> \n  <li>可以主动设置当所有任务完成时，Spider是否终止。</li> \n  <li>可以设置初始的Request，而不仅仅是Url <a href=\"https://github.com/code4craft/webmagic/issues/29\" rel=\"nofollow\">#29</a>。</li> \n  <li>增加http代理支持 <a href=\"https://github.com/code4craft/webmagic/issues/22\" rel=\"nofollow\">#22</a>。</li> \n  <li>支持自定义所有http头<a href=\"https://github.com/code4craft/webmagic/issues/27\" rel=\"nofollow\">#27</a></li> \n </ul> \n <p>同时webmagic的邮件组开通了，欢迎加入:</p> \n <p><a href=\"https://groups.google.com/forum/#!forum/webmagic-java\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/webmagic-java</a></p>\n</div>","description":"2013-11-04 07:42","name":"webmagic 0.4.0的特性","type":"text"},{"contents":"<h2>在webmagic中加入了自定义语言</h2><div class=\"BlogContent\">\n <p>一直想在webmagic中加入一门自定义语言(领域特定语言，简称DSL)，但是实在无力从语法解析层开始写起。尝试过在XPath上做文章，后来又觉得太难过了。今天又聊到这个话题，想到当年接触过的Ruby，找到了这个Ruby的简易爬虫项目： <br /><a href=\"https://github.com/mion/harvestman\" rel=\"nofollow\">https://github.com/mion/harvestman</a></p> \n <p>JVM上一个好处就是有很多奇怪的库，而且这些库还非常的成熟，比如JRuby，Jython以及rhino。于是鼓捣半天，整出了一个DSL的雏形(基于JRuby)：</p> \n <pre class=\"brush: ruby; auto-links: false;\">title = css &quot;div.BlogTitle h1&quot;\ncontent = css &quot;div.BlogContent&quot;\nurls &quot;http://my\\\\.oschina\\\\.net/flashsword/blog/\\\\d+&quot;</pre> \n <p>感觉还是非常强大的！最强大之处是你大概不知道它是Ruby，好像你也不怎么需要会Ruby的语法…</p> \n <p>可惜JRuby虽酷，但是遇到复杂情况定制起来可能会有点难度，毕竟会Ruby的人不那么多。这时我又想到了广大程序员喜闻乐见的Javascript！于是有了Javascript版本DSL(基于rhino)：</p> \n <pre class=\"brush: js; auto-links: false;\">var result = {\n    title: $(&quot;div.BlogTitle h1&quot;),\n    content: $(&quot;div.BlogContent&quot;)\n}\nvar config = {\n    ua: '',\n    sleepTime : 20\n}\nurls(&quot;http://my\\\\.oschina\\\\.net/flashsword/blog/\\\\d+&quot;)</pre> \n <p>说真的它已经不算是DSL了，因为有明显的js痕迹！不过没关系，毕竟熟悉js的人更多嘛，这样子高级定制会方便一些。</p>\n</div>","description":"2013-11-10 22:39","name":"在webmagic中加入了自定义语言","type":"text"},{"contents":"<h2>记webmagic一个多线程问题排查和修复的过程</h2><div class=\"BlogContent\">\n <p>在webmagic的多线程抓取中有一个比较麻烦的问题：当Scheduler拿不到url的时候，不能立即退出，需要等到没抓完的线程都运行完毕，没有新url产生时，才能退出。之前使用Thread.sleep来实现，当拿不到url时，sleep一段时间再取，确定没有线程执行之后，再退出。</p> \n <p>但是这种方式始终不够优雅。Java里面有wait/notify机制可以解决这种同步的问题。于是webmagic 0.4.0用wait/notify机制代替了之前的Thread.sleep机制。代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">while (!Thread.currentThread().isInterrupted() &amp;&amp; stat.get() == STAT_RUNNING) {\n        Request request = scheduler.poll(this);\n        if (request == null) {\n            if (threadAlive.get() == 0 &amp;&amp; exitWhenComplete) {\n                break;\n            }\n            // wait until new url added\n            waitNewUrl();\n        } else {\n            final Request requestFinal = request;\n            threadAlive.incrementAndGet();\n            executorService.execute(new Runnable() {\n                @Override\n                public void run() {\n                    try {\n                        processRequest(requestFinal);\n                    } catch (Exception e) {\n                        logger.error(&quot;download &quot; + requestFinal + &quot; error&quot;, e);\n                    } finally {\n                        threadAlive.decrementAndGet();\n                        signalNewUrl();\n                    }\n                }\n            });\n        }\n    }\n\nprivate void waitNewUrl() {\n    try {\n        newUrlLock.lock();\n        try {\n            newUrlCondition.await();\n        } catch (InterruptedException e) {\n        }\n    } finally {\n        newUrlLock.unlock();\n    }\n}</pre> \n <p>这里当线程完成之后，会调用<code>signalNewUrl()</code>来通知主线程，停止等待！</p> \n <p>0.4.0发布之后，有用户问我，为什么有的时候抓完无法退出？我开始就怀疑这里可能存在线程安全问题，但是苦于无法复现。</p> \n <p>思考了一下，有可能存在这样执行情况：</p> \n <ol> \n  <li>threadAlive&gt;0，执行<code>if (threadAlive.get() == 0 &amp;&amp; exitWhenComplete)</code>check跳过，于是准备进入<code>waitNewUrl()</code>;</li> \n  <li>此时最后一个子线程执行结束，<code>threadAlive.decrementAndGet();</code>和<code>signalNewUrl();</code>相继执行；</li> \n  <li>此时主线程进入<code>waitNewUrl()</code>，结果已无线程执行，也无人可以notify它了，于是线程一直等待…</li> \n </ol> \n <p>那么似乎在lock里加入double-check就OK了？但是今天看了<a href=\"http://coolshell.cn/articles/4576.html\" rel=\"nofollow\">http://coolshell.cn/articles/4576.html</a>这篇文章，大概意思是：出了问题不要靠猜！一定要复现并测试！</p> \n <p>于是决定手动模拟！开启10个线程，并mock了所有部件，循环10000次去执行，代码不贴了，地址：<a href=\"https://github.com/code4craft/webmagic/blob/master/webmagic-core/src/test/java/us/codecraft/webmagic/SpiderTest.java\" rel=\"nofollow\">https://github.com/code4craft/webmagic/blob/master/webmagic-core/src/test/java/us/codecraft/webmagic/SpiderTest.java</a>。执行一下，果然到了第13次就卡住了！jstack之后，果然卡在<code>newUrlCondition.await();</code>这里！</p> \n <p>然后加入double-check:</p> \n <pre class=\"brush: java; auto-links: false;\">private void waitNewUrl() {\n    try {\n        newUrlLock.lock();\n        //double check\n        if (threadAlive.get() == 0 &amp;&amp; exitWhenComplete) {\n            return;\n        }\n        try {\n            newUrlCondition.await();\n        } catch (InterruptedException e) {\n        }\n    } finally {\n        newUrlLock.unlock();\n    }\n}</pre> \n <p>结果执行成功！至此问题解决！</p> \n <p>经过这个例子，也大致明白了为什么wait/notify之前总是要先<code>lock</code>。为什么呢？有机会写一篇文章总结一下吧！</p> \n <p>很简单，是吧？其实这篇文章只想说明一件事：出了bug不要靠猜！一定要复现并确认解决！</p>\n</div>","description":"2013-11-27 23:58","name":"记webmagic一个多线程问题排查和修复的过程","type":"text"},{"contents":"<h2>webmagic使用手册</h2><div class=\"BlogContent\">\n <blockquote> \n  <p>webmagic是一个开源的Java垂直爬虫框架，目标是简化爬虫的开发流程，让开发者专注于逻辑功能的开发。webmagic的核心非常简单，但是覆盖爬虫的整个流程，也是很好的学习爬虫开发的材料。</p> \n  <p>web爬虫是一种技术，webmagic致力于将这种技术的实现成本降低，但是出于对资源提供者的尊重，webmagic不会做反封锁的事情，包括：验证码破解、代理切换、自动登录等。</p> \n  <p>作者黄亿华(<a href=\"http://www.oschina.net/code4crafter@gmail.com\" rel=\"nofollow\">code4crafter</a><a href=\"http://my.oschina.net/zantesu\" target=\"_blank\" rel=\"nofollow\">@gmail.com</a> )曾经在前公司进行过一年的垂直爬虫的开发，webmagic就是为了解决爬虫开发的一些重复劳动而产生的框架。</p> \n  <p>webmagic的架构和设计参考了以下两个项目，感谢以下两个项目的作者：</p> \n  <p>python爬虫 <strong>scrapy</strong> <a href=\"https://github.com/scrapy/scrapy\" rel=\"nofollow\">https://github.com/scrapy/scrapy</a></p> \n  <p>Java爬虫 <strong>Spiderman</strong> <a href=\"https://gitcafe.com/laiweiwei/Spiderman\" rel=\"nofollow\">https://gitcafe.com/laiweiwei/Spiderman</a></p> \n  <p>webmagic遵循<a href=\"http://www.apache.org/licenses/LICENSE-2.0.html\" rel=\"nofollow\">Apache 2.0协议</a>，你可以自由进行使用和修改。有使用不便或者问题，欢迎在github<a href=\"https://github.com/code4craft/webmagic/issues\" rel=\"nofollow\">提交issue</a>，或者在<a href=\"http://www.oschina.net/question\" rel=\"nofollow\">oschina讨论模块</a>提问。</p> \n </blockquote> \n <div></div> \n <span id=\"OSC_h2_1\"></span> \n <h2>下载及安装</h2> \n <span id=\"OSC_h3_2\"></span> \n <h3>使用maven</h3> \n <p>webmagic使用maven管理依赖，在项目中添加对应的依赖即可使用webmagic：</p> \n <pre class=\"brush: java; auto-links: false;\">&lt;dependency&gt;\n        &lt;groupId&gt;us.codecraft&lt;/groupId&gt;\n        &lt;artifactId&gt;webmagic-core&lt;/artifactId&gt;\n        &lt;version&gt;0.4.2&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;us.codecraft&lt;/groupId&gt;\n        &lt;artifactId&gt;webmagic-extension&lt;/artifactId&gt;\n        &lt;version&gt;0.4.2&lt;/version&gt;\n    &lt;/dependency&gt;</pre> \n <span id=\"OSC_h4_3\"></span> \n <h4>项目结构</h4> \n <p>webmagic主要包括两个包：</p> \n <ul> \n  <li><p><strong>webmagic-core</strong></p> <p>webmagic核心部分，只包含爬虫基本模块和基本抽取器。webmagic-core的目标是成为网页爬虫的一个教科书般的实现。</p> </li> \n  <li><p><strong>webmagic-extension</strong></p> <p>webmagic的扩展模块，提供一些更方便的编写爬虫的工具。包括注解格式定义爬虫、JSON、分布式等支持。</p> </li> \n </ul> \n <p>webmagic还包含两个可用的扩展包，因为这两个包都依赖了比较重量级的工具，所以从主要包中抽离出来，这些包需要下载源码后自己编译：</p> \n <ul> \n  <li><p><strong>webmagic-saxon</strong></p> <p>webmagic与Saxon结合的模块。Saxon是一个XPath、XSLT的解析工具，webmagic依赖Saxon来进行XPath2.0语法解析支持。</p> </li> \n  <li><p><strong>webmagic-selenium</strong></p> <p>webmagic与Selenium结合的模块。Selenium是一个模拟浏览器进行页面渲染的工具，webmagic依赖Selenium进行动态页面的抓取。</p> </li> \n </ul> \n <p>在项目中，你可以根据需要依赖不同的包。</p> \n <span id=\"OSC_h3_4\"></span> \n <h3>不使用maven</h3> \n <p>不使用maven的用户，可以下载附带二进制jar包的版本(感谢<a href=\"http://www.oschina.net/\" rel=\"nofollow\">oschina</a>)：</p> \n <pre class=\"brush: java; auto-links: false;\">git clone http://git.oschina.net/flashsword20/webmagic.git</pre> \n <p>在<strong>bin/lib</strong>目录下，有项目依赖的所有jar包，直接在IDE里import即可。</p> \n <span id=\"OSC_h2_5\"></span> \n <h2>第一个爬虫</h2> \n <span id=\"OSC_h3_6\"></span> \n <h3>定制PageProcessor</h3> \n <p>PageProcessor是webmagic-core的一部分，定制一个PageProcessor即可实现自己的爬虫逻辑。以下是抓取osc博客的一段代码：</p> \n <pre class=\"brush: java; auto-links: false;\">public class OschinaBlogPageProcesser implements PageProcessor {\n\n        private Site site = Site.me().setDomain(&quot;my.oschina.net&quot;)\n           .addStartUrl(&quot;http://my.oschina.net/flashsword/blog&quot;);\n\n        @Override\n        public void process(Page page) {\n            List&lt;String&gt; links = page.getHtml().links().regex(&quot;http://my\\\\.oschina\\\\.net/flashsword/blog/\\\\d+&quot;).all();\n            page.addTargetRequests(links);\n            page.putField(&quot;title&quot;, page.getHtml().xpath(&quot;//div[@class='BlogEntity']/div[@class='BlogTitle']/h1&quot;).toString());\n            page.putField(&quot;content&quot;, page.getHtml().$(&quot;div.content&quot;).toString());\n            page.putField(&quot;tags&quot;,page.getHtml().xpath(&quot;//div[@class='BlogTags']/a/text()&quot;).all());\n        }\n\n        @Override\n        public Site getSite() {\n            return site;\n\n        }\n\n        public static void main(String[] args) {\n            Spider.create(new OschinaBlogPageProcesser())\n                 .pipeline(new ConsolePipeline()).run();\n        }\n    }</pre> \n <p>这里通过page.addTargetRequests()方法来增加要抓取的URL，并通过page.putField()来保存抽取结果。page.getHtml().xpath()则是按照某个规则对结果进行抽取，这里抽取支持链式调用。调用结束后，toString()表示转化为单个String，all()则转化为一个String列表。</p> \n <p>Spider是爬虫的入口类。Pipeline是结果输出和持久化的接口，这里ConsolePipeline表示结果输出到控制台。</p> \n <p>执行这个main方法，即可在控制台看到抓取结果。webmagic默认有3秒抓取间隔，请耐心等待。你可以通过site.setSleepTime(int)修改这个值。site还有一些修改抓取属性的方法。</p> \n <span id=\"OSC_h4_7\"></span> \n <h4>使用注解</h4> \n <p>webmagic-extension包括了注解方式编写爬虫的方法，只需基于一个POJO增加注解即可完成一个爬虫。以下仍然是抓取oschina博客的一段代码，功能与OschinaBlogPageProcesser完全相同：</p> \n <pre class=\"brush: java; auto-links: false;\">@TargetUrl(&quot;http://my.oschina.net/flashsword/blog/\\\\d+&quot;)\n    public class OschinaBlog {\n\n        @ExtractBy(&quot;//title&quot;)\n        private String title;\n\n        @ExtractBy(value = &quot;div.BlogContent&quot;,type = ExtractBy.Type.Css)\n        private String content;\n\n        @ExtractBy(value = &quot;//div[@class='BlogTags']/a/text()&quot;, multi = true)\n        private List&lt;String&gt; tags;\n\n        @Formatter(&quot;yyyy-MM-dd HH:mm&quot;)\n        @ExtractBy(&quot;//div[@class='BlogStat']/regex('\\\\d+-\\\\d+-\\\\d+\\\\s+\\\\d+:\\\\d+')&quot;)\n        private Date date; \n\n        public static void main(String[] args) {\n            OOSpider.create(\n                Site.me().addStartUrl(&quot;http://my.oschina.net/flashsword/blog&quot;),\n                new ConsolePageModelPipeline(), OschinaBlog.class).run();\n        }\n    }</pre> \n <p>这个例子定义了一个Model类，Model类的字段'title'、'content'、'tags'均为要抽取的属性。这个类在Pipeline里是可以复用的。</p> \n <p>注解的详细使用方式见后文中的webmagic-extension注解模块。</p> \n <div></div> \n <span id=\"OSC_h2_8\"></span> \n <h2>模块详细介绍</h2> \n <span id=\"OSC_h2_9\"></span> \n <h2>webmagic-core</h2> \n <p>webmagic-core是爬虫的核心框架，只包括一个爬虫各功能模块的核心功能。webmagic-core的目标是成为网页爬虫的一个教科书般的实现。</p> \n <p>此节部分内容摘自作者的博文 <br /><a href=\"http://my.oschina.net/flashsword/blog/145796\" rel=\"nofollow\">webmagic的设计机制及原理-如何开发一个Java爬虫</a>。</p> \n <span id=\"OSC_h3_10\"></span> \n <h3>webmagic-core的模块划分</h3> \n <p>webmagic-core参考了scrapy的模块划分，分为Spider(整个爬虫的调度框架)、Downloader(页面下载)、PageProcessor(链接提取和页面分析)、Scheduler(URL管理)、Pipeline(离线分析和持久化)几部分。只不过scrapy通过middleware实现扩展，而webmagic则通过定义这几个接口，并将其不同的实现注入主框架类Spider来实现扩展。</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fcode4craft.github.io%2Fimages%2Fposts%2Fwebmagic.png\" alt=\"image\" /></p> \n <div></div> \n <span id=\"OSC_h4_11\"></span> \n <h4>Spider类(核心调度)</h4> \n <p><strong>Spider</strong>是爬虫的入口类，Spider的接口调用采用了链式的API设计，其他功能全部通过接口注入Spider实现，下面是启动一个比较复杂的Spider的例子。</p> \n <pre class=\"brush: java; auto-links: false;\">Spider.create(sinaBlogProcessor)\n    .scheduler(new FileCacheQueueScheduler(&quot;/data/temp/webmagic/cache/&quot;))\n    .pipeline(new FilePipeline())\n    .thread(10).run();</pre> \n <p>Spider的核心处理流程非常简单，代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">private void processRequest(Request request) {\n        Page page = downloader.download(request, this);\n        if (page == null) {\n            sleep(site.getSleepTime());\n            return;\n        }\n        pageProcessor.process(page);\n        addRequest(page);\n        for (Pipeline pipeline : pipelines) {\n            pipeline.process(page, this);\n        }\n        sleep(site.getSleepTime());\n    }</pre> \n <p>Spider还包括一个方法test(String url)，该方法只抓取一个单独的页面，用于测试抽取效果。</p> \n <span id=\"OSC_h4_12\"></span> \n <h4>PageProcessor(页面分析及链接抽取)</h4> \n <p>页面分析是垂直爬虫中需要定制的部分。在webmagic-core里，通过实现<strong>PageProcessor</strong>接口来实现定制爬虫。PageProcessor有两个核心方法：public void process(Page page)和public Site getSite() 。</p> \n <ul> \n  <li><p>public void process(Page page)</p> <p>通过对<strong>Page</strong>对象的操作，实现爬虫逻辑。Page对象包括两个最重要的方法：addTargetRequests()可以添加URL到待抓取队列，put()可以将结果保存供后续处理。 <br />Page的数据可以通过Page.getHtml()和Page.getUrl()获取。</p> </li> \n  <li><p>public Site getSite()</p> <p><strong>Site</strong>对象定义了爬虫的域名、起始地址、抓取间隔、编码等信息。</p> </li> \n </ul> \n <p><strong>Selector</strong>是webmagic为了简化页面抽取开发的独立模块，是webmagic-core的主要着力点。这里整合了CSS Selector、XPath和正则表达式，并可以进行链式的抽取。</p> \n <pre class=\"brush: java; auto-links: false;\">//content是用别的爬虫工具抽取到的正文\n    List&lt;String&gt; links = page.getHtml()\n    .$(&quot;div.title&quot;)  //css 选择，Java里虽然很少有$符号出现，不过貌似$作为方法名是合法的\n    .xpath(&quot;//@href&quot;)  //提取链接\n    .regex(&quot;.*blog.*&quot;) //正则匹配过滤\n    .all(); //转换为string列表</pre> \n <p>webmagic包括一个对于页面正文的自动抽取的类<strong>SmartContentSelector</strong>。相信用过Evernote Clearly都会对其自动抽取正文的技术印象深刻。这个技术又叫<strong>Readability</strong>。当然webmagic对Readability的实现还比较粗略，但是仍有一些学习价值。</p> \n <p>webmagic的XPath解析使用了作者另一个开源项目：基于Jsoup的XPath解析器<a href=\"https://github.com/code4craft/xsoup\" rel=\"nofollow\">Xsoup</a>，Xsoup对XPath的语法进行了一些扩展，支持一些自定义的函数。这些函数的使用方式都是在XPath末尾加上<code>/name-of-function()</code>，例如：<code>&quot;//div[@class='BlogStat']/regex('\\\\d+-\\\\d+-\\\\d+\\\\s+\\\\d+:\\\\d+')&quot;</code>。</p> \n <table> \n  <tbody> \n   <tr> \n    <td>函数</td> \n    <td>说明</td> \n   </tr> \n   <tr> \n    <td>text(n)</td> \n    <td>第n个文本节点(0表示取所有)</td> \n   </tr> \n   <tr> \n    <td>allText()</td> \n    <td>包括子节点的所有文本</td> \n   </tr> \n   <tr> \n    <td>tidyText()</td> \n    <td>包括子节点的所有文本，并进行智能换行</td> \n   </tr> \n   <tr> \n    <td>html()</td> \n    <td>内部html(不包括当前标签本身)</td> \n   </tr> \n   <tr> \n    <td>outerHtml()</td> \n    <td>外部html(包括当前标签本身)</td> \n   </tr> \n   <tr> \n    <td>regex(@attr,expr,group)</td> \n    <td>正则表达式，@attr是抽取的属性(可省略)，expr是表达式内容，group为捕获组(可省略，默认为0)</td> \n   </tr> \n  </tbody> \n </table> \n <p>基于Saxon，webmagic提供了XPath2.0语法的支持。XPath2.0语法支持内部函数、逻辑控制等，是一门完整的语言，如果你熟悉XPath2.0语法，倒是不妨一试(需要引入<strong>webmagic-saxon</strong>包)。</p> \n <p><strong>webmagic-samples</strong>包里有一些为某个站点定制的PageProcessor，供学习之用。</p> \n <span id=\"OSC_h4_13\"></span> \n <h4>Downloader(页面下载)</h4> \n <p><strong>Downloader</strong>是webmagic中下载页面的接口，主要方法：</p> \n <ul> \n  <li><p>public Page download(Request request, Task task)</p> <p><strong>Request</strong>对象封装了待抓取的URL及其他信息，而Page则包含了页面下载后的Html及其他信息。Task是一个包装了任务对应的Site信息的抽象接口。</p> </li> \n  <li><p>public void setThread(int thread)</p> <p>因为Downloader一般会涉及连接池等功能，而这些功能与多线程密切相关，所以定义了此方法。</p> </li> \n </ul> \n <p>目前有几个Downloader的实现：</p> \n <ul> \n  <li><p>HttpClientDownloader</p> <p>集成了<strong>Apache HttpClient</strong>的Downloader。Apache HttpClient(4.0后整合到HttpCompenent项目中)是强大的Java http下载器，它支持自定义HTTP头(对于爬虫比较有用的就是User-agent、cookie等)、自动redirect、连接复用、cookie保留、设置代理等诸多强大的功能。</p> </li> \n  <li><p>SeleniumDownloader</p> <p>对于一些Javascript动态加载的网页，仅仅使用http模拟下载工具，并不能取到页面的内容。这方面的思路有两种：一种是抽丝剥茧，分析js的逻辑，再用爬虫去重现它；另一种就是：内置一个浏览器，直接获取最后加载完的页面。<strong>webmagic-selenium</strong>包中整合了Selenium到SeleniumDownloader，可以直接进行动态加载页面的抓取。使用selenium需要安装一些native的工具，具体步骤可以参考作者的博文<a href=\"http://my.oschina.net/flashsword/blog/147334\" rel=\"nofollow\">使用Selenium来抓取动态加载的页面</a></p> </li> \n </ul> \n <span id=\"OSC_h4_14\"></span> \n <h4>Scheduler(URL管理)</h4> \n <p><strong>Scheduler</strong>是webmagic的管理模块，通过实现Scheduler可以定制自己的URL管理器。Scheduler包括两个主要方法：</p> \n <ul> \n  <li><p>public void push(Request request,Task task)</p> <p>将待抓取URL加入Scheduler。Request对象是对URL的一个封装，还包括优先级、以及一个供存储数据的Map。Task仍然用于区分不同任务，在多个任务公用一个Scheduler时可以此进行区分。</p> </li> \n  <li><p>public Request poll(Task task)</p> <p>从Scheduler里取出一条请求，并进行后续执行。</p> </li> \n </ul> \n <p>webmagic目前有三个Scheduler的实现：</p> \n <ul> \n  <li><p>QueueScheduler</p> <p>一个简单的内存队列，速度较快，并且是线程安全的。</p> </li> \n  <li><p>FileCacheQueueScheduler</p> <p>使用文件保存队列，它可以用于耗时较长的下载任务，在任务中途停止后(手动停止或者程序崩溃)，下次执行仍然从中止的URL开始继续爬取。</p> </li> \n  <li><p>RedisScheduler</p> <p>使用redis存储URL队列。通过使用同一台redis服务器存储URL，webmagic可以很容易的在多机部署，从而达到分布式爬虫的效果。</p> </li> \n </ul> \n <span id=\"OSC_h4_15\"></span> \n <h4>Pipeline(后续处理和持久化)</h4> \n <p><strong>Pipeline</strong>是最终抽取结果进行输出和持久化的接口。它只包括一个方法：</p> \n <ul> \n  <li><p>public void process(ResultItems resultItems,Task task)</p> <p><strong>ResultItems</strong>是集成了抽取结果的对象。通过ResultItems.get(key)可以获取抽取结果。Task同样是用于区分不同任务的对象。</p> </li> \n </ul> \n <p>webmagic包括以下几个Pipeline的实现：</p> \n <ul> \n  <li><p>ConsolePipeline</p> <p>直接输出结果到控制台，测试时使用。</p> </li> \n  <li><p>FilePipeline</p> <p>输出结果到文件，每个URL单独保存到一个页面，以URL的MD5结果作为文件名。通过构造函数<code>public FilePipeline(String path)</code>定义存储路径，<strong>以下使用文件持久化的类，多数都使用此方法指定路径</strong>。</p> </li> \n  <li><p>JsonFilePipeline</p> <p>以JSON输出结果到文件(.json后缀)，其他与FilePipeline相同。</p> </li> \n </ul> \n <p>webmagic目前不支持持久化到数据库，但是结合其他工具，持久化到数据库也是很容易的。这里不妨看一下<a href=\"http://www.oschina.net/code/snippet_190591_23456\" rel=\"nofollow\">webmagic结合JFinal持久化到数据库的一段代码</a>。因为JFinal目前还不支持maven，所以这段代码并没有放到webmagic-samples里来。</p> \n <div></div> \n <span id=\"OSC_h2_16\"></span> \n <h2>webmagic-extension</h2> \n <p>webmagic-extension是为了开发爬虫更方便而实现的一些功能模块。这些功能完全基于webmagic-core的框架，包括注解形式编写爬虫、分页、分布式等功能。</p> \n <span id=\"OSC_h3_17\"></span> \n <h3>注解模块</h3> \n <p>webmagic-extension包括注解模块。为什么会有注解方式？</p> \n <p>因为PageProcessor的方式灵活、强大，但是没有解决两个问题：</p> \n <ul> \n  <li>对于一个站点，如果想抓取多种格式的URL，那么必须在PageProcesser中写判断逻辑，代码难以管理。</li> \n  <li>抓取结果没有对应Model，并不符合Java程序开发习惯，与一些框架也无法很好整合。</li> \n </ul> \n <p>注解的核心是Model类，本身是一个POJO，这个Model类用于传递、保存页面最终抓取结果数据。注解方式直接将抽取与数据绑定，以便于编写和维护。</p> \n <p>注解方式其实也是通过一个PageProcessor的实现–ModelPageProcessor完成，因此对webmagic-core代码没有任何影响。仍然以抓取OschinaBlog的程序为例：</p> \n <pre class=\"brush: java; auto-links: false;\">@TargetUrl(&quot;http://my.oschina.net/flashsword/blog/\\\\d+&quot;)\n    public class OschinaBlog {\n\n        @ExtractBy(&quot;//title&quot;)\n        private String title;\n\n        @ExtractBy(value = &quot;div.BlogContent&quot;,type = ExtractBy.Type.Css)\n        private String content;\n\n        @ExtractBy(value = &quot;//div[@class='BlogTags']/a/text()&quot;, multi = true)\n        private List&lt;String&gt; tags;\n\n        @Formatter(&quot;yyyy-MM-dd HH:mm&quot;)\n        @ExtractBy(&quot;//div[@class='BlogStat']/regex('\\\\d+-\\\\d+-\\\\d+\\\\s+\\\\d+:\\\\d+')&quot;)\n        private Date date; \n\n        public static void main(String[] args) {\n            OOSpider.create(\n                Site.me().addStartUrl(&quot;http://my.oschina.net/flashsword/blog&quot;),\n                new ConsolePageModelPipeline(), OschinaBlog.class).run();\n        }\n    }</pre> \n <p>注解部分包括以下内容：</p> \n <ul> \n  <li><span id=\"OSC_h4_18\"></span><h4>TargetUrl</h4> <p>“TargetUrl&quot;表示这个Model对应要抓取的URL，它包含两层意思：符合这个条件的URL会被加入抓取队列；符合这个条件的URL会被这个Model抓取。TargetUrl可以<strong>sourceRegion</strong>指定提取URL的区域(仅支持XPath)。</p> <p>TargetUrl使用了正则表达式，匹配 “http://my.oschina.net/flashsword/blog/150039” 格式的URL。webmagic对正则表达式进行了修改，“.“仅表示字符”.“而不代表任意字符，而”*“则代表了”.*“，例如&quot;http://*.oschina.net/*“代表了oschina所有的二级域名下的URL。</p> <p>与TargetUrl相似的还有<strong>HelpUrl</strong>，HelpUrl表示：仅仅抓取该URL用作链接提取，并不对它进行内容抽取。例如博客正文页对应TargetUrl，而列表页则对应HelpUrl。</p> </li> \n  <li><span id=\"OSC_h4_19\"></span><h4>ExtractBy</h4> \n   <ul> \n    <li><span id=\"OSC_h4_20\"></span><h4>用于字段</h4> <p>“ExtractBy&quot;可用于类以及字段。用于字段时，定义了字段抽取的规则。抽取的规则默认使用<a href=\"http://www.w3school.com.cn/xpath/\" rel=\"nofollow\"><strong>XPath</strong></a>，也可以选择使用CSS Selector、正则表达式(通过设置type)。</p> <p>ExtractBy还有几个扩展属性。<strong>multi</strong>表示是否抽取列表，当然，设置为multi时，你需要一个List字段去容纳它。<strong>notnull</strong>则表示，此字段不允许为null，若为null则放弃整个对象。</p> </li> \n    <li><span id=\"OSC_h4_21\"></span><h4>用于类</h4> <p>“ExtractBy&quot;用于类时，则限定了字段抽取的区域。用于类时仍支持multi，multi则表示一个页面可以抽取到多个对象。</p> </li> \n    <li><span id=\"OSC_h4_22\"></span><h4>ExtractByUrl</h4> <p>ExtractByUrl表示从URL中抽取信息，只支持正则表达式。</p> </li> \n    <li><span id=\"OSC_h4_23\"></span><h4>ComboExtract</h4> <p>ComboExtract是对ExtractBy的一个补充，支持将对个抽取规则用and或者or的形式组合起来。</p> </li> \n   </ul> </li> \n  <li><span id=\"OSC_h4_24\"></span><h4>类型转换</h4> <p>webmagic的注解模式支持对抽取结果进行类型转换，这样抽取结果并不需要是String类型，而可以是任意类型。webmagic内置了基本类型的支持(需要保证抽取结果能够被转换到对应类型)。</p> </li> \n </ul> \n <pre class=\"brush: java; auto-links: false;\">@ExtractBy(&quot;//ul[@class='pagehead-actions']/li[1]//a[@class='social-count js-social-count']/text()&quot;)\n        private int star;</pre> \n <p>抽取结果也可以是<code>java.util.Date</code>类型，不过需要指定日期格式化的方式：</p> \n <pre class=\"brush: java; auto-links: false;\">@Formatter(&quot;yyyy-MM-dd HH:mm&quot;)\n        @ExtractBy(&quot;//div[@class='BlogStat']/regex('\\\\d+-\\\\d+-\\\\d+\\\\s+\\\\d+:\\\\d+')&quot;)\n        private Date date;</pre> \n <p>你也可以编写一个实现<code>ObjectFormatter</code>接口的类，进行自己的类型解析。要使用自己的类，需要调用<code>ObjectFormatters.put()</code>对这个类进行注册。</p> \n <ul> \n  <li><span id=\"OSC_h4_25\"></span><h4>AfterExtractor</h4> <p>AfterExtractor接口是对注解方式抽取能力不足的补充。实现AfterExtractor接口后，会在<strong>使用注解方式填充完字段后</strong>调用<strong>afterProcess()</strong>方法，在这个方法中可以直接访问已抽取的字段、补充需要抽取的字段，甚至做一些简单的输出和持久化操作(并不是很建议这么做)。这部分可以参考<a href=\"http://www.oschina.net/code/snippet_190591_23456\" rel=\"nofollow\">webmagic结合JFinal持久化到数据库的一段代码</a>。</p> </li> \n  <li><span id=\"OSC_h4_26\"></span><h4>OOSpider</h4> <p>OOSpider是注解式爬虫的入口，这里调用<strong>create()</strong>方法将OschinaBlog这个类加入到爬虫的抽取中，这里是可以传入多个类的，例如：</p> </li> \n </ul> \n <pre class=\"brush: java; auto-links: false;\">OOSpider.create(\n            Site.me().addStartUrl(&quot;http://www.oschina.net&quot;),\n            new ConsolePageModelPipeline(),\n            OschinaBlog.clas,OschinaAnswer.class).run();</pre> \n <pre class=\"brush: java; auto-links: false;\">OOSpider会根据TargetUrl调用不同的Model进行解析。</pre> \n <ul> \n  <li><span id=\"OSC_h4_27\"></span><h4>PageModelPipeline</h4> <p>可以通过定义PageModelPipeline来选择结果输出方式。这里new ConsolePageModelPipeline()是PageModelPipeline的一个实现，会将结果输出到控制台。</p> <p>PageModelPipeline目前包括<code>ConsolePageModelPipeline</code>、<code>JsonFilePageModelPipeline</code>、<code>FilePageModelPipeline</code>三个实现。</p> </li> \n  <li><span id=\"OSC_h4_28\"></span><h4>分页</h4> <p>处理单项数据分页(例如单条新闻多个页面)是爬虫一个比较头疼的问题。webmagic目前对于分页的解决方案是：在注解模式下，Model通过实现<strong>PagedModel</strong>接口，并引入PagedPipeline作为第一个Pipeline来实现。具体可以参考webmagic-samples中抓取网易新闻的代码：<strong>us.codecraft.webmagic.model.samples.News163</strong>。</p> <p>关于分页，这里有一篇对于webmagic分页实现的详细说明的文章<a href=\"http://my.oschina.net/flashsword/blog/150039\" rel=\"nofollow\">关于爬虫实现分页的一些思考</a>。 <br />目前分页功能还没有分布式实现，如果实现RedisScheduler进行分布式爬取，请不要使用分页功能。</p> </li> \n </ul> \n <span id=\"OSC_h3_29\"></span> \n <h3>分布式</h3> \n <p>webmagic-extension中，通过redis来管理URL，达到分布式的效果。但是对于分布式爬虫，仅仅程序能够分布式运行，还满足不了大规模抓取的需要，webmagic可能后期会加入一些任务管理和监控的功能，也欢迎各位用户为webmagic提交代码，做出贡献。</p>\n</div>","description":"2013-12-01 20:54","name":"webmagic使用手册","type":"text"},{"contents":"<h2>webmagic新版文档大纲</h2><div class=\"BlogContent\">\n <span id=\"OSC_h1_1\"></span> \n <h1>webmagic新版文档大纲</h1> \n <p>有朋友反应webmagic之前的文档不够直观，我决定从需求场景出发来组织文档。希望大家多多给出建议。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>1. 基本的爬虫</h2> \n <span id=\"OSC_h3_3\"></span> \n <h3>1.1 抽取内容(xpath, regex, css selector, jsonpath)</h3> \n <span id=\"OSC_h3_4\"></span> \n <h3>1.2 发现链接</h3> \n <span id=\"OSC_h3_5\"></span> \n <h3>1.3 处理多个页面</h3> \n <span id=\"OSC_h2_6\"></span> \n <h2>2. 使用注解</h2> \n <span id=\"OSC_h3_7\"></span> \n <h3>2.1 抽取内容(xpath, regex, css selector, jsonpath)</h3> \n <span id=\"OSC_h3_8\"></span> \n <h3>2.2 发现链接</h3> \n <span id=\"OSC_h3_9\"></span> \n <h3>2.3 处理多个页面</h3> \n <span id=\"OSC_h3_10\"></span> \n <h3>2.4 在POJO中实现复杂逻辑</h3> \n <span id=\"OSC_h2_11\"></span> \n <h2>3. 配置爬虫</h2> \n <span id=\"OSC_h3_12\"></span> \n <h3>3.1 抓取频率</h3> \n <span id=\"OSC_h3_13\"></span> \n <h3>3.2 编码</h3> \n <span id=\"OSC_h3_14\"></span> \n <h3>3.3 代理</h3> \n <span id=\"OSC_h3_15\"></span> \n <h3>3.4 设置cookie/UA等http头信息</h3> \n <span id=\"OSC_h3_16\"></span> \n <h3>3.5 重试机制</h3> \n <span id=\"OSC_h3_17\"></span> \n <h3>3.6 多线程</h3> \n <span id=\"OSC_h2_18\"></span> \n <h2>4. 爬虫的启动和终止</h2> \n <span id=\"OSC_h3_19\"></span> \n <h3>4.1 启动爬虫</h3> \n <span id=\"OSC_h3_20\"></span> \n <h3>4.2 终止爬虫</h3> \n <span id=\"OSC_h3_21\"></span> \n <h3>4.3 设置执行时间</h3> \n <span id=\"OSC_h3_22\"></span> \n <h3>4.4 定期抓取</h3> \n <span id=\"OSC_h2_23\"></span> \n <h2>5. 管理URL</h2> \n <span id=\"OSC_h3_24\"></span> \n <h3>5.1 手动添加URL</h3> \n <span id=\"OSC_h3_25\"></span> \n <h3>5.2 在URL中保存信息</h3> \n <span id=\"OSC_h3_26\"></span> \n <h3>5.3 几种URL管理方式</h3> \n <span id=\"OSC_h3_27\"></span> \n <h3>5.4 自己管理爬虫的URL</h3> \n <span id=\"OSC_h2_28\"></span> \n <h2>6. 持久化</h2> \n <span id=\"OSC_h3_29\"></span> \n <h3>6.1 输出到控制台</h3> \n <span id=\"OSC_h3_30\"></span> \n <h3>6.2 保存到文件</h3> \n <span id=\"OSC_h3_31\"></span> \n <h3>6.3 JSON格式输出</h3> \n <span id=\"OSC_h3_32\"></span> \n <h3>6.4 自定义持久化方式(mysql/mongodb…)</h3> \n <span id=\"OSC_h2_33\"></span> \n <h2>7. 实例</h2> \n <span id=\"OSC_h3_34\"></span> \n <h3>7.1 基本的列表+详情页的抓取</h3> \n <span id=\"OSC_h3_35\"></span> \n <h3>7.2 抓取动态页面</h3> \n <span id=\"OSC_h3_36\"></span> \n <h3>7.3 分页抓取</h3> \n <span id=\"OSC_h3_37\"></span> \n <h3>7.4 定期抓取</h3>\n</div>","description":"2014-01-15 14:41","name":"webmagic新版文档大纲","type":"text"},{"contents":"<h2>WebMagic Avalon设计草图</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>创建爬虫</h2> \n <p>这里可以配置爬虫的基本信息。</p> \n <p>爬虫的抽取逻辑<code>PageProcessor</code>采用模板化的思想，编写一个Java文件之后，提供一些属性注入点，程序会自动根据注入点，产生表单。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2014/0227/233628_gnVv_190591.png\" alt=\"create spider\" /></p> \n <span id=\"OSC_h2_2\"></span> \n <h2>管理爬虫</h2> \n <p>这里可以查看爬虫运行状态，并对爬虫进行管理。</p> \n <p>worker是正在运行的机器。</p> \n <p>爬虫状态包括总共url，下载页面数，失败数等。失败数可以点击查看详细结果及异常。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2014/0227/233650_7bll_190591.png\" alt=\"spider manage\" /></p>\n</div>","description":"2014-02-25 11:56","name":"WebMagic Avalon设计草图","type":"text"}],"name":"webmagic","type":"dir"},{"contents":[{"contents":"<h2>关于HTTP keep-alive的实验</h2><div class=\"BlogContent\">\n <h1><span style=\"font-size:14px;line-height:1.6em;\">&nbsp; &nbsp;前面一篇文章提到，HTTP1.1中持久连接已经是默认配置，除非设置Connection为close，否则默认都会进行持久连接。但是我们知道事实标准跟教科书还是可能会有一定差距的，所以不妨自己尝试一下。</span></h1> \n <div class=\"rich-content\"> \n  <p>&nbsp;&nbsp;&nbsp;我们知道，TCP建立连接时会进行三次握手，而握手是以一方发送一个SYN为开始的。下载抓包工具Wireshark之后，进行抓包调试。在Java里实现了一段模拟请求的代码：</p> \n  <div> \n   <div class=\"syntaxhighlighter java\"> \n    <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n     <tbody> \n      <tr> \n       <td> \n        <div class=\"line number1 index0 alt2\">\n          1 \n        </div> \n        <div class=\"line number2 index1 alt1\">\n          2 \n        </div> \n        <div class=\"line number3 index2 alt2\">\n          3 \n        </div> \n        <div class=\"line number4 index3 alt1\">\n          4 \n        </div> \n        <div class=\"line number5 index4 alt2\">\n          5 \n        </div> \n        <div class=\"line number6 index5 alt1\">\n          6 \n        </div> \n        <div class=\"line number7 index6 alt2\">\n          7 \n        </div> \n        <div class=\"line number8 index7 alt1\">\n          8 \n        </div> \n        <div class=\"line number9 index8 alt2\">\n          9 \n        </div> \n        <div class=\"line number10 index9 alt1\">\n          10 \n        </div> \n        <div class=\"line number11 index10 alt2\">\n          11 \n        </div> \n        <div class=\"line number12 index11 alt1\">\n          12 \n        </div> \n        <div class=\"line number13 index12 alt2\">\n          13 \n        </div> \n        <div class=\"line number14 index13 alt1\">\n          14 \n        </div> \n        <div class=\"line number15 index14 alt2\">\n          15 \n        </div> \n        <div class=\"line number16 index15 alt1\">\n          16 \n        </div> \n        <div class=\"line number17 index16 alt2\">\n          17 \n        </div> \n        <div class=\"line number18 index17 alt1\">\n          18 \n        </div> \n        <div class=\"line number19 index18 alt2\">\n          19 \n        </div> \n        <div class=\"line number20 index19 alt1\">\n          20 \n        </div> \n        <div class=\"line number21 index20 alt2\">\n          21 \n        </div> \n        <div class=\"line number22 index21 alt1\">\n          22 \n        </div> \n        <div class=\"line number23 index22 alt2\">\n          23 \n        </div> \n        <div class=\"line number24 index23 alt1\">\n          24 \n        </div> \n        <div class=\"line number25 index24 alt2\">\n          25 \n        </div> \n        <div class=\"line number26 index25 alt1\">\n          26 \n        </div> \n        <div class=\"line number27 index26 alt2\">\n          27 \n        </div> \n        <div class=\"line number28 index27 alt1\">\n          28 \n        </div> \n        <div class=\"line number29 index28 alt2\">\n          29 \n        </div> \n        <div class=\"line number30 index29 alt1\">\n          30 \n        </div> \n        <div class=\"line number31 index30 alt2\">\n          31 \n        </div> \n        <div class=\"line number32 index31 alt1\">\n          32 \n        </div> \n        <div class=\"line number33 index32 alt2\">\n          33 \n        </div> \n        <div class=\"line number34 index33 alt1\">\n          34 \n        </div> \n        <div class=\"line number35 index34 alt2\">\n          35 \n        </div> \n        <div class=\"line number36 index35 alt1\">\n          36 \n        </div> \n        <div class=\"line number37 index36 alt2\">\n          37 \n        </div> \n        <div class=\"line number38 index37 alt1\">\n          38 \n        </div> \n        <div class=\"line number39 index38 alt2\">\n          39 \n        </div> \n        <div class=\"line number40 index39 alt1\">\n          40 \n        </div> \n        <div class=\"line number41 index40 alt2\">\n          41 \n        </div> \n        <div class=\"line number42 index41 alt1\">\n          42 \n        </div> \n        <div class=\"line number43 index42 alt2\">\n          43 \n        </div> \n        <div class=\"line number44 index43 alt1\">\n          44 \n        </div> \n        <div class=\"line number45 index44 alt2\">\n          45 \n        </div> \n        <div class=\"line number46 index45 alt1\">\n          46 \n        </div> \n        <div class=\"line number47 index46 alt2\">\n          47 \n        </div> \n        <div class=\"line number48 index47 alt1\">\n          48 \n        </div> \n        <div class=\"line number49 index48 alt2\">\n          49 \n        </div> \n        <div class=\"line number50 index49 alt1\">\n          50 \n        </div> \n        <div class=\"line number51 index50 alt2\">\n          51 \n        </div> \n        <div class=\"line number52 index51 alt1\">\n          52 \n        </div> \n        <div class=\"line number53 index52 alt2\">\n          53 \n        </div> </td> \n       <td> \n        <div class=\"container\"> \n         <div class=\"line number1 index0 alt2\"> \n          <code>package</code> \n          <code>test;</code> \n         </div> \n         <div class=\"line number2 index1 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>&nbsp; \n         </div> \n         <div class=\"line number3 index2 alt2\"> \n          <code>import</code> \n          <code>java.io.IOException;</code> \n         </div> \n         <div class=\"line number4 index3 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>&nbsp; \n         </div> \n         <div class=\"line number5 index4 alt2\"> \n          <code>import</code> \n          <code>org.apache.commons.httpclient.HttpClient;</code> \n         </div> \n         <div class=\"line number6 index5 alt1\"> \n          <code>import</code> \n          <code>org.apache.commons.httpclient.HttpException;</code> \n         </div> \n         <div class=\"line number7 index6 alt2\"> \n          <code>import</code> \n          <code>org.apache.commons.httpclient.SimpleHttpConnectionManager;</code> \n         </div> \n         <div class=\"line number8 index7 alt1\"> \n          <code>import</code> \n          <code>org.apache.commons.httpclient.methods.GetMethod;</code> \n         </div> \n         <div class=\"line number9 index8 alt2\"> \n          <code>import</code> \n          <code>org.junit.Test;</code> \n         </div> \n         <div class=\"line number10 index9 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>&nbsp; \n         </div> \n         <div class=\"line number11 index10 alt2\"> \n          <code>/**</code> \n         </div> \n         <div class=\"line number12 index11 alt1\"> \n          <code>&nbsp;</code> \n          <code>* TODO Comment of TestHttpClient</code> \n         </div> \n         <div class=\"line number13 index12 alt2\"> \n          <code>&nbsp;</code> \n          <code>* </code> \n         </div> \n         <div class=\"line number14 index13 alt1\"> \n          <code>&nbsp;</code> \n          <code>* <a href=\"http://my.oschina.net/arthor\" target=\"_blank\" rel=\"nofollow\">@author</a> yihua.huang</code> \n         </div> \n         <div class=\"line number15 index14 alt2\"> \n          <code>&nbsp;</code> \n          <code>* </code> \n         </div> \n         <div class=\"line number16 index15 alt1\"> \n          <code>&nbsp;</code> \n          <code>*/</code> \n         </div> \n         <div class=\"line number17 index16 alt2\"> \n          <code>public</code> \n          <code>class</code> \n          <code>TestHttpClient {</code> \n         </div> \n         <div class=\"line number18 index17 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>&nbsp; \n         </div> \n         <div class=\"line number19 index18 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code><a href=\"http://my.oschina.net/saff\" target=\"_blank\" rel=\"nofollow\">@Test</a> </code> \n         </div> \n         <div class=\"line number20 index19 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>public</code> \n          <code>void</code> \n          <code>testHeader() {</code> \n         </div> \n         <div class=\"line number21 index20 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>HttpClient httpClient = </code> \n          <code>new</code> \n          <code>HttpClient(</code> \n          <code>new</code> \n          <code>SimpleHttpConnectionManager(</code> \n          <code>true</code> \n          <code>));</code> \n         </div> \n         <div class=\"line number22 index21 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>httpClient.getHttpConnectionManager().getParams().setSoTimeout(</code> \n          <code>5000</code> \n          <code>);</code> \n         </div> \n         <div class=\"line number23 index22 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>httpClient.getHttpConnectionManager().getParams().setConnectionTimeout(</code> \n          <code>5000</code> \n          <code>);</code> \n         </div> \n         <div class=\"line number24 index23 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>GetMethod get = </code> \n          <code>new</code> \n          <code>GetMethod(</code> \n          <code>&quot;<a href=\"http://www.dianping.com/\" rel=\"nofollow\">http://www.dianping.com</a>&quot;</code> \n          <code>);</code> \n         </div> \n         <div class=\"line number25 index24 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>try</code> \n          <code>{</code> \n         </div> \n         <div class=\"line number26 index25 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>httpClient.executeMethod(get);</code> \n         </div> \n         <div class=\"line number27 index26 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>} </code> \n          <code>catch</code> \n          <code>(HttpException e) {</code> \n         </div> \n         <div class=\"line number28 index27 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>// TODO Auto-generated catch block</code> \n         </div> \n         <div class=\"line number29 index28 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>e.printStackTrace();</code> \n         </div> \n         <div class=\"line number30 index29 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>} </code> \n          <code>catch</code> \n          <code>(IOException e) {</code> \n         </div> \n         <div class=\"line number31 index30 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>// TODO Auto-generated catch block</code> \n         </div> \n         <div class=\"line number32 index31 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>e.printStackTrace();</code> \n         </div> \n         <div class=\"line number33 index32 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>}</code> \n         </div> \n         <div class=\"line number34 index33 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>try</code> \n          <code>{</code> \n         </div> \n         <div class=\"line number35 index34 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>Thread.sleep(</code> \n          <code>10000</code> \n          <code>);</code> \n         </div> \n         <div class=\"line number36 index35 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>} </code> \n          <code>catch</code> \n          <code>(InterruptedException e1) {</code> \n         </div> \n         <div class=\"line number37 index36 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>// TODO Auto-generated catch block</code> \n         </div> \n         <div class=\"line number38 index37 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>e1.printStackTrace();</code> \n         </div> \n         <div class=\"line number39 index38 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>}</code> \n         </div> \n         <div class=\"line number40 index39 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>get = </code> \n          <code>new</code> \n          <code>GetMethod(</code> \n          <code>&quot;<a href=\"http://www.dianping.com/\" rel=\"nofollow\">http://www.dianping.com</a>&quot;</code> \n          <code>);</code> \n         </div> \n         <div class=\"line number41 index40 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>get.setRequestHeader(</code> \n          <code>&quot;Connection&quot;</code> \n          <code>, </code> \n          <code>&quot;keep-alive&quot;</code> \n          <code>);</code> \n         </div> \n         <div class=\"line number42 index41 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>try</code> \n          <code>{</code> \n         </div> \n         <div class=\"line number43 index42 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>httpClient.executeMethod(get);</code> \n         </div> \n         <div class=\"line number44 index43 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>} </code> \n          <code>catch</code> \n          <code>(HttpException e) {</code> \n         </div> \n         <div class=\"line number45 index44 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>// TODO Auto-generated catch block</code> \n         </div> \n         <div class=\"line number46 index45 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>e.printStackTrace();</code> \n         </div> \n         <div class=\"line number47 index46 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>} </code> \n          <code>catch</code> \n          <code>(IOException e) {</code> \n         </div> \n         <div class=\"line number48 index47 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>// TODO Auto-generated catch block</code> \n         </div> \n         <div class=\"line number49 index48 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>e.printStackTrace();</code> \n         </div> \n         <div class=\"line number50 index49 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>}</code> \n         </div> \n         <div class=\"line number51 index50 alt2\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;</code> \n          <code>}</code> \n         </div> \n         <div class=\"line number52 index51 alt1\"> \n          <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>&nbsp; \n         </div> \n         <div class=\"line number53 index52 alt2\"> \n          <code>}</code> \n         </div> \n        </div> </td> \n      </tr> \n     </tbody> \n    </table> \n   </div> \n  </div> \n  <p>&nbsp;&nbsp;&nbsp;请求结果如下。可以看到，图一中共有两次HTTP请求，但是只建立了一次TCP连接，说明持久连接是有效的。而等到10秒之后(代码40行开始)的HTTP请求，又会重新建立连接，证明keep-alive已经过了超时时间。然后在头中加入Keep-Alive: 300，结果第二次请求仍然会重新连接，证明服务器端对于Keep-alive超时进行了配置，并不接受Keep-Alive: 300头。</p> \n  <p>&nbsp;&nbsp;&nbsp;</p> \n  <p>&nbsp;<span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201308/27074230_0fsu.jpeg\" width=\"519\" height=\"117\" /></span></p> \n  <p>图1 第一次请求，keep-alive生效</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201308/27074230_aUSk.jpeg\" width=\"483\" height=\"97\" /></span></p> \n  <p>图2 10秒后第二次请求，keep-alive过期</p> \n  <p>&nbsp;&nbsp;&nbsp;然后我们将Connection头设置为close，重试。发现确实建立了两次TCP连接。</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201308/27074230_Eslg.jpeg\" width=\"480\" height=\"201\" /></span></p> \n  <p>图3 设置Connection:close后，keep-alive无效</p> \n  <p>&nbsp;&nbsp;&nbsp;总结：</p> \n  <ol> \n   <li><p>Keep-alive只是HTTP1.0时代对持久化连接的叫法，目前HTTP1.1已经默认所有请求都是持久化的，RFC规范是正确的。</p> </li> \n   <li><p>头部不设置Connection: keep-alive，依然会进行持久化连接。</p> </li> \n   <li><p>如果设置Connection:close，则不进行持久化连接。</p> </li> \n   <li><p>目前连接过期时间在服务端设置，Keep-Alive头设置超时时间的做法已经不再有效。</p> </li> \n  </ol> \n </div>\n</div>","description":"2012-09-24 11:25","name":"关于HTTP keep-alive的实验","type":"text"},{"contents":"<h2>为什么修改hosts不立即生效？--浏览器DNS缓存机制分析</h2><div class=\"BlogContent\">\n <p>经常做Web开发的工程师，都会遇到需要将某个域名绑定到特定IP上，进行测试的情况。大家一般都会用修改hosts文件的方式来解决，但是经常也会遇到修改hosts不生效的情况，而且有时生效，有时不生效的情况也有发生，这到底是为什么呢？</p> \n <h3>起：DNS缓存机制</h3> \n <p>关于DNS缓存的机制，有一篇非常详细的文章<a href=\"http://igoro.com/archive/what-really-happens-when-you-navigate-to-a-url/\" rel=\"nofollow\">What really happens when you navigate to a URL</a>。</p> \n <p>简单来说，一条域名的DNS记录会在本地有两种缓存：浏览器缓存和操作系统(OS)缓存。在浏览器中访问的时候，会优先访问浏览器缓存，如果未命中则访问OS缓存，最后再访问DNS服务器(一般是ISP提供)，然后DNS服务器会递归式的查找域名记录，然后返回。</p> \n <p>DNS记录会有一个ttl值(time to live)，单位是秒，意思是这个记录最大有效期是多少。经过实验，OS缓存会参考ttl值，但是不完全等于ttl值，而<strong>浏览器DNS缓存的时间跟ttl值无关，每种浏览器都使用一个固定值</strong>。 <br />这里有一篇文章，做过详细的测试<a href=\"http://dyn.com/web-browser-dns-caching-bad-thing/\" rel=\"nofollow\">Why Web Browser DNS Caching Can Be A Bad Thing</a>：</p> \n <p><img src=\"/action/blog/img_proxy?url=http%3A%2F%2Fdyn.com%2Fwp-content%2Fuploads%2F2011%2F08%2Fdns-cache-table.png\" alt=\"image\" /></p> \n <p>后来我也做过测试，Mac下Chrome(23.0.1271.101)的DNS缓存时间是1分钟。Safari下DNS缓存时间大约为10秒。</p> \n <h3>解：hosts文件修改的原理</h3> \n <p>那么在修改hosts文件之后，发生了什么事情呢？这里不妨先提提Chrome下的一个工具：<a rel=\"nofollow\">chrome://net-internals/#dns</a>。这里列出了目前系统中的DNS缓存和Chrome中使用的情况。通过这个工具，可以看到：</p> \n <pre class=\"brush: java; auto-links: false;\">**在修改hosts文件后，所有OS中DNS缓存会被清空，而浏览器缓存则不发生变化。**</pre> \n <p>网上盛传<a rel=\"nofollow\">chrome://net-internals/#dns</a>下的&quot;Clear Host Cache&quot;可以清空DNS缓存，这里博主做了一个测试，<strong>这里清空的仅仅是OS的缓存，而并非浏览器DNS缓存。当某条DNS记录显示&quot;Expired&quot;的时候，才表示浏览器DNS缓存已经被清除。所以使用Clear Host Cache其实是没有用的。</strong></p> \n <p>那么回到最初的问题上来，为什么修改hosts文件之后，有时会立刻生效，有时却一直不生效呢？其实原因很简单，这是因为浏览器缓存的过期时间，是从某个域名上次查询DNS记录开始计算的。</p> \n <p>例如：我00秒的时候使用chrome访问过www.google.com.hk，此时浏览器DNS缓存产生，然后我修改了hosts文件，将www.google.com.hk指向本地127.0.0.1，然后在05秒的时候尝试再次访问这个地址，因为浏览器DNS缓存未过期，所以hosts修改无法体现出来。</p> \n <p>另一种情况下，我很久都没有访问www.baidu.com了，然后我修改了hosts文件，将其指向127.0.0.1，这时因为浏览器没有DNS缓存，所以会查询操作系统中的DNS缓存，结果此时hosts文件生效！</p> \n <p>前面也提到，Safari的浏览器DNS缓存时间大约为10秒，所以一般调试程序的时候，很多人都习惯修改hosts后，用Safari来调试，因为大部分情况下，修改hosts之后，浏览器DNS缓存已经失效了。</p> \n <p>那么怎么主动清除浏览器DNS缓存呢？博主目前也没有找到办法，测试过Chrome下的“清除缓存”选项，发现没有起到期望的效果。</p> \n <p>那么，就请在修改hosts之后，耐下心来，稍等几十秒吧。</p> \n <p>最后打个广告，博主正在开发一款比修改hosts更方便的DNS更改工具，应该能够在新年推出，敬请期待！</p>\n</div>","description":"2012-12-29 15:07","name":"为什么修改hosts不立即生效？--浏览器DNS缓存机制分析","type":"text"}],"name":"探耽求究","type":"dir"},{"contents":[{"contents":"<h2>分布式消息系统研究报告之Kafka</h2><div class=\"BlogContent\">\n <p>最近在看消息系统方面的东西。作为一个实践主义者，在看消息系统的各种实现时，不妨先粗略思考一下如何设计一个消息系统。我总觉出来有这么几个点(比较粗陋，以后继续补充)：</p> \n <ol> \n  <li><p>队列的存储和管理</p> <p>用什么方式存储消息决定了这个消息系统的最终表现。</p> </li> \n  <li><p>push还是pull</p> <p>producer没啥好说的，肯定是push，这里主要说consumer，pull的好处是可以根据consumer消费能力来处理消息，而push的好处则是实时性</p> </li> \n  <li><p>服务横向扩展</p> <p>是否存在单点？如何进行横向扩展的？failover如何做？</p> </li> \n  <li><p>保证一次消费</p> <p>消息不丢失；不会重复消费。</p> </li> \n  <li><p>topic模式</p> <p>是否支持单条message多个comsumer同时消费？用什么机制保证其工作？</p> </li> \n  <li><p>监控</p> <p>有没有监控手段？</p> </li> \n </ol> \n <p>好了，现在先来看Kafka。Kafka是LinkedIn的一个消息系统。主要用来处理日志并进行实时分析。 <br />Kafka有一篇翻译好的文章<a href=\"http://www.oschina.net/translate/kafka-design\" rel=\"nofollow\">http://www.oschina.net/translate/kafka-design</a>。</p> \n <p>Kafka要解决的是大吞吐量下的消息队列问题。</p> \n <ol> \n  <li>队列过长时，很多消息系统都不给力 <br />Kafka使用文件系统来进行存储，基本没有什么限制。文件都是立刻flush。</li> \n  <li>将消息打包成<strong>MessageSet</strong>，本身是Buffer的思想，例如nagle算法</li> \n  <li>消息压缩 支持GZIP</li> \n  <li>将消息强制排序，并用“最高水位标记”（high water mark）“来记录消费者状态</li> \n  <li>用groupId+atomicInteger代替guid来标识每一条消息，减少复杂性</li> \n </ol> \n <p>一些与结构无关的notes:</p> \n <ol> \n  <li><p>Java实用sendfile <code>FileChannel.transferTo</code></p> </li> \n  <li><p>flush与分页缓存的关系</p> </li> \n </ol> \n <blockquote> \n  <p>实际中这么做意味着，数据被传输到OS内核的页面缓存中了，OS随后会将这些数据刷新到磁盘的。 <br />这段话的思路可以考虑一下。</p> \n </blockquote> \n <ol> \n  <li><p>问题4的科学称呼：消息传递语义（Message delivery semantics）</p> \n   <blockquote> \n    <p>系统可以提供的几种可能的消息传递保障如下所示:</p> \n    <ol> \n     <li><p>最多一次—这种用于处理前段文字所述的第一种情况。消息在发出后立即标示为已使用，因此消息不会被发出去两次，但这在许多故障中都会导致消息丢失。</p> </li> \n     <li><p>至少一次—这种用于处理前文所述的第二种情况，系统保证每条消息至少会发送一次，但在有故障的情况下可能会导致重复发送。</p> </li> \n     <li><p>仅仅一次—这种是人们实际想要的，每条消息只会而且仅会发送一次。</p> </li> \n    </ol> \n    <p>这个问题已得到广泛的研究，属于“事务提交”问题的一个变种。提供仅仅一次语义的算法已经有了，两阶段或者三阶段提交法以及Paxos算法的一些变种就是其中的一些例子，但它们都有与生俱来的的缺陷。这些算法往往需要多个网络往返（round trip），可能也无法很好的保证其活性（liveness）（它们可能会导致无限期停机）。FLP结果给出了这些算法的一些基本的局限。</p> \n   </blockquote> </li> \n </ol>\n</div>","description":"2013-08-13 08:23","name":"分布式消息系统研究报告之Kafka","type":"text"},{"contents":"<h2>Jafka源码粗略解读之一</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>相关资料</h2> \n <p><a href=\"https://github.com/adyliu/jafka\" rel=\"nofollow\">Jafka</a>是sohu的adyliu开源的Kafka的完整Java实现(Kafka本身是用Scala的)。没有学习Scala的计划，又想研究研究MQ，那就不妨从Jafka入手了。</p> \n <p>关于Jafka有个slides，地址：<a href=\"https://www.slideshare.net/slideshow/embed_code/12795614\" rel=\"nofollow\">https://www.slideshare.net/slideshow/embed_code/12795614</a></p> \n <span id=\"OSC_h2_2\"></span> \n <h2>包结构</h2> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0814/083334_hfID_190591.png\" alt=\"jafka包结构\" /></p> \n <ul> \n  <li><p>api</p> <p>封装了消息等C/S通讯的对象。</p> </li> \n  <li><p>cluster</p> <p>将zk中的配置信息封装为对象。<code>Partition</code>=&gt;<code>Broker</code>=&gt;<code>Cluster</code>。</p> </li> \n  <li><p>common</p> <p>定义了一些异常和注解。几个注解<code>@ThreadSafe</code>、<code>ServerSide</code>等都是表示型的注解，没有特殊功能。</p> </li> \n  <li><p>console</p> <p>各种从控制台的启动方法。</p> </li> \n  <li><p>log</p> <p>log就是log了，没啥好说的。不过<code>DailyRollingStrategy</code>这些都是Log4j已有的功能，可以细看一下有什么更改。</p> </li> \n  <li><p>mx</p> <p>JMX相关。</p> </li> \n  <li><p>message</p> <p>消息体存储、压缩相关类。</p> </li> \n  <li><p>network</p> <p>网络传输相关。</p> </li> \n  <li><p>producer</p> <p>就是producer。</p> </li> \n  <li><p>server</p> <p>就是server。应该是对应broker。</p> </li> \n  <li><p>consumer</p> <p>就是consumer。</p> </li> \n </ul> \n <p>待续。</p>\n</div>","description":"2013-08-14 08:33","name":"Jafka源码粗略解读之一","type":"text"},{"contents":"<h2>Jafka源码粗略解读之二--关于JMX</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>JMX</h2> \n <p>Jafka里用到了JMX，之前也没用过，迅速突击了一下，感觉还是挺简单的：</p> \n <p>有一篇文章用一个例子介绍JMX怎么使用的，简洁明了：<a href=\"http://www.javalobby.org/java/forums/t49130.html\" rel=\"nofollow\">http://www.javalobby.org/java/forums/t49130.html</a>。就是声明一个bean，然后在MBeanServer中加入这个bean：</p> \n <pre class=\"brush: java; auto-links: false;\">ApplicationCache cache = new ApplicationCache();\n    MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();\n    ObjectName name = new ObjectName(&quot;org.javalobby.tnt.jmx:type=ApplicationCacheMBean&quot;);\n    mbs.registerMBean(cache, name);</pre> \n <p>这里ApplicationCache是个POJO,特殊的是它必须实现一个名为*MBean的接口。至此，一个JMX调用就完成了。在JConsole里连接，会找到对应方法。貌似setter和getter会被打包反射成一个field，其他都是方法调用。</p> \n <p>JMX的设计倒是非常符合Java OO的思想，使用也还算简洁，是个好东西。结构说明：<a href=\"http://pub.admc.com/howtos/jmx/architecture-chapt.html\" rel=\"nofollow\">http://pub.admc.com/howtos/jmx/architecture-chapt.html</a></p> \n <span id=\"OSC_h2_2\"></span> \n <h2>utils包</h2> \n <p>本来想从三大组件或者消息结构来看看Jafka的实现的，时间太零散，随便翻到了<code>utils</code>包，发现也有些惊喜：</p> \n <ul> \n  <li><a href=\"https://github.com/adyliu/jafka/blob/master/src/main/java/com/sohu/jafka/utils/ImmutableMap.java\" rel=\"nofollow\"><code>ImmutableMap</code></a>是个很有意思的Map初始化方式，使用static of(key,value)来初始化一个Map，倒是很好的弥补了Java初始化Map不便的问题。</li> \n </ul> \n <p>这个utils里多数是一些Java已有工具的简单封装，基本思路就是能用静态方法的用静态方法，把一些烦人的声明式异常异常的就把转化为RuntimeException(例如最烦人且无用的<code>UnsupportedEncodingException</code>)。代码实现比较精细，也是些通用工具，可以拿来用用。磨刀不误砍柴工，这样的思路倒是深得我心。</p>\n</div>","description":"2013-08-14 23:26","name":"Jafka源码粗略解读之二--关于JMX","type":"text"},{"contents":"<h2>Jafka源码粗略解读之三-producer</h2><div class=\"BlogContent\">\n <span id=\"OSC_h3_1\"></span> \n <h3>资料</h3> \n <p>今天看到研究Jafka的人还挺多的，比较优秀的是@FrankHui的<a href=\"http://my.oschina.net/ielts0909/blog?catalog=263107\" rel=\"nofollow\">Kafka系列文章</a>，还有<a href=\"http://my.oschina.net/rockybean\" target=\"_blank\" rel=\"nofollow\">@rockybean</a> 的<a href=\"http://rockybean.info/\" rel=\"nofollow\">博客</a>。这两个博客都写的很详细，条理清晰，图文并茂，比起我这种走马观花，笔记式的记录要好得多了。</p> \n <p>不过其实读源码每个人侧重点都不同，我还是继续记录我的。</p> \n <p>作为一个实用主义者，我觉得读源码有几种目的：</p> \n <ol> \n  <li>实际使用到该项目，想要弄清其原理，乃至于需要做定制化的</li> \n  <li>想要学习其设计方法、架构思想的</li> \n  <li>想要学习到一些代码实现上的技巧</li> \n </ol> \n <p>因为项目中也没有用到Jafka，而是公司内部基于mongodb和netty写的一个MQ，其实我倒是更倾向于3和2，然后再带着想法回头改进自己的。既然已经写了是粗略解读，倒是不怕人指责了。</p> \n <span id=\"OSC_h3_2\"></span> \n <h3>代码</h3> \n <p>Producer的入口可以看<code>ProducerTest</code>类。</p> \n <p>根据配置，send()可以使用sync和async方式。</p> \n <p><code>BlockingChannel</code>是封装了网络连接的类，底层是NIO的<code>SocketChannel</code>。</p> \n <p>这里颇有意思的是<code>BlockingChannel</code>的<code>send</code>方法：</p> \n <pre class=\"brush: java; auto-links: false;\">public int send(BoundedByteBufferSend bufferSend) throws IOException {\n    if (!isConnected()) {\n        throw new ClosedChannelException();\n    }\n    return bufferSend.writeCompletely(writeChannel);\n}</pre> \n <p>一般在涉及IO的开发中，我们都是直接拿一个流，然后用统一的序列化方式，最后写入buffer:</p> \n <pre class=\"brush: java; auto-links: false;\">writeChannel.write(encoder.encode(object))</pre> \n <p>而Jafka里的<code>BoundedByteBufferSend</code>很显然是Java里面动作名词化的实践之一，<code>bufferSend.writeCompletely(writeChannel)</code>的含义是：由<code>BoundedByteBufferSend</code>来决定如何组织数据并写入缓存，而不是在负责网络IO的<code>BlockingChannel</code>类里统一做处理。这样的方式引入了OO的特性，更为优雅和易维护。同样，<code>Request</code>也使用了这样的方法<code>writeTo</code>。</p> \n <p><code>MessageSet</code>是打包消息和传输的类。Jafka压缩消息的算法目前只实现了GZip，GZip在JDK里可以通过<code>GZIPInputStream</code>实现。</p> \n <span id=\"OSC_h3_3\"></span> \n <h3>协议</h3> \n <p>个人对于网络协议这一块比较感兴趣，既然看到了Message，就顺带对Jafka的传输协议进行一下分析。Jafka所用的协议应该是完全兼容Kafka的。</p> \n <p>在Jafka里，所有的请求都会首先带上4个字节的长度，然后才是内容(代码参考<code>BoundedByteBufferSend</code>里的<code>sizeBuffer</code>和<code>buffer</code>)：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0818/164613_k5UT_190591.png\" alt=\"Jafka message content\" /></p> \n <p>对于Producer，Producer的message格式如下(代码参考<code>MessageSet.createByteBuffer()</code>)：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0818/164232_yuZV_190591.png\" alt=\"Jafka Producer MessgeSet\" /></p> \n <p>在不压缩的情况下，消息仍然是按照4byte长度+内容的方式发送。而压缩是将所有消息混合压缩的。</p>\n</div>","description":"2013-08-18 16:51","name":"Jafka源码粗略解读之三-producer","type":"text"},{"contents":"<h2>Jafka源码粗略解读之四-log及其他</h2><div class=\"BlogContent\">\n <p>这几天琢磨其他的东西，Jafka源码搁置了，对其解读已经失去了兴趣。为了给自己一个交代，还是写个结尾系列吧。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>log</h2> \n <p>Log模块并非是log4j一套，而是Jafka的<strong>消息持久化系统</strong>，当初一扫而过，这么精华的部分竟然没注意到。</p> \n <p>不过所谓O(1)的持久化效率而并非多么复杂，其实就是在offset处append而已。这个最重要的部分，现在算是弄清楚了。</p> \n <p>剩余部分都没有仔细读过源码，有些是从<a href=\"http://rockybean.info/\" rel=\"nofollow\">rockybean</a>的博客中直接看的。</p> \n <p>Jafka对NIO这块的使用，相当值得参考和借鉴。不过对一些细节的处理，只有自己真正开发相关功能才能体会，于是决定先搁置了。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>关于MetaQ</h2> \n <p>MetaQ据说是淘宝内部的MQ，在Kafka上做了改进，可以看成跟Jafka同源。clone了一份MetaQ的代码，<a href=\"https://github.com/killme2008/Metamorphosis\" rel=\"nofollow\">https://github.com/killme2008/Metamorphosis</a>，粗略看了一下，看得出来是公司级别的开发，并非为开源而生，所以精细程度不如Jafka(指代码级别的技巧)，但是各种接口定义要更清晰一点。</p> \n <p>找了MetaQ的文档，对于MQ的特性和问题，做了一些总结，好好读了一遍： <br /><a href=\"http://alibaba.github.io/metaq/document/design/design.pdf\" rel=\"nofollow\">http://alibaba.github.io/metaq/document/design/design.pdf</a></p> \n <p>有几个东西，确实是实践出真知：</p> \n <ul> \n  <li><p>关于MQ的优先级</p> <p>MetaQ支持在内存中排序，但是放弃了磁盘系统的排序。</p> </li> \n  <li><p>关于重复消费(Exactly And Only Once)</p> <p>保证送达，不保证不重复，而在业务中判断重复，消息消费具有幂等性。</p> </li> \n </ul> \n <p>MetaQ在消息回溯时，使用了时间做offset。时间真是个好东西，分布式的排序和一致性，靠这个省了好多事。twitter的UUID服务Snowflake也用到了这个玩意，我在做邮件调度的时候也用到了这个东西，实在是好用得很。</p>\n</div>","description":"2013-08-24 23:48","name":"Jafka源码粗略解读之四-log及其他","type":"text"}],"name":"Jafka","type":"dir"},{"contents":[{"contents":"<h2>怎样设计一个安全的验证码--从验证码识别技术原理说起</h2><div class=\"BlogContent\">\n <div class=\"rich-content\"> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;最近公司发生了一些暴力破解密码的事件，很多用户的账号因此被盗。后来给所有登录入口都加上了验证码，但是仍然偶尔会出现了某些IP频繁登录的情况。是不是验证码被攻破了？本着相信科学的态度，因为以前也学过模式识别方面的东西，不妨从验证码识别技术开始来分析这些可能性。</p> \n  <h2>起源</h2> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;验证码英文叫CAPTCHA，全称是&quot;Completely Automated Public Turing test to tell Computers and Humans Apart&quot;。<em>图灵测试</em>(Turing test)是计算机科学的祖师爷阿兰.图灵提出来的，也是人工智能领域最著名的实验，意思就是：给你一个人A，一台计算机B，然后把另一个人(考官)放在另一个房间里，考官出题，然后通过A和B的回答，判断谁是计算机。如果考官分不出来哪个是计算机，B就算是通过了图灵测试，也就意味着拥有了真正意义的智能了。这是人工智能的终极目标，目前没有计算机通过呢。所以CAPTCHA的意思呢就是说，它是一种自动化的区别人和计算机的图灵测试。</p> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;CAPTCHA出现的意义是划时代的，它是目前防范各种机器人最有效的解决方案。但是就像人工智能界总是在不断发展，挑战图灵测试一样，验证码也受到一些模式识别技术的挑战。2008年的时候，yahoo发明的EZ-Gimpy宣布被破解，达到92%的破解率。同期的微软、google等公司的验证码破解率也达到20%~40%不等。那么不同的验证码为什么安全程度会有差异呢？差异到底在哪里？先从验证码识别的技术说起。</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062101_CcHp.jpeg\" width=\"290\" height=\"80\" /></span>图1：EZ-Gimpy</p> \n  <h2>验证码识别</h2> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;目前大部分验证码都是文字的序列，因此现有的识别方法，大都来自OCR(光学字符识别)的技术。 OCR用于印刷体扫描后文字的识别，一般分为三个步骤：</p> \n  <p>1、预处理</p> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;因为有些印刷文字会存在字迹不清、污点、颜色不统一等问题，所以在最开始都要对图像进行预处理。这些处理包括边缘检测、二值化等操作。边缘检测就是根据颜色和图形的特征，检测出一个文字的边缘，这样就可以得到文字的轮廓。而二值化就是将图片变成黑白的，有些验证码将背景和文字变为不同颜色，实际上在这一步会被识别出来。如果验证码的设计要增加预处理的难度，就需要增加更大的噪点、使用色彩渐变等方式使文字更加难以分辨，但是这样做也同时增加了人识别的难度。而这部分来说，计算机和人的识别能力差不多，甚至要优于人的识别力。所以在这方面做的工作效果并不好。</p> \n  <p>2、字符分割</p> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;我们人类阅读经常说“一目十行”，但是计算机识别大段的文字，却只能按照一个一个文字进行识别。字符分割就是将文字拆分成一个个的字符，以便于单独进行识别的过程。为什么要这么做呢？这要从OCR的核心：图像识别技术说起。</p> \n  <p><strong>&nbsp;&nbsp;&nbsp;&nbsp;图像识别</strong>&nbsp;的基本原理都是一样的：给计算机一个图像集合A，告诉计算机这些图像分别对应的含义，等它“学懂”后，然后再让它去判断新的图像b，跟集合A中的哪个图像(或者哪类图像)更相似，再借此判断它的含义。这个过程又有个很形象的名字叫“机器学习”。在机器学习的术语里，集合A称为“训练集(training set)”，A的含义叫做“标记(label)”，学习的过程叫做“训练(training)”，推断A的含义的过程叫做“分类(classify)”或者“标注(labeling)”，而把图像转化成计算机能理解的过程叫做“特征提取(feature extract)”。</p> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;这个过程有个很大的问题，在于训练集的规模。 计算机的存储能力是很强的，推理能力却是很弱的，给它一个&quot;abcd&quot;组合的图片，告诉它&quot;这是abcd&quot;，如果算法足够强大，它以后能够识别出所有&quot;abcd&quot;组合的图片，但是它绝无可能识别出一个&quot;acbd&quot;组合的图片。这种情况下，如果要识别“acbd”，那么必须再设计一套&quot;acbd&quot;组合的图片。如果是6位的验证码，每位由大小写和数字组成，那么一共有(26*2+10)^62=56,800,235,584种可能，就需要设计这么多种图片让计算机去学习。这显然是难以实现的。还有一种做法是将图片拆开，拆成一个个小区域，一次只识别一个字母，这样每个区域需要识别的类型就大大减少。仍以验证码为例，此时仅需要52张图片作为训练即可。</p> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;所以，字符分割可以大大降低验证码识别的难度。字符分割方面用到的技术更多，不过在这方面，人却比计算机有较大的优势。目前一种较安全的验证码设计方式就是直接在所有字母中加一条横线，对人类阅读几乎无影响，对计算机切分就比较困难了。还有一种做法是将所有字母变化并重合在一起，这样也能起到难以分割的效果。</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062102_TdOt.jpeg\" width=\"290\" height=\"55\" /></span>横线分割的验证码</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062102_vrLf.gif\" width=\"290\" height=\"60\" /></span>扭曲的验证码</p> \n  <p>3、字符识别</p> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;字符识别使用的就是上面说到的图像识别方法。只要切分成功，那么图像识别的任务就是识别一个区域的图像对应的字母。很多验证码技术都对字母进行了变形，最常见的就是扭曲。但是破解者同样可以将扭曲后的文字作为训练集交给计算机。假设一种文字有100种扭曲方法，那么实际上也只有6200种情况需要计算机来判断，这实在是小菜一碟。</p> \n  <h2>怎样设计一个安全的验证码</h2> \n  <p>&nbsp;&nbsp;&nbsp;&nbsp;这里有一个项目PWNtcha对目前的一些验证码实现进行了分析和破解<a href=\"http://caca.zoy.org/wiki/PWNtcha\" rel=\"nofollow\">http://caca.zoy.org/wiki/PWNtcha</a>&nbsp;。目前主流的验证码，都是基于字符重合和扭曲来实现的。同时，好的验证码必须保证输出的多样性，输出的变化越多越好。</p> \n  <p><strong>国内各大网站的验证码</strong></p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062102_Zaox.png\" width=\"100\" height=\"40\" /></span>新浪</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062102_VtnB.jpeg\" width=\"130\" height=\"53\" /></span>QQ空间</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062102_ibhj.jpeg\" width=\"250\" height=\"40\" /></span>豆瓣</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062103_3xoh.jpeg\" width=\"120\" height=\"45\" /></span>人人网</p> \n  <p><strong>一些新的思路</strong></p> \n  <p><strong>&nbsp;&nbsp;&nbsp;&nbsp;使用单词</strong>&nbsp;目前有一些网站使用词语来作为验证码，这样对于用户来说，即使某个字母不认识也可以根据已有语言知识拼写出来，对于用户体验来说是很有帮助的。初到大众点评时，看到这个词组的验证码，不免有点眼前一亮的感觉。但是这种方式，必须有一个足够大的词库，否则，即使不采用图像识别，仅仅使用暴力破解的方法，仍然能达到一定成功率(理论上成功率达到1%的验证码就不能使用了)。其次，可以使用隐式马尔科夫模型等利用前后字母的信息，增加识别成功率。(隐式马尔科夫模型也是一种模式识别的工具，它根据前面某几个词语来预测后面的内容，在语音识别领域有广泛应用。这个不属于本文内容，就不细说了)</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062102_ibhj.jpeg\" width=\"250\" height=\"40\" /></span>豆瓣</p> \n  <p><strong>&nbsp;&nbsp;&nbsp;&nbsp;使用汉字</strong>&nbsp;汉字验证码是个很有趣的尝试，因为汉字数量众多，以GB2312为例，一共有3755个常用汉字，加上变换的情况，基本上是一个很庞大的数字。同时国内破解验证码的研究基本停留在照抄国外技术的阶段，国外没有汉字验证码的研究啊，所以使用汉字还是比较让人放心的。目前点评使用的汉字验证码，但是词库比较小，还是有一点风险的。使用汉字验证码可能有个缺点就是：汉字本身的多样性可能给用户识别带来的困难，需要细心挑选汉字字库。不过目前没有发现这方面更多的使用，也难以评价。</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062103_PYyO.png\" width=\"200\" height=\"70\" /></span>点评团购</p> \n  <p><strong>&nbsp;&nbsp;&nbsp;&nbsp;使用问答</strong>&nbsp;有些网站的验证码是出一道题目让人填答案什么的，乍一看，计算机必定不具备思考能力，肯定识别不出来。但是别忘了，计算机没有思考能力，必然也不会有出题能力，就那么几道题目，只能人工制定，反而给破解者带来便利。所以这种技术非常难以使用，必须制定大量题库并且随时更新。有些网站注册设置了这种验证码，但是就博主看来其实只是为了考验人类的智商而已，计算机可是会“背答案”的！</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062103_KzL4.jpg\" width=\"800\" height=\"184\" /></span>小木虫</p> \n  <p><strong>&nbsp;&nbsp;&nbsp;&nbsp;使用图片交互</strong>&nbsp;下图是个很有趣的尝试，要求读图片之后回答问题，这么做很多图片识别技术就无能为力了。不过还是那句话，题库需要足够大，题目足够随机，防止计算机“背答案”。国内某些“验证码广告”，其实题库就那么几个，完全只是广告而已。<span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062103_MtIc.png\" width=\"220\" height=\"183\" /></span><a href=\"http://www.picatcha.com/\" rel=\"nofollow\">http://www.picatcha.com/</a><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062103_y5k3.png\" width=\"505\" height=\"316\" /></span></p> \n  <p><strong>&nbsp;&nbsp;&nbsp;&nbsp;reCaptcha</strong>&nbsp;最后提到一个有趣的项目，google的reCAPTCHA。这个验证码的特点是：它由两个单词组成，一个单词A是计算机知道答案的，而另外一个B是从古籍里面扫描出来，机器难以识别的。它通过A是否验证正确，来判断B的结果的有效性，并将多个有效结果结合起来，组成一个正确结果。基本上这系列的验证码以“难以识别”著称。当然这是指计算机难以识别，但是就我目前测试来看，人类识别也好不到哪去...</p> \n  <p><span style=\"margin:0px;padding:0px;display:block;\"><img src=\"http://static.oschina.net/uploads/img/201307/21062103_81qp.png\" width=\"336\" height=\"173\" /></span></p> \n </div>\n</div>","description":"2012-09-10 13:28","name":"怎样设计一个安全的验证码--从验证码识别技术原理说起","type":"text"},{"contents":"<h2>《推荐系统实践》读书笔记</h2><div class=\"BlogContent\">\n <p>《推荐系统实践》是一本讲推荐系统的入门书籍，可贵的是它做到了理论和实践相结合，理论也不是很复杂，非常适合工业界想要使用推荐算法的人学习。这里把读书过程的笔记摘录下来，给自己留个备忘。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>1.好的推荐系统</h2> \n <p>推荐系统是为了解决信息过载问题。</p> \n <span id=\"OSC_h3_2\"></span> \n <h3>应用领域：</h3> \n <ul> \n  <li><p>电子商务</p> <p>相关商品(item-based)。</p> </li> \n  <li><p>电影和视频</p> <p>样本少，早期依靠人工编辑效果也不错。</p> </li> \n  <li><p>音乐</p> <p>物品空间大，消费时间短。</p> </li> \n  <li><p>社交网络</p> <p>推荐内容广泛(人、事情、物品)。</p> </li> \n  <li><p>个性化阅读</p> </li> \n  <li><p>LBS</p> </li> \n  <li><p>个性化广告</p> </li> \n </ul> \n <span id=\"OSC_h3_3\"></span> \n <h3>评测标准</h3> \n <ul> \n  <li><p>满意度</p> </li> \n  <li><p>准确率</p> </li> \n  <li><p>覆盖率</p> </li> \n  <li><p>多样性</p> </li> \n  <li><p>新颖性</p> <p>不要都是热门资源</p> </li> \n  <li><p>惊喜度</p> </li> \n  <li><p>信任度</p> <p>增加系统的透明度，提供推荐解释。社交网络信息。</p> </li> \n  <li><p>实时性</p> </li> \n  <li><p>健壮性</p> </li> \n  <li><p>商业目标</p> </li> \n </ul> \n <span id=\"OSC_h2_4\"></span> \n <h2>2.用户行为数据</h2> \n <span id=\"OSC_h3_5\"></span> \n <h3>数据来源</h3> \n <p>raw log =&gt; session log =&gt; impression log</p> \n <p>显示数据：喜欢 <br />隐式数据：浏览</p> \n <p>无上下文信息的隐性反馈数据集：用户ID+物品ID作为一条记录，如浏览数据。</p> \n <span id=\"OSC_h3_6\"></span> \n <h3>PowerLow–长尾效应–Zipf定律</h3> \n <span id=\"OSC_h3_7\"></span> \n <h3>协同过滤的算法：</h3> \n <ul> \n  <li><p>基于邻域的算法(neighborhood-based)</p> \n   <ul> \n    <li><span id=\"OSC_h4_8\"></span><h4>UserBased</h4> <p>1.<strong>User相似度计算</strong>：</p> <p><img src=\"http://static.oschina.net/uploads/space/2013/0910/140616_IEKB_190591.gif\" alt=\"Latex:{w}_{uv}=\\frac{\\sum_{i\\epsilon N(u)\\bigcap N(v)} \\frac{1}_{log1+|N(i)|}}{\\sqrt{|N(u)||N(v)|}}\" /></p> <p>其中N(i)表示用户i有正反馈的物品集合，<img src=\"http://static.oschina.net/uploads/space/2013/0910/134319_dS09_190591.gif\" alt=\"Latex:\\frac{1}_{log1+|N(i)|}}\" />是惩罚因子，避免热门物品的影响。</p> <p>2.<strong>Item感兴趣程度计算</strong>：</p> <p><img src=\"http://static.oschina.net/uploads/space/2013/0910/131833_upck_190591.gif\" alt=\"Latex:p(u,i)=\\sum_{v\\epsilon S(u,k)\\bigcap N(i)} {w}_{uv} {r}_{vi}\" /></p> <p>k是输入参数，S(u,k)是与u有关的k个人。</p> <p>使用UserBased的公司：Digg，文章推荐网站，类似无觅</p> </li> \n    <li><span id=\"OSC_h4_9\"></span><h4>ItemBased</h4> <p>1.<strong>Item相似度计算</strong>：</p> <p><img src=\"http://static.oschina.net/uploads/space/2013/0910/140058_QTuY_190591.gif\" alt=\"Latex:{w}_{ij}=\\frac{|N(i)\\bigcap N(j)|}{{|N(i)|}^{1-\\alpha }{|N(j)|}^{\\alpha }}, \\alpha\\in [0.5,1]\" /></p> <p>其中alpha是对热门物品j的惩罚因子。实验证明alpha为0.5时结果最佳，但是仍然可以使用其他值来保证新颖性。</p> <p>IUF(Inverse User Frequence):活跃用户的贡献度应小于不活跃的用户。ItemCF-IUF效果略好于ItemCF。</p> <p><img src=\"http://static.oschina.net/uploads/space/2013/0910/140923_2z5n_190591.gif\" alt=\"Latex:{w}_{ij}=\\frac{\\sum_{u\\epsilon N(i)\\bigcap N(j)} \\frac{1}_{log1+|N(u)|}}{\\sqrt{|N(i)||N(j)|}}\" /></p> <p>2.<strong>Item感兴趣程度计算</strong>：</p> <p><img src=\"http://static.oschina.net/uploads/space/2013/0910/141404_QT5p_190591.gif\" alt=\"Latex:{p}_{uj}=\\sum_{i\\epsilon N(u)\\bigcap S(j,K)} {w}_{ji} {r}_{ui}\" /></p> <p>K同样是输入参数。</p> <p>ItemCF更让人信服，因为提供推荐解释<em>“喜欢A的人还喜欢B”</em>。</p> </li> \n   </ul> </li> \n  <li><p>隐语义模型(latent factor model)</p> <p>todo</p> </li> \n  <li><p>基于图的随机游走(random walk on graph)</p> <p>todo</p> </li> \n </ul>\n</div>","description":"2013-09-10 14:15","name":"《推荐系统实践》读书笔记","type":"text"}],"name":"机器学习","type":"dir"},{"contents":[{"contents":"<h2>Linux内核学习之一-Take It Easy！</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>起-做个了解底层的码农</h2> \n <p>节前上班的日子总是那么悠闲，这么集中的时间，正好集中学习一下。一直以来都做的是Java开发，对不了解底层，总觉得心有不安。听到别人说起“进程切换”、“内存管理”、“内核态和用户态”，也总是觉得似懂非懂。所以就干脆把目标定大一点，学学Linux内核吧！</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>承-下载Linux内核及编译</h2> \n <span id=\"OSC_h3_3\"></span> \n <h3>下载</h3> \n <p>其实如果你使用Linux系统，那么内核的源码就直接在/usr/src目录下了。不过还是建议去下载一份最新的源码！哪里下载呢？Linux的作者-大名鼎鼎的Linus Torvalds也是Git的作者，所以你知道最新的源码去哪里下载了吧！赶紧去<a href=\"https://github.com/torvalds/linux\" rel=\"nofollow\">https://github.com/torvalds/linux</a>拉一份最新代码吧！</p> \n <pre class=\"brush: java; auto-links: false;\">git clone https://github.com/torvalds/linux</pre> \n <p>代码一共有1.4G，所以耐心等待一会吧…</p> \n <span id=\"OSC_h3_4\"></span> \n <h3>编译内核</h3> \n <p>编译内核是个苦力活。首先，你必须得在Linux系统下，因为编译Linux是依赖gcc的。然后，你编译的版本得跟当前版本一致（博主不完全肯定，但是实践下来是这样）。</p> \n <p>然后就是编译了！Linux内核编译反而会简单，因为它没有太多的依赖要编译。所以可以用常用的三段式（需要root权限）：</p> \n <pre class=\"brush: java; auto-links: false;\">make config\nmake\nmake install #install就替换当前内核了，三思而后行！</pre> \n <ol> \n  <li><code>make config</code>是交互式的，会需要指定使用什么不使用什么。不过这选项实在太多了点，第一次大概选了几百个选项吧…后面才知道，可以图个方便，用<code>make allyesconfig</code>来替代了。反正我们只是看看能不能编译嘛，嗯。</li> \n  <li><code>make</code>是个很漫长的过程。</li> \n  <li><code>make install</code>会替换当前内核了，我们这边就不替换了。</li> \n </ol> \n <p>总之到了这里，已经有一些成就感了！</p> \n <span id=\"OSC_h3_5\"></span> \n <h3>开始读代码？</h3> \n <p>关于Linux的代码结构有很多文章，例如这篇：<a href=\"http://blog.csdn.net/liaoshengjiong/article/details/3957654\" rel=\"nofollow\">http://blog.csdn.net/liaoshengjiong/article/details/3957654</a>，就不赘述了。查看一下代码，乖乖，一共500多万行，估计一两年也读不完吧！我的目的只是了解底层的基本原理，没有必要深入到各种细节。更何况，好多驱动、文件、内存的概念也不熟悉，怎么办呢？还是先看书吧！</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>转-还是读书吧</h2> \n <p>我之前的观点是读源码前至少了解项目的领域知识。对于Java码农来说，操作系统毕竟不是熟悉的领域，一开始就看源码不太现实。一两本参考书是必不可少的。这里我也浏览过几本书，最后觉得比较好的是《Linux内核设计与实现》，这本书大部分是理论为主，但是最后总会介绍到大致对应的代码在哪里，就起到非常好的提纲挈领的效果。对于有过一些代码经验的人来说，会觉得异常亲切。关键是，<strong>它只有200页！</strong></p> \n <p>浏览的另外几本书，包括大名鼎鼎的《深入理解计算机系统》，这本书全面详尽，但是更适合做教材，实践性弱了点（虽然它也有很多例子）。还有一本《深入理解LINUX内核》，内容对于入门又深了一点。一句话，讲了“深入”的都不太适合入门！还有本《30天自制操作系统》，不是说书不好，而是太基础了点，看到“用二进制编辑器写代码”就看不下去了。</p> \n <span id=\"OSC_h2_7\"></span> \n <h2>合-Take It Easy!</h2> \n <p>好了，下面开始学习了。其实弄了那么多，我想说一件事就是，内核虽然很难，很多人只靠研究它就已经成了大牛。但是它难在于，越是底层的东西，对质量、稳定性、性能要求越高，同时需要考虑的情况越多，但是其实其理论和思想，可能大家都是耳熟能详的。</p> \n <p>例如，在“进程管理”部分，我们常见的“进程描述符”对应的是<code>sched.h</code>中的一个结构：<code>task_struct</code>:</p> \n <pre class=\"brush: c; auto-links: false;\">struct task_struct {\n    volatile long state;    /* -1 unrunnable, 0 runnable, &gt;0 stopped */\n    struct thread_info *thread_info;\n    atomic_t usage;\n    unsigned long flags;    /* per process flags, defined below */\n    unsigned long ptrace;\n    …\n}</pre> \n <p>而进程是保存在一个带优先级的双向链表里的，这跟Java里的PriorityQueue原理相似。怎么样，是不是觉得“进程调度”也没有那么神秘了呢？</p> \n <p>同理，我们经常说“内核态”和“用户态”，实际上两者的代码都是c实现，搞出一个“内核态”是为了安全和某些性能的考虑，但是区别也没有想象中的那么大！其实这跟我们熟悉的“平台”和“业务逻辑”是不是有那么点相似呢？</p> \n <p>总之，掌握基本的内核知识，应该还是不难的！好处就是，以后对程序设计的理解会更进一步了！</p> \n <p>关于内核实现的一些原理的具体内容，《Linux内核设计与实现》（Linux Kernel Development，简称LKD）已经比较全面了，网络上的资料也非常多。这系列博文主要想站在初学者的角度，在了解How之前，先了解What跟Why，从而对内核有个稳固的大局观。同时会寻根究底的方式，找到对应的内核代码，满足一下考究的爱好。 <br />PS:博主对c和Linux的理解都是入门水平都算不上，如果有问题欢迎指正，我会很开心接受的！</p>\n</div>","description":"2014-01-26 23:07","name":"Linux内核学习之一-Take It Easy！","type":"text"},{"contents":"<h2>Linux内核学习之二-进程与线程</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>一、操作系统的功能</h2> \n <p>根据维基百科的解释，一个操作系统大概包括以下几个功能：</p> \n <ol> \n  <li>进程管理（Processing management）</li> \n  <li>安全机制（Security）</li> \n  <li>内存管理（Memory management）</li> \n  <li>用户界面（User interface）</li> \n  <li>文件系统（File system）</li> \n  <li>驱动程序（Device drivers）</li> \n  <li>网络通信（Networking）</li> \n </ol> \n <p>可以看到，这些功能彼此之间关系并不大，所以操作系统其实是这么些功能的低内聚复合体。所以学习的时候，采用逐个击破的方式，要比囫囵吞枣，一下全看来的好。进程管理是操作系统最最核心的功能，我们就从这里开始。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二、什么是进程</h2> \n <p>什么是进程？这个问题不太好回答，我们不妨从另一个角度来看看这个问题。</p> \n <p>最早的操作系统是没有“进程“这个概念的，比如<a href=\"http://zh.wikipedia.org/wiki/DOS\" rel=\"nofollow\">DOS</a>。正如其名“Disk Operating System”，DOS主要的任务就是管理一下磁盘，并把BIOS和硬件做一点抽象。在上面开发的程序，其实是直接跟CPU打交道的，程序最终会编译或者解释成CPU指令并被执行。</p> \n <p>这个系统有个最大的问题，就是同时只能执行一个程序。这样对于用户使用无疑太不友好了，我想一边听音乐一边写代码都做不到！怎么办呢？CPU就像一个无脑的工人，在它那里根本没有“程序”的概念，只负责处理“指令”，所以如果我们程序不做点事情，那么好像无论如何都无法实现“多个程序同时执行”吧？</p> \n <p>于是，就有了“分时多进程”的操作系统。操作系统把想要执行的程序管理起来，并且按照一定的规则，让它们都得到执行。因为CPU执行很快，所以对用户看起来它们就像同时在执行一样，这就是所谓的“进程“。</p> \n <p>在这里我想强调一个观点：<strong>操作系统也是一种程序</strong>，这样子会对于码农距离感更小一点。作为码农，我们不妨想想如何实现分时间片调度？我写了一段最简单的调度算法，大概是这样子（wait这里其实依赖时钟周期相关的东东，但不妨先假设一下）：</p> \n <pre class=\"brush: java; auto-links: false;\">while (true){\n     processing = nextProcessing();\n     processing.run();\n     wait(100); //每100毫秒分片\n     processing.interrupt();\n }</pre> \n <p>而<code>nextProcessing()</code>则可以使用一个FIFO的循环队列来保存，这样子是不是有点意思了？（实际上Linux的调度算法要比这个复杂很多，但是也没有到无法理解的程度，这个我们下篇文章再说。）</p> \n <p>总结一下这部分：进程就是程序执行的一个实例。它是操作系统为了管理多个程序的执行而产生的机制。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>三、Linux中的进程</h2> \n <p>废话很多了，来点干货吧！Linux内核中进程相关的代码在<code>include/linux/sched.h</code>和<code>kernel/sched.c</code>里。（本文针对2.6.39版本的内核）</p> \n <p><em>插一句，Linux的项目结构大概包括三部分：</em></p> \n <p><em>1. <code>include</code>是对外发布的部分，看到代码中有<code>#include &lt;linux/config.h&gt;</code>这样的，就是在&quot;include&quot;目录中。</em></p> \n <p><em>2. <code>kernel</code>则是内核部分的实现，<code>arch</code>是对不同平台的适配。</em></p> \n <p><em>3. 其他目录多是功能模块，例如初始化<code>init</code>，文件系统<code>fs</code>，内存管理<code>mm</code>等。</em></p> \n <p>记得有句名言叫做“程序=算法+数据结构”。我在写一般业务逻辑的时候，总觉得不完全符合，但是看Linux代码的时候，确确实实感觉到了这句话的道理。</p> \n <p>进程相关的最重要的数据结构，我觉得有两个。一个是<code>task_struct</code>（在<code>sched.h</code>中），就是我们常说的“进程描述符”，用于标识一个进程，以及保存上下文信息。弄懂这个可以算是成功了一半了！</p> \n <p>task_struct是个巨大的结构体，光定义就有好几百行，有很多<code>#ifdef</code>括起来的可选功能。有些功能需要到后面才能看懂，这里主要说几个部分：</p> \n <pre class=\"brush: c; auto-links: false;\">struct task_struct {\n\n    /* 执行状态，具体的状态见TASK_RUNNING等一系列常量定义 */\n    volatile long state;\n\n    /* 执行中的标志位，具体内容见PF_* 系列常量定义 */\n    unsigned int flags;\n\n    /* 优先级，用于调度 */\n    int prio, static_prio, normal_prio;\n\n    /* 进程使用的内存 */\n    struct mm_struct *mm, *active_mm;\n}</pre> \n <p>感觉细节仍然不明白？其实我也不明白，不过好歹算是懂了个大概！</p> \n <span id=\"OSC_h2_4\"></span> \n <h2>四、进程与线程</h2> \n <p>说完了进程，我们来理一理线程的概念。其实线程可以理解为特殊的进程，它没有独立的资源（对，就是上面的*mm），它依赖于进程，某个进程的子线程之间可以共享资源，除此之外没有什么区别。</p> \n <p>在c程序里，我们使用fork来创建进程。例如：</p> \n <pre class=\"brush: c; auto-links: false;\">#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\nint main(int argc, const char* argv[]) {\n  pid_t pid;\n  printf(&quot;Hello, World!%d\\n&quot;,pid);\n  for (int i=0;i&lt;2;i++){\n      pid = fork();\n      if (pid == 0){\n        printf(&quot;I am child&quot;);\n      } else {\n        printf(&quot;I am parent, my child is %d&quot;,pid);\n      }\n  }\n  return 0;\n}</pre> \n <p>这里fork会创建一份新的进程。这个进程会复制当前进程的所有上下文，包括寄存器内容、堆栈和内存（现在内存一般使用Copy-On-Write机制，不过我觉得对于用户来说觉得它是复制了一份也没什么问题）。因为程序计数器也一起复制了，所以执行到哪一步也会被复制下来。</p> \n <p>fork的实现在<code>kernal/fork.c</code>里。</p> \n <pre class=\"brush: c; auto-links: false;\">long do_fork(unsigned long clone_flags,\n          unsigned long stack_start,\n          struct pt_regs *regs,\n          unsigned long stack_size,\n          int __user *parent_tidptr,\n          int __user *child_tidptr)</pre> \n <p>到底是创建线程还是进程，取决于<code>clone_flags</code>传入的参数。</p> \n <p>下篇文章分析一下进程的生命周期及调度。</p> \n <p>参考资料：</p> \n <ul> \n  <li><a href=\"http://blog.csdn.net/hongchangfirst/article/details/7075026\" rel=\"nofollow\">http://blog.csdn.net/hongchangfirst/article/details/7075026</a></li> \n  <li><a href=\"http://zh.wikipedia.org/wiki/DOS\" rel=\"nofollow\">http://zh.wikipedia.org/wiki/DOS</a></li> \n  <li>《Linux内核设计与实现》</li> \n  <li>《深入理解Linux内核》</li> \n </ul>\n</div>","description":"2014-01-27 14:52","name":"Linux内核学习之二-进程与线程","type":"text"},{"contents":"<h2>Linux内核学习之三-进程的调度</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>一、调度的总体流程</h2> \n <p>进程的调度是进程部分的核心-很显然，如果没有调度，我们也不需要进程了！我们在上一篇文章的第二部分实现了一个最简单的按照时间片的调度算法，每个进程都平均执行100毫秒。</p> \n <pre class=\"brush: java; auto-links: false;\">while (true){\n     processing = nextProcessing();\n     processing.run();\n     wait(100); //每100毫秒分片\n     processing.interrupt();\n }</pre> \n <p>那么Linux中如何实现的呢？我们先来看流程。调度相关的代码都在<code>sched.c</code>中。这个就是Linux代码核心中的核心，它被运行在亿万台机器上，每台机器每个时钟周期就要执行一次，看到它是不是有点激动？终于知道“高性能的底层代码”长什么样了！</p> \n <p>这个文件的核心函数是<code>asmlinkage void __sched schedule(void)</code>，这就是调度部分的具体代码。当我读完并注释之后才发现已经有很多注释版本了，比如这篇文章：<a href=\"http://blog.csdn.net/zhoudaxia/article/details/7375836\" rel=\"nofollow\">http://blog.csdn.net/zhoudaxia/article/details/7375836</a>，所以就不贴代码了。我注释后的代码在<a href=\"https://github.com/code4craft/os-learning/blob/master/linux/kernel/sched.c\" rel=\"nofollow\">sched.c</a>(4079行开始)里。不过不读源码，不用那些关键词去搜索，估计也找不到一些好文章，这也是一个学习的过程吧。</p> \n <p>这个方法有两个重要的点，一个是<code>pick_next_task(rq);</code>，获取下一个可执行进程，它涉及到调度算法；一个是<code>context_switch(rq, prev, next);</code>，这就是所谓的“上下文切换”了。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二、调度算法</h2> \n <p>我们前面的“100毫秒算法”算法当然是非常粗糙的。在了解货真价实的Linux调度算法时，不妨看看，调度系统需要考虑什么问题（非官方不权威总结）：</p> \n <ol> \n  <li>最大限度利用CPU，只要有进程能执行，就不让要CPU空等。尽量最大化CPU利用率。</li> \n  <li>保证进程（特别是交互式进程）的响应时间尽可能短。</li> \n  <li>能由系统管理员指定优先级，让重要的任务先执行。</li> \n  <li>因为调度执行非常频繁，所以必须考虑它的性能。</li> \n  <li>支持多核平均调度，也就是所谓的对称多处理器（Symmetric Multi-Processor，SMP）。</li> \n </ol> \n <p>我们的“100毫秒算法”不满足1和3，对于2来说其实也不太好（可能有些进程都不会执行那么久）。如果我们把时间缩短，换成1毫秒怎么样呢？我们知道，“进程切换”本身也有开销，这样子频繁切换，岂不是得不偿失了？</p> \n <p>实际上，因为其核心地位，Linux的调度算法一旦提升一点点性能，对整个工业界的提升也是巨大的。对于算法高手来说，这里成了大显身手的好地方。所以Linux调度算法的变化那是相当的快，从<a href=\"http://en.wikipedia.org/wiki/O(n)_scheduler\" rel=\"nofollow\">O(n)调度器</a>到<a href=\"http://en.wikipedia.org/wiki/O(1)_scheduler\" rel=\"nofollow\">O(1)调度器</a>，再到2.6.23中的”<a href=\"http://zh.wikipedia.org/wiki/%E5%AE%8C%E5%85%A8%E5%85%AC%E5%B9%B3%E6%8E%92%E7%A8%8B%E5%99%A8\" rel=\"nofollow\">CFS（completely fair schedule）</a>“，让人看得都晕了！</p> \n <p>了解了要解决的问题，或许会更容易理解一点。O(n)和O(1)算法都是基于时间片的，基本思路就是：给进程指定优先级，IO高、交互强的进程给予更高的优先级，CPU占用高的则降低优先级，每次选优先级最高的执行；同时为每个进程分配时间片（每个进程的时间片都是动态调整的），每个进程每次执行的时间就是这个时间片的时间。O(n)和O(1)的区别在于从优先级队列里取进程的时候的时间复杂度而已。具体细节就不多说了。</p> \n <p>而&quot;CFS&quot;则是使用了一个&quot;vruntime&quot;的概念来保存执行时间。同时它用一颗红黑树来对进程做排序，vruntime越小的进程会被越先执行，所以它的时间复杂度是O(logn)。它的代码在<code>kernel/sched_fair.c</code>中。</p> \n <p>另外还有个“实时调度算法”的概念。这些就是“加塞的”的进程，它们优先于CFS的所有进程。对应的类型是<code>SCHED_FIFO</code>和<code>SCHED_RR</code>，在<code>sched.h</code>中可以看到。</p> \n <p>调度部分就这么多，还有些细节，例如CFG具体实现，书里已经很详细了，就不重复记录，免得写晕了！</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>参考资料：</h2> \n <ul> \n  <li>《Linux内核设计与实现》 LKD</li> \n  <li>Linux 2.6内核中新的锁机制–RCU <a href=\"http://www.ibm.com/developerworks/cn/linux/l-rcu/\" rel=\"nofollow\">http://www.ibm.com/developerworks/cn/linux/l-rcu/</a></li> \n  <li>Linux进程调度(3)：进程切换分析 <a href=\"http://blog.csdn.net/zhoudaxia/article/details/7375836\" rel=\"nofollow\">http://blog.csdn.net/zhoudaxia/article/details/7375836</a></li> \n  <li><a href=\"http://blog.csdn.net/yunsongice/article/details/8547107\" rel=\"nofollow\">http://blog.csdn.net/yunsongice/article/details/8547107</a></li> \n </ul>\n</div>","description":"2014-01-27 22:09","name":"Linux内核学习之三-进程的调度","type":"text"},{"contents":"<h2>Linux内核学习之四-内存管理</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>一、虚拟存储器</h2> \n <p>内存管理最基础的概念，恐怕是虚拟存储器（Virtual Memory，简称VM）了，它是计算机系统（注意我没写操作系统，因为其中还有部分硬件功能）在物理存储之上的一套机制。它将物理地址（Physical Address，简称PA）转换为虚拟地址（Virtual Address，简称VA），来访问存储。正是因为有了虚拟存储器，才有了后面的内存转换、页表等机制。</p> \n <p>看到这里我就有疑问了，有了物理地址，程序已经能定位到内存块并且使用了，为什么需要有虚拟地址？</p> \n <p>实际上，如果只有一个程序在内存中运行，没有虚拟存储问题也不大，比如DOS（又提到它了！），而且据说DOS确实是没有虚拟存储机制的。但是当有了多进程之后，问题就出现了：多个进程共同使用一整个物理内存，既不安全也不方便，比如A用了<code>0xb7001008</code>，结果B没法知道，然后也用了它，岂不是乱套了？</p> \n <p>为了解决这个问题，就有了虚拟存储机制。对于每个进程来说，它的虚拟地址空间总是一样的，但是实际使用的物理内存是分开的，而且它也不知道到底是在使用虚拟地址，还是物理地址，反正用就对了！这样子既简化了程序开发，又增加了安全性，真是非常巧妙的设计！</p> \n <p>总结一下，虚拟存储的最大作用就是<strong>隔离与抽象</strong>。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二、地址转换的实现</h2> \n <p>为了了解地址的转换，我们必须引入“页”（page）的概念。其实页就是一块连续的内存，这也是操作系统利用内存的最小单位。更直观一点的说，在Linux里，它是这么实现的：</p> \n <pre class=\"brush: c; auto-links: false;\">struct page{\n    //保存状态\n    unsigned long flags;\n    //引用计数\n    atomic_t _count;\n    atomic_t _mapcount;\n    unsigned long private;\n    struct address_space *mapping;\n    pgoff_t index;\n    struct list_head lru;\n    //指向虚拟地址\n    void *virtual;\n}</pre> \n <p><code>page</code>结构体保存对应页的引用数、虚拟地址等信息。因为这个结构本身也是消耗内存的，所以一页的大小太小，那么还要存<code>page</code>结构，就有很多内存浪费了，很不划算。如果页大小太大，经常会出现一个页装不满的情况，也是我们不愿看到的。在32位CPU里，一页是4KB。</p> \n <p>有了页的知识，地址转换就可以进行了。在看这部分之前，不妨先想想，如果让我们实现一套地址转换，会怎么做？</p> \n <p>似乎这没有什么难度啊？可以分两部分，你看我伪代码都写好了：</p> \n <ol> \n  <li><p>保存虚拟地址到物理地址的映射关系</p> <pre class=\"brush: java; auto-links: false;\">page_table={virtual_address:physical_address}</pre> </li> \n  <li><p>在程序中使用指针访问物理地址的时候，对其进行转换</p> <pre class=\"brush: java; auto-links: false;\">physical_address=page_table[virtual_address]</pre> <p>是不是非常简单？</p> </li> \n </ol> \n <p>实际上目前的计算机系统做的方式也差不多。但是区别是，因为这两个操作非常频繁，光靠软件实现性能未必有那么好，所以这两部分有了一些硬件上的优化。</p> \n <p>把VA转换为PA的事情，由CPU里一个专门的部件来完成，它叫做“内存管理单元”（Memory Management Unit，简称MMU）。</p> \n <p>保存地址映射关系的部件，叫做页表（Page Table），它是保存在内存中的，由操作系统维护。但是访问一次内存还要查一次内存，这事感觉不太科学，所以MMU还会维护一份用过的页表索引，这就是传说中的TLB（Translation Lookaside Buffer，也叫转换备用缓冲区，我们学校的孙钟秀院士在他的教材中将其翻译为“快表”）。</p> \n <p>所以最后的流程是：</p> \n <ol> \n  <li>操作系统新建进程时，为进程分配内存空间，并更新页表；</li> \n  <li>该进程的指令到CPU之前，其中的虚拟地址，会触发MMU转换流程；</li> \n  <li>MMU先到TLB中找页表，找不到再去物理内存中找页表，最后转换为物理地址，递给CPU执行。</li> \n </ol> \n <p>这其实也是一个操作系统反过来影响CPU设计的案例，这也说明，其实硬件跟系统分界并不是死的，比如有些CPU的指令集也会包括一些高等的操作，理论上越底层越快，所以到底放在哪一层，主要取决于这个机制的价值和通用性。</p> \n <p>至此地址转换算是差不多了，操作系统和MMU握了个手，合作愉快！</p> \n <p>PS：在有些嵌入式CPU上没有MMU，就确实是软件来完成地址转换。不过现在带有MMU的CPU越来越多了！</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>三、Linux中的内存管理</h2> \n <p>Linux中内存分配相关的代码在<a href=\"https://github.com/code4craft/os-learning/blob/master/linux/mm/page_alloc.c\" rel=\"nofollow\"><code>kernal/page_alloc.c</code></a>中，其中核心的函数是<code>struct page * __alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, struct zonelist *zonelist, nodemask_t *nodemask)</code>。我对能看懂的代码做了注释，大部分都没看懂，等全部都研究一遍之后再来细细研究吧…</p> \n <p>Linux内存管理中还有很多细节，罗列几个，做个备忘。</p> \n <ol> \n  <li><p>分区（zone）</p> <p>Linux将内存分为几个区：ZONE_DMA、ZONE_NORMAL和ZONE_HIGHEN。DMA（Direct Memory Access）是一种IO直接操作内存的技术，有些硬件只能用特定地址的内存来进行DMA，对这种内存需要标记一下。</p> </li> \n  <li><p>NUMA</p> <p>NUMA（Non-Uniform Memory Access Architecture）是相对于UMA（Uniform Memory Access Architecture）来说的。UMA就是指多处理器共享一片内存，而NUMA则反其道行之，将CPU绑定到一些内存中，从而加快速度。据说在多于八核的处理器中效果明显。</p> </li> \n  <li><p>slab</p> <p>slab这部分LKD讲的并不好，有些绕弯（也可能是翻译不好吧），然后我搜到很多资料，大致连描述都照样复制，我也不知道是不是我智商太低，弄不懂，还是作者只是做了个摘抄，反正对于这些技术文章只能呵呵了。</p> <p>其实slab解决了什么问题呢？我们知道在内核里有些数据结构是很常用的，例如inode，这些数据结构会频繁初始化和销毁。但是初始化数据结构是有开销的啊，更好的办法是把它存下来，然后下次创建的时候，直接拿一个现成的，改改内容，就可以用了！slab又译作“板坯”，这样子是不是好理解一点呢？</p> <p>在实现上，slab会为一类对象开辟一段空间，存储多个这样的对象，然后创建和销毁，其实只是在这片空间里指针移动一下的事情了！我们其实可以叫它“对象池”或者“结构池”吧！slab的代码实现在LKD中有非常详细的描述，不再赘述了。</p> </li> \n </ol> \n <p>参考资料：</p> \n <ul> \n  <li>文中讲到的LKD指《Linux内核设计与实现》（Linux Kernel Development）</li> \n  <li>《深入理解计算机系统》</li> \n  <li><a href=\"http://learn.akae.cn/media/ch17s04.html\" rel=\"nofollow\">http://learn.akae.cn/media/ch17s04.html</a></li> \n  <li><a href=\"http://www.cnblogs.com/shanyou/archive/2009/12/26/1633052.html\" rel=\"nofollow\">http://www.cnblogs.com/shanyou/archive/2009/12/26/1633052.html</a></li> \n  <li>The Slab Allocator:An Object-Caching Kernel Memory Allocator <a href=\"http://www.usenix.org/publications/library/proceedings/bos94/full_papers/bonwick.ps\" rel=\"nofollow\">http://www.usenix.org/publications/library/proceedings/bos94/full_papers/bonwick.ps</a></li> \n </ul>\n</div>","description":"2014-01-28 17:05","name":"Linux内核学习之四-内存管理","type":"text"}],"name":"linux","type":"dir"},{"contents":[{"contents":"<h2>构建一个可靠的分布式计数器--memcached之incr/decr操作实战分析</h2><div class=\"BlogContent\">\n <p> &nbsp;最近的项目要依赖于一个分布式计数器的实现，因为公司使用memcached历史已久，所以就想到了使用memcached来作为计数器。之前也用过memcached的incr操作，但是有人封装好了，也没有深究，自己测试起来，越到了问题。经过大半天的调试、查阅文档、查看源码，解决了问题，现在将收集到的信息整理一下。 </p> \n <p> &nbsp;&nbsp;&nbsp;incr/decr是memcached 1.2.4加入的原子性整数操作(<a href=\"https://github.com/memcached/memcached/blob/master/ChangeLog\" target=\"_blank\" rel=\"nofollow\">changelog:2006-10-03</a>)。这个功能常用于分布式项目中的计数。 </p> \n <p> <strong>1.incr/decr在memcached中的保存方式是：字符串(十进制)表示的无符号64bit整数。 &nbsp;&nbsp;&nbsp;</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </p> \n <p> &nbsp;&nbsp;&nbsp;memcached的wiki中这样描述： </p> \n <p> &nbsp;&nbsp;&nbsp;<span style=\"text-decoration:underline !important;\">Increment and Decrement. If an item stored is the string representation of a 64bit integer, you may run incr or decr commands to modify that number. You may only incr by positive values, or decr by positive values. They does not accept negative values.</span> </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;为了验证，在memcached telnet终端中如下操作： </p> \n <div> \n  <div> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width:700px;margin:0px !important;padding:0px !important;font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;height:auto !important;text-align:left !important;\"> \n    <tbody> \n     <tr> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;color:#AFAFAF !important;\"> \n       <div>\n         1 \n       </div> \n       <div>\n         2 \n       </div> \n       <div>\n         3 \n       </div> \n       <div>\n         4 \n       </div> \n       <div>\n         5 \n       </div> \n       <div>\n         6 \n       </div> \n       <div>\n         7 \n       </div> \n       <div>\n         8 \n       </div> \n       <div>\n         9 \n       </div> \n       <div>\n         10 \n       </div> \n       <div>\n         11 \n       </div> \n       <div>\n         12 \n       </div> \n       <div>\n         13 \n       </div> \n       <div>\n         14 \n       </div> \n       <div>\n         15 \n       </div> \n       <div>\n         16 \n       </div> \n       <div>\n         17 \n       </div> \n       <div>\n         18 \n       </div> \n       <div>\n         19 \n       </div> </td> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;\"> \n       <div> \n        <div>\n          seta 0 0 2 \n        </div> \n        <div>\n          12 \n        </div> \n        <div>\n          STORED \n        </div> \n        <div>\n          &nbsp;&nbsp;#设置key=a的项为&quot;12&quot; \n        </div> \n        <div>\n          incr a 1&nbsp;&nbsp;&nbsp;&nbsp; \n        </div> \n        <div>\n          13 \n        </div> \n        <div>\n          &nbsp;&nbsp;#incr 1 返回13 \n        </div> \n        <div>\n          append a 0 0 1 \n        </div> \n        <div>\n          3 \n        </div> \n        <div>\n          STORED \n        </div> \n        <div>\n          &nbsp;&nbsp;#在a项后面增加一个字符'3' \n        </div> \n        <div>\n          get a \n        </div> \n        <div>\n          VALUE a 0 3 \n        </div> \n        <div>\n          133 \n        </div> \n        <div>\n          END \n        </div> \n        <div>\n          &nbsp;&nbsp;#a变为133 \n        </div> \n        <div>\n          incr a 1 \n        </div> \n        <div>\n          134 \n        </div> \n        <div>\n          &nbsp;&nbsp;#a incr 1后变为134 \n        </div> \n       </div> </td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </div> \n <p> &nbsp;&nbsp;&nbsp;可以看到，在把a当做字符串进行append操作后，得到字符串133，此时incr 1，变为134，证明memcached内部确实incr项将保存为字符串。 </p> \n <p> &nbsp;&nbsp;&nbsp;那么，如果我们使用二进制协议，将a写入数字后，再使用incr会产生什么结果呢？(使用Java语言，memcached客户端为：spymemcached-2.5)。 </p> \n <div> \n  <div> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width:700px;margin:0px !important;padding:0px !important;font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;height:auto !important;text-align:left !important;\"> \n    <tbody> \n     <tr> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;color:#AFAFAF !important;\"> \n       <div>\n         1 \n       </div> \n       <div>\n         2 \n       </div> \n       <div>\n         3 \n       </div> \n       <div>\n         4 \n       </div> \n       <div>\n         5 \n       </div> \n       <div>\n         6 \n       </div> </td> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;\"> \n       <div> \n        <div>\n          memcachedClient.set(key, exp,51); \n        </div> \n        <div>\n          Object object = memcachedClient.get(key); \n        </div> \n        <div>\n          System.out.println(&quot;init &quot;+ object); \n        </div> \n        <div>\n          longincr = memcachedClient.incr(key,1); \n        </div> \n        <div>\n          object = memcachedClient.get(key); \n        </div> \n        <div>\n          System.out.println(&quot;after incr &quot;+ incr +&quot; &quot;+ (object)); \n        </div> \n       </div> </td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </div> \n <p> &nbsp;&nbsp;&nbsp;输出为： </p> \n <div> \n  <div> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width:700px;margin:0px !important;padding:0px !important;font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;height:auto !important;text-align:left !important;\"> \n    <tbody> \n     <tr> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;color:#AFAFAF !important;\"> \n       <div>\n         1 \n       </div> \n       <div>\n         2 \n       </div> </td> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;\"> \n       <div> \n        <div>\n          init 51 \n        </div> \n        <div>\n          after incr 4 52 \n        </div> \n       </div> </td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </div> \n <p> &nbsp;&nbsp;&nbsp;是不是无法理解？按道理，incr的返回值就是memcached中的最终结果，与get结果相同。结果一个返回4，一个返回52？ </p> \n <p> &nbsp;&nbsp;&nbsp;等等，4和52，为什么看起来那么眼熟？ </p> \n <p> &nbsp;&nbsp;&nbsp;查阅ascii表得知，4的ascii值刚好是52，难道真这么巧，第二次get的时候，spymemcached客户端将4的字符值当做整型展开，得到了52？ </p> \n <p> &nbsp;&nbsp;&nbsp;不急，先使用telnet终端连接memcached，得到： </p> \n <div> \n  <div> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width:700px;margin:0px !important;padding:0px !important;font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;height:auto !important;text-align:left !important;\"> \n    <tbody> \n     <tr> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;color:#AFAFAF !important;\"> \n       <div>\n         1 \n       </div> \n       <div>\n         2 \n       </div> \n       <div>\n         3 \n       </div> </td> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;\"> \n       <div> \n        <div>\n          get a \n        </div> \n        <div>\n          VALUE a 512 1 \n        </div> \n        <div>\n          4 \n        </div> \n       </div> </td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </div> \n <p> &nbsp;&nbsp;&nbsp;其中512是flag属性。 </p> \n <p> &nbsp;&nbsp;&nbsp;这里简单提到一下memcached协议中的flag机制。flag是memcached除了key、value、expireTime之外额外保存的一个16bit(1.2.4之后为32bit)值，它标志着这个值的”类型“。这个值对于memcached-server是无意义的，它提供给client，来定义对value的处理方式(主要是编码，也有些客户端用flag作为是否压缩的依据)。 </p> \n <p> &nbsp;&nbsp;&nbsp;在spymemcached-client中，0为字符串，512为整数。所以这里虽然值保存为字符串4，但是spymemcached仍然将其当做整数解析，那么就得到了52！ </p> \n <p> &nbsp;&nbsp;&nbsp;于是我们得到一个教训：初始化计数器的时候，请使用字符串memcachedClient.set(key, exp, &quot;0&quot;)，或者自行封装方法。否则可能得到不可预知的结果！ </p> \n <p> <strong>2. incr/decr操作无法刷新过期时间。</strong> </p> \n <p> &nbsp;&nbsp;&nbsp;memcached的协议可以看<a href=\"https://github.com/memcached/memcached/blob/master/doc/protocol.txt\" target=\"_blank\" rel=\"nofollow\">这里</a>。incr/decr操作无法刷新过期时间，所以过期时间以初始化的时间为准。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;最开始以为spy的memcacheClient的incr(String key, int by, long def, int exp)可以刷新过期时间，后来才发现，此方法是封装了incr/decr和add的组合操作。这个exp指的是，若incr失败，则将def值add到此key，并使用这个过期时间exp，如果成功，过期时间不变！ </p> \n <p> &nbsp;&nbsp;&nbsp;因此，如果使用memcached作为长期的计数器，必须用额外的机制定时刷新item。memcached协议提供了touch方法，只刷新时间，不对值作修改，最新的spymemcached 客户端中提供了这个功能。 </p> \n <p> <strong>3. 如果对应值不存在，incr/decr会失败，而不会从0开始计数。</strong> </p> \n <p> &nbsp;&nbsp;&nbsp;telnet下输入： </p> \n <div> \n  <div> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width:700px;margin:0px !important;padding:0px !important;font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;height:auto !important;text-align:left !important;\"> \n    <tbody> \n     <tr> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;color:#AFAFAF !important;\"> \n       <div>\n         1 \n       </div> \n       <div>\n         2 \n       </div> </td> \n      <td style=\"font-size:1em !important;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;border:0px !important;vertical-align:baseline !important;\"> \n       <div> \n        <div>\n          incr b 1 \n        </div> \n        <div>\n          NOT_FOUND \n        </div> \n       </div> </td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </div> \n <p> &nbsp;&nbsp;&nbsp;返回NOT_FOUND，没有incr成功。memcachedClient.incr(key,delta)调用之后，若key不存在，则返回-1。 </p>\n</div>","description":"2012-11-30 13:59","name":"构建一个可靠的分布式计数器--memcached之incr/decr操作实战分析","type":"text"}],"name":"memcached","type":"dir"},{"contents":[{"contents":"<h2>名词王国里的新政-解读Java8之lambda表达式</h2><div class=\"BlogContent\">\n <p>前几天在reddit上看到Java8 M8 Developer Preview版本已经发布了，不免想要尝鲜一把。Developer Preview版本已经所有Feature都完成了，Java8的特性可以在这里看到<a href=\"http://openjdk.java.net/projects/jdk8/features\" rel=\"nofollow\">http://openjdk.java.net/projects/jdk8/features</a>，下载地址：<a href=\"http://jdk8.java.net/download.html\" rel=\"nofollow\">http://jdk8.java.net/download.html</a>。Java8最值得期待的就是lambda表达式了，本文就将带你体验lambda表达式，并进行比较深入的解析。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>下载及配置</h2> \n <p>Intellij IDEA已经完美支持Java8了。首先打开Project Structure，在Project里设置新的JDK路径，并设置Modules=&gt;Source=&gt;Language Level为8.0即可。</p> \n <p>现在我们可以使用Java8编写程序了！但是当我们开开心心编写完，享受到高级的lambda表达式后，运行程序，会提示：<code>java: Compilation failed: internal java compiler error</code>！这是因为javacc的版本还不对，在Compiler=&gt;Java Compiler里将项目对应的javacc版本选为1.8即可。</p> \n <p>什么？你说你用Eclipse？好像目前还没有稳定版！想尝鲜的，可以看看这个地址<a href=\"http://stackoverflow.com/questions/13295275/programming-java-8-in-eclipse\" rel=\"nofollow\">http://stackoverflow.com/questions/13295275/programming-java-8-in-eclipse</a>，大致是先checkout Eclipse JDT的beta java8分支，然后在Eclipse里运行这个项目，从而启动一个支持java8的Eclipse…不过应该难不倒作为geek的你吧！</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>体验lambda表达式</h2> \n <p>好了，我们开始体验Java8的新特性-lambda表达式吧！现在我们的匿名类可以写成这样子了：</p> \n <pre class=\"brush: java; auto-links: false;\">new Thread(() -&gt; {\n        System.out.println(&quot;Foo&quot;);\n    }).start();</pre> \n <p>而之前的写法只能是这样子：</p> \n <pre class=\"brush: java; auto-links: false;\">new Thread(new Runnable() {\n        @Override\n        public void run() {\n            System.out.println(&quot;Foo&quot;);\n        }\n    }).start();</pre> \n <p>这样一看，我们似乎就是匿名类写起来简单了一点啊？而第二种方法，借助便捷的IDE，好像编写效率也没什么差别？博主开始也是这样认为，仔细学习之后，才知道其中的奥妙所在！</p> \n <p>这里有一个重要的信息，就是<strong><code>()-&gt;{}</code>这里代表一个函数，而非一个对象。</strong>可能这么说比较抽象，我们还是代码说话吧：</p> \n <pre class=\"brush: java; auto-links: false;\">public class LambdaTest {\n\n    private static void bar(){\n        System.out.println(&quot;bar&quot;);\n    }\n\n    public static void main(String[] args) {\n        new Thread(LambdaTest::bar).start();\n    }\n\n}</pre> \n <p>看懂了么？这里<code>LambdaTest::bar</code>代表一个函数(用C++的同学笑了)，而new Thread(Runnable runnable)的参数，可以接受是一个函数作为参数！</p> \n <p>是不是觉得很神奇，颠覆了Java思维？在剖析原理以前，博主暂且卖个关子，我们先来讲讲什么是lambda表达式。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>什么是lambda表达式</h2> \n <span id=\"OSC_h3_4\"></span> \n <h3>lambda表达式的由来</h3> \n <p>絮叨几句，现代编程语言的lamdba表达式都来自1930年代初，阿隆佐&middot;邱奇(Alonzo Church)提出的λ演算(Lambda calculus)理论。λ演算的核心思想就是“万物皆函数”。一个λ算子即一个函数，其一般形式是<code>λx.x + 2</code>。一个λ算子可以作为另一个λ算子的输入，从而构建一个高阶的函数。λ演算是函数式编程的鼻祖，大名鼎鼎的编程语言Lisp就是基于λ演算而建立。用过Lisp的应该都清楚，它的语法很简单，但是却有包容万物的能力。</p> \n <p>可能搞计算机的对邱奇比较陌生，但是提起和邱奇同时代的另外一个人，大家就会觉得如雷贯耳了，那就是阿兰&middot;图灵。邱奇成名的时候，图灵还是个大学生。邱奇和图灵一起发表了邱奇-图灵论题，并分别提出了λ演算和图灵机，加上哥德尔提出的递归函数一起，在理论上确定了什么是可计算性。至于什么是可计算性，其实博主也说不清楚，但是现代所有计算机程序语言，都可以认为是从三种之一发展而来，并与之等价的。仅此一点，其影响深远，可想而知。当年教我们《计算理论》的是一个德高望重的教授，人称宋公，每次讲到那个辉煌的年代，总是要停下来，神情专注的感叹一句：“伟大啊！”想想确实挺伟大，人家图灵大学时候就奠定了现代计算机的基础，而我们那会大概还在打DOTA…</p> \n <p>附上大神们的照片，大家感受一下：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0914/160058_HLj3_190591.png\" alt=\"turing etc.\" /></p> \n <span id=\"OSC_h3_5\"></span> \n <h3>现代编程语言中的lambda表达式</h3> \n <p>好了扯远了，神游过了那个伟大的时代，我们继续思考如何编代码做需求吧…</p> \n <p>现代语言的lambda表达式，大概具备几个特征(博主自己归纳的，如有不严谨，欢迎指正)：</p> \n <ol> \n  <li>函数可作为输入；</li> \n  <li>函数可作为输出；</li> \n  <li>函数可作用在函数上，形成高阶函数。</li> \n  <li>函数支持lambda格式的定义。</li> \n </ol> \n <p>其实有了1、2，3也就是顺水推舟的事情，而4其实没有太大的必要性，因为一般语言都有自己的函数定义方式，4仅仅是作为一种补充。当然实现了4的语言，一般都会说：“你看我实现了lambda表达式！”(望向Java8和Python同学)</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>在Java8中使用lambda表达式</h2> \n <span id=\"OSC_h3_7\"></span> \n <h3>FunctionalInterface</h3> \n <p>Java中的lambda无法单独出现，它需要一个接口来盛放。这个接口必须使用@FunctionalInterface作为注解，并且只有一个未实现的方法。等等，什么叫接口中未实现的方法？难道接口中还可以有已实现的方法？恭喜你，猜对了！Java8的接口也可以写实现了！是不是觉得Interface和AbstractClass更加傻傻分不清楚了？但是AbstractClass是无法使用@FunctionalInterface注解的，官方的解释是为了防止AbstractClass的构造函数做一些事情，可能会导致一些调用者意料不到的事情发生。</p> \n <p>好了，我们来看一点代码，Runnable接口现在变成了这个样子：</p> \n <pre class=\"brush: java; auto-links: false;\">@FunctionalInterface\npublic interface Runnable {\n    public abstract void run();\n}</pre> \n <p>这里我们可以将任意无参数的lambda表达式赋值给Runnable:</p> \n <pre class=\"brush: java; auto-links: false;\">Runnable runnable = () -&gt; {\n        System.out.println(&quot;Hello lambda!&quot;);\n    };\n    runnable.run();</pre> \n <p>lambda表达式本质上是一个函数，所以我们还可以用更加神奇的赋值：</p> \n <pre class=\"brush: java; auto-links: false;\">public class HelloLambda {\n\n    private static void hellolambda() {\n        System.out.println(&quot;Hello lambda!&quot;);\n    }\n\n    public static void main(String[] args) {\n        Runnable runnable = HelloLambda::hellolambda;\n        runnable.run();\n    }\n}</pre> \n <p>这里看到这里，大家大概明白了，lambda表达式其实只是个幌子，更深层次的含义是：函数在Java里面可以作为一个实体进行表示了。这就意味着，在Java8里，函数既可以作为函数的参数，也可以作为函数的返回值，即具有了lambda演算的所有特性。</p> \n <span id=\"OSC_h3_8\"></span> \n <h3>Function系列API</h3> \n <p>看到这里，可能大家会有疑问？什么样的函数和什么样的lambda表达式属于同一类型？答案是参数和返回值的类型共同决定函数的类型。例如Runnable的run方法不接受参数，也没有返回值，那么Runnable接口则可以用任意没有参数且没有返回值的函数来赋值。这样概念上来说，Runnable表示的含义就<strong>从一个对象变成了一个方法</strong>。</p> \n <p>这一点在Java8中的java.util.function包里的代码得到了验证。以最具有代表性的Function接口为例：</p> \n <pre class=\"brush: java; auto-links: false;\">@FunctionalInterface\npublic interface Function&lt;T, R&gt; {\n\n    R apply(T t);\n\n}</pre> \n <p>有了Function，我们可以这样写：</p> \n <pre class=\"brush: java; auto-links: false;\">Function&lt;Integer,String&gt; convert = String::valueOf;\n    String s = convert.apply(1);</pre> \n <p>这个东东是不是很像Javascript中的函数对象？</p> \n <p>可惜的是，这里的Function算是个半成品，它只能表示一个有单个参数，并有非void返回值的函数。像System.out.println()这种方法，因为返回值为void，是无法赋值为Function的！</p> \n <p>怎么办？java.util.function包提供了一个不那么完美的解决方案：多定义几个FunctionalInterface呗！</p> \n <p>于是，在Java8里有了：</p> \n <ul> \n  <li>Supplier: 没有参数，只有返回值的函数</li> \n  <li>Consumer: 一个参数，返回值为void的函数</li> \n  <li>BiFunction: 两个参数，一个返回值的函数</li> \n  <li>BiConsumer: 两个参数，没有返回值的函数</li> \n  <li>…</li> \n </ul> \n <p>对于这些个API，我也没有什么力气吐槽了，反正我也想不出更好的方法…大家趁机，多学几个单词吧，嗯。</p> \n <span id=\"OSC_h2_9\"></span> \n <h2>总结：名词王国的新政</h2> \n <p>相信很多同学都看过这篇著名的文章：<a href=\"http://lcwangchao.github.io/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/2012/07/02/excution_in_the_kingdom_of_nouns/\" rel=\"nofollow\">名词王国里的死刑</a>。这篇文章吐槽了Java里，动词(方法)在Java里总是要依附于某个名词(对象/类)存在。</p> \n <p>现在动词在名词王国终于有了一个身份了。当然这个动词需要先取得一个名词的身份(FunctionInterface)，然后才能名正言顺的幸存下来。好在Oracle国王预先为他们留了一些身份(Function、Consumer、Supplier、BiFunction…)，所以大多数动词都已经找到了自己的位置。System.out.println(String)现在是Consumer 了，String.valueOf(Integer)现在是Function 了，Collection.size()现在是Supplier 了…。要为一些较长参数的方法获取一个身份，也是挺容易的(定义一个新的FunctionInterface接口)。 </p> \n <p>我相信这个影响是深远的。例如下面一段代码，可以同一行代码将一个List 转换成一个List ： </p> \n <pre class=\"brush: java; auto-links: false;\">List&lt;String&gt; strings = intList.stream().map(String::valueOf).collect(Collectors.&lt;String&gt;toList());</pre> \n <p>当然问题也存在。因为包含了闭包等因素，FunctionInterface的序列化/反序列化会是一个相当复杂的事情。熟悉Java的开发者，也会因为lambda的引入，带来了一些困惑。俗话说活到老学到老，我倒是不介意这个新功能，你说呢？</p> \n <span id=\"OSC_h2_10\"></span> \n <h2>参考文献：</h2> \n <ol> \n  <li><a href=\"http://blog.sciencenet.cn/blog-414166-628109.html\" rel=\"nofollow\">http://blog.sciencenet.cn/blog-414166-628109.html</a></li> \n  <li><a href=\"http://www.global-sci.org/mc/issues/3/no2/freepdf/80s.pdf\" rel=\"nofollow\">http://www.global-sci.org/mc/issues/3/no2/freepdf/80s.pdf</a></li> \n  <li><a href=\"http://en.wikipedia.org/wiki/Lambda_calculus\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Lambda_calculus</a></li> \n </ol> \n <p><strong>本系列文章还有余下几部分，敬请期待：</strong></p> \n <p><a href=\"http://my.oschina.net/flashsword/blog/161413\" rel=\"nofollow\">lambda表达式与闭包</a></p> \n <p><a href=\"http://www.oschina.net\" rel=\"nofollow\">Java8 lambda表达式原理分析</a></p>\n</div>","description":"2013-09-15 01:30","name":"名词王国里的新政-解读Java8之lambda表达式","type":"text"},{"contents":"<h2>lambda表达式和闭包</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>区分lambda表达式和闭包</h2> \n <p>熟悉的Javascript或者Ruby的同学，可能对另一个名词：闭包更加熟悉。因为一般闭包的示例代码，长得跟lambda差不多，导致我也在以前很长一段时间对这两个概念傻傻分不清楚。其实呢，这两个概念是完全不同维度的东西。</p> \n <p>闭包是个什么东西呢？我觉得Ruby之父松本行弘在《代码的未来》一书中解释的最好：<em>闭包就是把函数以及变量包起来，使得变量的生存周期延长。闭包跟面向对象是一棵树上的两条枝，实现的功能是等价的。</em></p> \n <p>这样说可能不够直观，我们还是用代码说话吧。其实Java在很早的版本就支持闭包了，只是因为应用场景太少，这个概念一直没得到推广。在Java6里，我们可以这样写：</p> \n <pre class=\"brush: java; auto-links: false;\">public static Supplier&lt;Integer&gt; testClosure(){\n    final int i = 1;\n    return new Supplier&lt;Integer&gt;() {\n        @Override\n        public Integer get() {\n            return i;\n        }\n    };\n}\n\npublic interface Supplier&lt;T&gt; {\n    T get();\n}</pre> \n <p>看出问题了么？这里<strong>i</strong>是函数testClosure的内部变量，但是最终返回里的匿名对象里，仍然返回了i。我们知道，函数的局部变量，其作用域仅限于函数内部，在函数结束时，就应该是不可见状态，而闭包则将i的生存周期延长了，并且使得变量可以被外部函数所引用。这就是闭包了。这里，其实我们的lambda表达式还没有出现呢！</p> \n <p>而支持lambda表达式的语言，一般也会附带着支持闭包了，因为lambda总归在函数内部，与函数局部变量属于同一语句块，如果不让它引用局部变量，不会让人很别扭么？例如Python的lambda定义我觉得是最符合λ算子的形式的，我们可以这样定义lambda：</p> \n <pre class=\"brush: python; auto-links: false;\">#!/usr/bin/python\ny = 1\nf=lambda x: x + y\nprint f(2)\ny = 3\nprint f(2)\n输出： \n3\n5</pre> \n <p>这里y其实是外部变量。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>Java中闭包带来的问题</h2> \n <p>在Java的经典著作《Effective Java》、《Java Concurrency in Practice》里，大神们都提到：匿名函数里的变量引用，也叫做变量引用泄露，会导致线程安全问题，因此在Java8之前，如果在匿名类内部引用函数局部变量，必须将其声明为final，即不可变对象。(Python和Javascript从一开始就是为单线程而生的语言，一般也不会考虑这样的问题，所以它的外部变量是可以任意修改的)。</p> \n <p>在Java8里，有了一些改动，现在我们可以这样写lambda或者匿名类了：</p> \n <pre class=\"brush: java; auto-links: false;\">public static Supplier&lt;Integer&gt; testClosure() {\n    int i = 1;\n    return () -&gt; {\n        return i;\n    };\n}</pre> \n <p>这里我们不用写final了！但是，Java大神们说的引用泄露怎么办呢？其实呢，本质没有变，只是Java8这里加了一个语法糖：<strong>在lambda表达式以及匿名类内部，如果引用某局部变量，则直接将其视为final。</strong>我们直接看一段代码吧：</p> \n <pre class=\"brush: java; auto-links: false;\">public static Supplier&lt;Integer&gt; testClosure() {\n    int i = 1;\n    i++;\n    return () -&gt; {\n        return i; //这里会出现编译错误\n    };\n}</pre> \n <p>明白了么？其实这里我们仅仅是省去了变量的final定义，这里i会强制被理解成final类型。很搞笑的是编译错误出现在lambda表达式内部引用i的地方，而不是改变变量值的<code>i++</code>…这也是Java的lambda的一个被人诟病的地方。我只能说，强制闭包里变量必须为final，出于严谨性我还可以接受，但是这个语法糖有点酸酸的感觉，还不如强制写final呢…</p>\n</div>","description":"2013-09-15 05:57","name":"lambda表达式和闭包","type":"text"}],"name":"lambda","type":"dir"},{"contents":[{"contents":"<h2>DNS服务器BlackHole开发日记-起源及一点心得</h2><div class=\"BlogContent\">\n <h3>起因</h3> \n <p>最近公司在做一个邮件系统的项目，涉及到测试对外发送的环节。开始构思是这样：建立一个接收服务器，并将所有请求导向该服务器。这里面就涉及到一个DNS拦截的问题。这个问题其实在开发和测试环境中很常见，但是单是绑hosts或者使用传统DNS都不太能满足需要(不支持通配符)。</p> \n <p>后来调研DNS工具也烦了，于是想自己写一个，实现简单的功能。找到一个Java的开源项目EagleDNS看了下，把UDP连接模块看了看，发现还是比较简单的。于是就构思着开发一个简单的DNS服务器吧！项目托管到了github: <a href=\"https://github.com/code4craft/blackhole\" rel=\"nofollow\">https://github.com/code4craft/blackhole</a></p> \n <p>构想功能和研究协议花了一天时间，后来就急不可耐的开始编码了。花了一个上午，做了写死配置，一个拦截所有请求的简单服务器，发现能够work，更加坚定了信心。</p> \n <p>下午做了一些开发，参考jetty的思路，实现了handler的结构，基本代码成型。因为不想引入Spring，写了一堆很丑的单例。</p> \n <p>晚上回家，引入了Spring，并做了一些bugfix。</p> \n <p>引入了一个监控模块wifesays，后来发现Java有个模块JMX就是做这个事的，长见识了！</p> \n <h3>心得</h3> \n <p>这个项目选择相当有挑战，基本上就是自己开发一个服务器。很重要的一个心得：从零开始开发，开始尝试将需要的组件都自己简单实现，后面再引入框架级的东西，可以更好的理解J2EE世界的工具。</p> \n <p>比如开始准备实现一个简单的GlobalFactory，做Spring做的事，只是省去繁琐的xml配置（而且印象中Spring启动实在是太慢了）。后来发现，依赖管理是相当复杂的一块，特别是初始化的时候的顺序。后来只好引入了Spring，发现Spring本身启动并不慢，而且使用annotation代替xml之后，也相当容易配置，重构起来也很方便，一改我在公司项目开发中，Spring又慢又笨重的印象。</p> \n <p>再比如项目需要做到一个可外部管理应用的东西，当时还得意洋洋的搞了个项目叫wifesays，用的是TCP文本协议。后来才发现，Java有个模块JMX，专门就是用来干这事的。不过之前很难理解JMX，现在发现容易理解很多。</p>\n</div>","description":"2012-12-19 09:45","name":"DNS服务器BlackHole开发日记-起源及一点心得","type":"text"},{"contents":"<h2>BlackHole开发日记-2012-12-15</h2><div class=\"BlogContent\">\n <p>将wifesays独立成一个项目。</p> \n <p>兴致勃勃的定义了wifesays的协议，是一个基于TCP的文本协议，端口用的是老婆的生日40310，呵呵。</p> \n <p>开发了一个wifesays的客户端，用了apache的commons-cli做参数解析（这是个好东西）。目标是代替telnet，并且可以通过文件输入而不是telnet那样全是纯手工的方式。这样写一个配置文件，就可以达到发送测试邮件的目的。后来Socket超时那部分很难搞定，再说吧。</p> \n <p>晚上遇到一个问题：之前的构思是，希望将blackhole作为第一顺序DNS服务器，只负责拦截，然后无法拦截的通过断开连接的方式，使用系统配置的第二顺序DNS服务器解析。</p> \n <p>但是后来发现，这样做会非常低效并且不一定可行。</p> \n <p>MacOX下，当系统尝试第一顺序DNS失败次数过多后，会放弃尝试，以后的请求都会使用其他DNS服务器。</p> \n <p>CentOS下，系统每次请求都会尝试第一顺序DNS服务器，但是超时时间非常长，导致每次解析变得很慢。</p> \n <p>后来尝试使用BlackHole做代理，于是有了转发模式。测试之后，发现转发模式能够工作。当时的兴奋很难形容。</p> \n <p>目标转移到可用性上来，熬夜做了SHELL脚本，并写了README。事实证明README是很有用的。</p>\n</div>","description":"2012-12-19 09:48","name":"BlackHole开发日记-2012-12-15","type":"text"},{"contents":"<h2>BlackHole开发日记-2012-12-16</h2><div class=\"BlogContent\">\n <p>使用BIND的压力测试工具queryperf做了benchmark。</p> \n <p>第一次测试结果不尽人意，拦截模式qps为6000，转发模式只有3000，而BIND有36000。</p> \n <p>后来想到会不会是log的原因？因为到了大于10000qps的时候，IO操作耗时就显得很重要了。于是关掉log重试，结果提升明显，拦截模式qps达到16000，转发模式为8000。</p> \n <p>BIND是采用C写的，难道Java比C有天生的劣势？忽然想到HotSpot虚拟机都是运行一段时间会变快的，于是尝试多次测试，发现拦截模式qps达到30000。看来Java在工作时间变长之后，性能劣势就并非那么明显了。</p> \n <p>benchmark的优秀滋生了将BlackHole做成一个通用DNS服务器的野心。这是一个很宏伟的目标，涉及到DNS协议完全分析、缓存机制、UDP协议分析等。是个很有前途的目标，come on!</p>\n</div>","description":"2012-12-19 09:49","name":"BlackHole开发日记-2012-12-16","type":"text"},{"contents":"<h2>BlackHole开发日记-尝试引入缓存，出现问题</h2><div class=\"BlogContent\">\n <p>今天在公司公开了这个项目，得到大家的肯定，坚定了把这个项目做下去的决心。</p> \n <p>下午公司项目codereview，被指出很多问题。虽然自己在代码可扩展性上做了不少努力，但是大家都反应可读性不那么好。决定以后改进风格。这个决定也体现在BlackHole上，因为一开始就想用英文写代码注释，所以多看看JavaDoc也是很有必要的！锻炼下英文吧，感觉这也是开源的必经之路。</p> \n <p>晚上回家时间不多，尝试着将ehcache引入，结果效果让人大跌眼镜，qps直接降到3000。不知道ehcache做了什么事，感觉额外的东西太多。\b</p> \n <p>但是缓存依然是需要的，得日后调研了，或许自己写一个。</p> \n <p>开始构思的是缓存外部DNS的UDP包内容，后来发现Message.getHeader()存在一个ID，如果该ID不符，则可能导致不正确的结果。queryperf中出现了很多这样的错误：</p> \n <pre class=\"brush: java; auto-links: false;\">Warning: Received a response with an unexpected (maybe timed out) id: 3</pre> \n <p>看来详细研究一下DNS是非常有必要的。</p> \n <p>晚上开始记录开发日志。这才是货真价实的“每天进步一点！”。</p>\n</div>","description":"2012-12-19 09:50","name":"BlackHole开发日记-尝试引入缓存，出现问题","type":"text"},{"contents":"<h2>BlackHole开发日记-几种缓存方式性能测试</h2><div class=\"BlogContent\">\n <p>早上做了ehcache的benchmark，set和get一个40k的字符串(压缩到19k)到ehcache。10000次set和get操作，每次都使用不同的key。</p> \n <p>ehcache的测试结果(10000次)：</p> \n <table> \n  <tbody> \n   <tr> \n    <td>Operation</td> \n    <td>Total(ms)</td> \n    <td>Average(ms)</td> \n   </tr> \n   <tr> \n    <td>set</td> \n    <td>34</td> \n    <td>0.0034</td> \n   </tr> \n   <tr> \n    <td>get</td> \n    <td>6</td> \n    <td>0.00065</td> \n   </tr> \n  </tbody> \n </table> \n <p>结果相当令人满意。</p> \n <p>作为对比，使用JDK提供的简单Cache类型WeakHashMap做一个测试(10000次)：</p> \n <table> \n  <tbody> \n   <tr> \n    <td>Operation</td> \n    <td>Total(ms)</td> \n    <td>Average(ms)</td> \n   </tr> \n   <tr> \n    <td>set</td> \n    <td>4</td> \n    <td>4e-4</td> \n   </tr> \n   <tr> \n    <td>get</td> \n    <td>5</td> \n    <td>5e-4</td> \n   </tr> \n  </tbody> \n </table> \n <p>可以看到，ehcache的set比WeakHashMap耗时提升了10倍，但是get的效率是差不多的。因为cache的使用场景，一般都是读远大于写，所以ehcache是一个胜任的进程内缓存。回去需要调研一下昨天失败的原因。</p> \n <p>出于兴趣，又使用memcached做了一个测试。spy的客户端似乎会将字符串做压缩，最后将40k的字符串压缩到19k，但是结果仍然是毫秒级的，这也证明了涉及到网络IO的操作，会慢上几个数量级。</p> \n <p>memcached的测试结果(1000次)：</p> \n <table> \n  <tbody> \n   <tr> \n    <td>Operation</td> \n    <td>Total(ms)</td> \n    <td>Average(ms)</td> \n   </tr> \n   <tr> \n    <td>set</td> \n    <td>4796</td> \n    <td>4.796</td> \n   </tr> \n   <tr> \n    <td>get</td> \n    <td>1726</td> \n    <td>1.726</td> \n   </tr> \n  </tbody> \n </table> \n <p>开始调研DNS协议。尝试输出DNS query的UDP包内容，发现不是文本编码，看来得研究一下了。</p> \n <p>晚上到家，尝试将MX记录也伪造一下，方法是在domain前面加上mail.，并且把mail.domain记录到A记录列表，下次将这个mail.domain直接指向配置好的IP地址。queryperf真是个好东西。</p> \n <p>晚上使用dig查看了一些知名网站的TTL，发现都在几百到几千之间。后来尝试了一下MacOX下对TTL的应对策略，发现不会又TTL设置那么长，但是绝对跟TTL有关系。</p> \n <p>突然有个想法，可以将BlackHole内置缓存，并且可以主动刷新！这样子就很方便了，因为如果是本地搭建BlackHole，实际上本地做缓存和使用BlackHole缓存效率是相近的。</p> \n <p>明天的任务是解析代理的响应，并做缓存。</p>\n</div>","description":"2012-12-19 09:51","name":"BlackHole开发日记-几种缓存方式性能测试","type":"text"},{"contents":"<h2>BlackHole开发日记-尝试NIO和ehcache</h2><div class=\"BlogContent\">\n <p>今天上班的路上在对比Tomcat和Jety的连接模型。Tomcat使用多线程处理请求，一个请求一个线程；Jetty则采用NIO。有文章说，对于逻辑复杂、处理时间较长的连接，Tomcat有优势，但是对于处理时间较短的连接，Jetty有优势。毫无疑问DNS的处理时间是很短的，看来把之前connector部分多线程的处理模型换成NIO的，应该性能会有一些提升。以后几天一个大的开发计划，就是调研Java NIO和Jetty里的实现，写一个完整的NIO connector。Cache机制开发延后。</p> \n <p>上午在网上找了点资料，磕磕碰碰把基于NIO的服务器模型搭出来了。因为DNS使用的是UDP协议，同时数据量很小，所以NIO并没有起到理想中的效果。</p> \n <p>主要服务器部分代码在<a href=\"https://github.com/flashsword20/blackhole/blob/nio/src/main/java/us/codecraft/blackhole/connector/UDPSocketMonitor.java\" rel=\"nofollow\">https://github.com/flashsword20/blackhole/blob/nio/src/main/java/us/codecraft/blackhole/connector/UDPSocketMonitor.java</a>。测试之后的效果让人失望，NIO效率比多线程+BIO更低，只有24000~28000qps，并且因为代码不熟悉，系统变得很不稳定。所以暂时保留到NIO分支了。</p> \n <p>结论是这样的：</p> \n <p>一个DNS query的包大小大约是几十byte，而response也不超过100 byte，如此小的传输量，同时因为UDP包也不涉及连接建立等东西，发送速度也很快，所以NIO发挥不了效率。</p> \n <p>晚上回家，尝试加入cache机制：</p> \n <p>使用了ehcache，但是死活都存在UDP包乱序的问题。后来发现</p> \n <p><strong>对于同一key，ehcache获取出来的对象总是同一个，这也是进程内缓存的特殊之处，不妨将其想想为一个Map</strong></p> \n <p>而我会尝试改变其ID值，结果就导致看起来ID变了，其实也改变了其他线程获取到的值，出现了不确定性！</p> \n <p>后来改进了数据结构，尝试写一个CopyOnWriteMessage(Message是dnsjava中DNS报文的抽象类)，结果因为其很多方法都是私有，所以失败了。后来构建了一个UDPPackage的对象，尝试将byte[]用CopyOnWrite和访问锁的方式解决并发问题，测试结果CopyOnWrite性能会好一点，这也是因为数据量较小，而且Arrays.copyOf是本地方法吧。</p> \n <p>后来测试，值得高兴的是有缓存的情况下，转发模式效率达到了40000qps，可喜可贺！</p> \n <p>家里连公司，benchmark里，UDP丢包率大概在10%，效果相当差，所以说网络才是第一要素！</p>\n</div>","description":"2012-12-20 13:55","name":"BlackHole开发日记-尝试NIO和ehcache","type":"text"},{"contents":"<h2>BlackHole开发日记-多线程NIO和超时机制</h2><div class=\"BlogContent\">\n <p>今天尝试使用Selector改造转发逻辑，结果可耻的失败了！因为<strong>Selector不是线程安全的</strong>，试图多个线程进行register会导致严重的问题，这也是为什么基于事件的IO模型都不怎么支持多线程的原因，太难做了。</p> \n <p>后来尝试用Java的Future机制来实现超时。我们知道，Java的FutureTask需要一个执行的线程池。如果每次都new出来当然没有问题，但是经测试性能开销较大(qps被降到了4000)。后来尝试复用同一大线程池，发现请求多了之后，总是会超时！</p> \n <p>然后jstack查看发现，很多线程仍然卡在了Callable.call方法，就是我们常说的异常把线程抛死了！原来TimeoutException也会导致线程抛出异常但是无法回收。解决方法：使用future.cancel()。</p> \n <p>这也说明，线程抛出异常死掉时，jstack查看到的是它抛出异常时的执行栈。</p> \n <p>加入超时机制后，程序算是稳定了，这周末弄个1.0版吧，以后开始写ReleaseNotes。</p> \n <p>今天看了一下代码，作为一个开源项目，似乎风格不是那么优雅，很多长函数，注释也不完整。顶多对架构和原理感兴趣，代码的OOP神马的，这方面完全提不起兴趣来啊。</p> \n <p>在自己的MBP上也编译了一个queryperf，测试性能达到55000qps，而拦截模式只有35000，果然还是缓存byte[]更给力啊。因此把拦截模式也加入了cache。</p>\n</div>","description":"2012-12-20 20:35","name":"BlackHole开发日记-多线程NIO和超时机制","type":"text"},{"contents":"<h2>BlackHole开发日记-设置Mac下开机启动，qmail DNS拦截</h2><div class=\"BlogContent\">\n <p>今天，太阳照常升起，逃过了一劫，那就开始新的生命吧。</p> \n <p>为了把BlackHole推广出去，想要做一个MacOS下的包。调研了mac开机启动的东西，将启动程序写成了一个plist文件，放在/Library/LaunchDaemons下面，脚本是这样的：</p> \n <pre class=\"brush: java; auto-links: false;\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;\n&lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt;\n&lt;plist version=&quot;1.0&quot;&gt;\n  &lt;dict&gt;\n      &lt;key&gt;Label&lt;/key&gt;\n      &lt;string&gt;blackhole.init&lt;/string&gt;\n      &lt;key&gt;ProgramArguments&lt;/key&gt;\n      &lt;array&gt;\n        &lt;string&gt;/usr/local/blackhole/blackhole-start.sh&lt;/string&gt;\n      &lt;/array&gt;\n        &lt;key&gt;KeepAlive&lt;/key&gt;\n        &lt;false/&gt;\n      &lt;key&gt;RunAtLoad&lt;/key&gt;\n        &lt;true/&gt;\n        &lt;key&gt;StandardErrorPath&lt;/key&gt;\n        &lt;string&gt;/tmp/blackhole.err&lt;/string&gt;\n        &lt;key&gt;StandardOutPath&lt;/key&gt;\n        &lt;string&gt;/tmp/blackhole.out&lt;/string&gt;\n        &lt;key&gt;UserName&lt;/key&gt;\n        &lt;string&gt;root&lt;/string&gt;\n  &lt;/dict&gt;\n&lt;/plist&gt;</pre> \n <p>事实证明UserName=root那段必须加上，要不然不会用root权限启动，然后就会失败！</p> \n <p>重启后一切正常，开始使用BlackHole作为DNS服务器，考察稳定性。</p> \n <p>早上来到公司就出事了，主进程启动了，wifesays没启动，导致telnet无响应。悲剧！</p> \n <p>为什么wifesays老是启动不起来？</p> \n <p>后来知道，因为<strong>Spring初始化时是阻塞进行的，包括afterPropertySet方法，如果里面调用了耗时较长的程序，则会阻塞直到服务结束才会继续初始化，而这个过程的顺序是未知的</strong>。ehcache初始化的时间挺久(好多秒，不知道为什么)，然后就导致wifesays的进程一直等不到Spring初始化结束，这时调用之，就抛出了空指针异常！后来将ehcache做了异步加载，并进行了错误判断，问题解决！</p> \n <p>下午使用qmail进行拦截测试的时候出了点问题，后来debug发现qmail竟然打了一条ANY类型的请求！原来还有这种类型，长见识了。</p> \n <p>找到几个公用的DNS服务器，以后可以增加多服务器切换的功能。</p> \n <p>多服务器的可用性是个问题，刚好最近也在研究服务器的可用性维护。最终实现如下：使用failedTimes和wakeup机制。failedTimes由外部调用指定，当次数过多时，标志为不可用；内部线程定期循环，尝试检查不可用的服务器，一旦可用，则重新标志为可用。</p>\n</div>","description":"2012-12-21 07:47","name":"BlackHole开发日记-设置Mac下开机启动，qmail DNS拦截","type":"text"},{"contents":"<h2>BlackHole开发日记-设置多个外部DNS并选择</h2><div class=\"BlogContent\">\n <h4>2012-12-22</h4> \n <p>今天做了一天家务，周末比上班还忙啊。晚上9点半开始写了点代码，想把外部DNS选择机制改为：最短请求时间。</p> \n <p>晚上从9点开始写代码，终于到12点写完了。开始尝试用TreeMap做一个按照响应时间自排序的数据结构，类似redis的SortedSet。后来发现：如果尝试改变TreeMap的key值，TreeMap并不会重新排序，到后面就会出现无法预知的结果了！还有一个办法就是写一个incrScore的函数，并且限定score为double类型，但是这时score就没法用自定义类型了，也不是很好用。</p> \n <p>所以最后干脆在弹出时做了一个筛选，每次选出所有元素，并做一个筛选。后来这个算法就能正常运行了。</p> \n <h4>2012-12-23</h4> \n <p>今天下午写了一点代码，尝试把超时跟平均响应时间分开了，分为正常响应时间、次数和超时次数。如何才能做到多个服务器可用性的判断？这个问题有很多种方案，希望找到一个可行有效的方案。</p> \n <p>这又涉及到业务的东西了。上班写一堆业务，下班不想写业务啊写业务。想做一个使用Selector，多个DNS服务器同时forward，使用最快的结果作为响应。但是后来测试，用途不大。</p> \n <p>自己在这里研究这些意义不大，这应该是一个很common的问题。晚上研究一下load balance和failover的东西。</p> \n <p>感觉这几天写的load balance的东西都太不成熟，需要等研究一下相关机制之后，再来继续深入。</p> \n <p>今天也没有想到其他的优化点了。开发先到这里吧，以后做一点推广方面的工作吧，写一个站点，然后把东西挂上去。老薛主机的下载速度太慢了，看来要找个地方把文件放进去。</p>\n</div>","description":"2012-12-23 16:39","name":"BlackHole开发日记-设置多个外部DNS并选择","type":"text"},{"contents":"<h2>BlackHole开发日记-负载均衡，DNS切换</h2><div class=\"BlogContent\">\n <h4>2012-12-24</h4> \n <p>今天写的不能叫开发日记了，主要是学习，主要想要学习一些load balance的东西。</p> \n <p>看了LVS社区的一些东西，系统涉及的目标：透明性、可伸缩性、高可用性和易管理性，跟我想的还不太一样。</p> \n <p>VIP技术：无缝的单点切换。</p> \n <p>这里看了一篇章文嵩博士自己发表的<a href=\"http://zh.linuxvirtualserver.org/node/98\" rel=\"nofollow\">LVS集群系统网络核心原理分析</a>，其中转发的原理有三种模式，可以理解为都是修改IP包内容，然后使用户与Real Server实现通信，看上去就像直接和Load Balancer通信一样。</p> \n <p>调度算法才是我想研究的重点，LVS实现了八中负载均衡调度算法，总结下来分为三种策略： <br />轮循调度(Round-Robin)，最小连接数和哈希。</p> \n <h4>2012-12-25</h4> \n <p>今天想了想，如果把BlackHole作为一个拦截工具的话，一直开启DNS服务器也不合适，所以就想写一个模块，在启动时修改OS的DNS配置，关闭时再把DNS配置切换回去，看看是不是可行？这个工具我另建了一个项目叫<a href=\"https://github.com/flashsword20/dnstools\" rel=\"nofollow\">dnstools</a>。实现了一些windows下的DNS切换，用的是Java外部调用系统命令，目前测试可行，但是系统兼容度就未知了，先做做看吧。</p>\n</div>","description":"2012-12-25 21:20","name":"BlackHole开发日记-负载均衡，DNS切换","type":"text"},{"contents":"<h2>BlackHole开发日记-Mac下动态修改DNS服务器</h2><div class=\"BlogContent\">\n <p>研究了下Mac下DNS的修改方法。Mac下虽然有/etc/resovled.conf文件，但是这个文件是自动生成的，好像也不起什么作用。后来搜到一个帖子<a href=\"http://hints.macworld.com/article.php?story=20050621051643993\" rel=\"nofollow\">Configure DNS lookups from the terminal </a>讲的比较详细。我大概整理下帖子的内容：</p> \n <p>首先，Mac下网络配置存在/Library/Preferences/SystemConfiguration/preferences.plist这个文件中，每次系统重启会读取这个文件。但是尝试直接修改文件后，发现配置不能立刻生效，搜索之后，也没有找到好的办法使它立刻生效。</p> \n <p>还有一个办法是使用scutil。scutil修改的结果在下次重启后会失效，希望持久化修改，请修改/Library/Preferences/SystemConfiguration/preferences.plist文件。网上还搜到一篇关于使用scutil修改DNS的病毒，很好玩。这里贴上帖子里的一段修改DNS的代码，感谢原作者<a href=\"http://hints.macworld.com/users.php?mode=profile&amp;uid=1035540\" rel=\"nofollow\">emzy</a>(10.7下测试通过)：</p> \n <pre class=\"brush: java; auto-links: false;\">#!/bin/bash\n\n# Script is used to set the Nameserver Lookup under Max OS X 10.4 with the Console\n# Script by Stephan Oeste &lt;stephan@oeste.de&gt;\n\nif [ $# -lt 2 ] ; then\necho &quot;Use: $0 &lt;domain&gt; &lt;1.Nameserver&gt; [2.Nameserver]&quot;\necho &quot;Example Use: $0 example.tld 1.2.3.4 1.2.3.5&quot;\nexit 1\nfi\n\nPSID=$( (scutil | grep PrimaryService | sed -e 's/.*PrimaryService : //')&lt;&lt; EOF\nopen\nget State:/Network/Global/IPv4\nd.show\nquit\nEOF\n)\n\nscutil &lt;&lt; EOF\nopen\nd.init\nd.add ServerAddresses * $2 $3 \nd.add DomainName $1\nset State:/Network/Service/$PSID/DNS\nquit\nEOF</pre>\n</div>","description":"2012-12-25 22:38","name":"BlackHole开发日记-Mac下动态修改DNS服务器","type":"text"},{"contents":"<h2>BlackHole开发日记-Java中调用外部命令及scutil使用</h2><div class=\"BlogContent\">\n <p>今天完成了Windows下DNS的读取和写入，用的是ipconfig /all和netsh，在Java中调用脚本大概是这样子的：</p> \n <pre class=\"brush: java; auto-links: false;\">Process exec = Runtime.getRuntime().exec(\n            commandString));\nBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(exec.getInputStream()));</pre> \n <p>bufferedReader读出来就是程序的输出。只要Java程序使用管理员权限启动，那么调用的脚本也会获得对应权限，在MacOS和Win7下测试通过。</p> \n <p>今天仔细研究了下scutil，发现大概是个读写plist的工具。Mac下的配置好像都是基于XML的。</p> \n <pre class=\"brush: java; auto-links: false;\">例如：\n\nopen\nd.init\nd.add ServerAddresses * $2 $3 \nd.add DomainName $1\nset State:/Network/Service/$PSID/DNS</pre> \n <p>这一段中，d其实是个XML的值，scutil里称之为&quot;dict”。如果要获取一个dict的值，就是这么写：</p> \n <pre class=\"brush: java; auto-links: false;\">open\nget State:/Network/Service/$PSID/DNS\nd.show</pre> \n <p>发现另一款类似的软件<a href=\"http://thekelleys.org.uk/dnsmasq/doc.html\" rel=\"nofollow\">dnsmasq</a>，也是用于本地的轻量级DNS服务器，似乎是从hosts文件读取配置，并加以拦截，用于解决某些情况下修改hosts不生效的问题。看来已经有人研究过这个了！不过无论如何，做个东西总是好的。正好学到一些思想什么的。</p>\n</div>","description":"2012-12-26 21:53","name":"BlackHole开发日记-Java中调用外部命令及scutil使用","type":"text"},{"contents":"<h2>BlackHole开发日记-jar包内文件的访问</h2><div class=\"BlogContent\">\n <h4>2012-12-27</h4> \n <p>今天将Mac下DNS设置的模块完成了，于是着手做一个单机服务器吧！将项目拆开成了两个目录，server和localserver。</p> \n <p>另外解决了一个很初级的Spring配置的问题，如果要引入jar包中的配置，需要在classpath后面加上'<em>'，例如： <br />classpath*:/spring/applicationContext</em>.xml</p> \n <p>后来又遇到一个问题：想要把shell脚本打入jar包，但是发现即使获取到了jar包中shell脚本的路径(xxx.jar!/xx/ss这样的路径)，也无法使用外部程序调用这个文件！</p> \n <h4>2012-12-28</h4> \n <p>怎么执行jar包内的shell脚本？这是个有趣的话题。后来尝试使用getResourceAsStream读取出文件，然后再写到临时文件夹，然后访问…好吧，问题解决。</p> \n <p>后来完善了localserver的设计。考虑到项目已经有4个模块了，就引入了maven聚合来完成编译,将xml中module的路径配置一下就可以了。 顺便提一下，maven-jar-plugin也挺好用的，可以将META-INF写入jar包。例如，下面设置依赖路径和执行的Main类:</p> \n <pre class=\"brush: java; auto-links: false;\">&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n    &lt;configuration&gt;\n        &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;addClasspath&gt;true&lt;/addClasspath&gt;\n                &lt;classpathPrefix&gt;lib&lt;/classpathPrefix&gt;\n                &lt;mainClass&gt;us.codecraft.blackhole.selfhost.MacMain&lt;/mainClass&gt;\n            &lt;/manifest&gt;\n        &lt;/archive&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;</pre> \n <h4>2012-12-29</h4> \n <p>今天完成了Mac下的单机服务器版本，可以在程序启动的时候设置DNS服务器、清空DNS缓存，结果遇到了一个比较麻烦的问题：即使系统缓存清空了，浏览器仍然会有缓存。而且有个有趣的事情：<strong>浏览器DNS缓存的时间跟ttl值无关</strong>，因为浏览器不知道A记录的TTL值，所以一旦访问成功，都会尝试用一个固定过期时间来缓存内容。因为这个问题还挺费解的，也给之前的开发和测试带来不少困扰，所以就做了一个详细的研究，写了一篇博文：<a href=\"http://my.oschina.net/flashsword/blog/99068\" rel=\"nofollow\">为什么修改hosts不立即生效？–浏览器DNS缓存机制分析</a>。</p> \n <p>剩下的就是一些操作的包装了，好好考虑和测试一下。</p>\n</div>","description":"2012-12-29 15:28","name":"BlackHole开发日记-jar包内文件的访问","type":"text"},{"contents":"<h2>BlackHole开发日记-Java守护进程、Signal处理</h2><div class=\"BlogContent\">\n <h4>2012-12-30</h4> \n <p>今天继续写单机版BlackHole。碰到一个问题，想要将程序作为系统进程，后台运行，并且在shell关闭时不退出，有两种办法：一种是使用nohup，一种是使用Deamon程序的开发方式来写Java，并引入很多框架，例如Apache Commons Daemon。后者觉得太重了，但是前者无法在控制台输出一些错误信息，也不够友好。最后用了一个很粗暴的方法：将错误输出重定向到一个文件，shell脚本退出的时候打印出来！赢了！</p> \n <p>后来使用package maker做了一个安装包，比想象中好用，支持shell脚本什么的。</p> \n <p>遇到一个问题，在mac下设置两个DNS，BlackHole为主DNS，结果仍然无法保证每次都使用BlackHole进行解析。后来索性改成只有一个DNS，127.0.0.1，倒是正常工作了。</p> \n <p>这个单机版本我取名叫hostd，大概是hosts取代者的意思吧。因为要保证程序即使被kill之后也能做出一些释放资源的操作(在hostd里，需要把修改过的DNS改回来)，所以给wifesays增加了一个响应，用了Java里一个响应信号量的api。</p> \n <pre class=\"brush: java; auto-links: false;\">import sun.misc.Signal;  \nimport sun.misc.SignalHandler; \nSignal.handle(new Signal(&quot;TERM&quot;), new SignalHandler() {\n\n        @Override\n        public void handle(Signal arg0) {\n            shutDown();\n        }\n\n});</pre> \n <h4>2012-12-31</h4> \n <p>新年的最后一天，大家都无心上班，那么我就在上班时间鼓捣项目了！将hostd完善了一下，加入了实时响应配置更改的机制。</p> \n <p>开始的想法是通过md5来判断文件内容是否被更改，但是这样每隔一个周期就必须完全load一次文件，不划算；后来想到，为什么不直接用文件的最后修改时间呢？大多数情况下，只要是人工修改的配置文件，多个配置文件的修改时间是不可能相同的，在Java里直接可以用file.lastModified()来查看，多方便！</p> \n <p>晚上写了一篇广告帖，效果不好，大家都去过节去了嘛。</p> \n <p>后来有个以前搞手机的同事回复我，手机上目前没有方便的hosts修改工具。android下改hostd是需要重启的，相当麻烦。于是感觉找到一个很大的应用场景了！</p> \n <h4>2013-1-1</h4> \n <p>新的一年，新的日期格式，稍微有点不习惯。今天抽空看了一点Android开发的东西，鼓捣了一下adt。网易有个公开课讲android的，个人认为讲的不错，正好学点英语，地址<a href=\"http://v.163.com/special/opencourse/developingandroidapplications.html\" rel=\"nofollow\">密西西比河谷州立大学：Android应用程序开发</a>。 <br />因为视频有点模糊，附上其他地址：<a href=\"http://masl.cis.gvsu.edu/2010/10/12/android-dev-tutorial-now-available-on-the-gvsu-itunes-u-portal/\" rel=\"nofollow\">原文</a>，<a href=\"http://masl.cis.gvsu.edu/wp-content/uploads/2010/10/AndroidTutorialHandout.pdf\" rel=\"nofollow\">讲义</a>，<a href=\"http://masl.cis.gvsu.edu/wp-content/uploads/2010/10/AndroidTutorialSourceCode.zip\" rel=\"nofollow\">源码</a></p>\n</div>","description":"2013-01-02 00:08","name":"BlackHole开发日记-Java守护进程、Signal处理","type":"text"},{"contents":"<h2>BlackHole开发日志-尝试基于Android的DNS服务器</h2><div class=\"BlogContent\">\n <h4>2013-1-2</h4> \n <p>今天白天出门了，晚上把<a href=\"http://v.163.com/special/opencourse/developingandroidapplications.html\" rel=\"nofollow\">Android公开课</a>看了两集。虽然这个课程是比较浅，不过详略还算得当，总得来说还算是不错的，而且只有3个小时，博主对这种速成式的比较感兴趣。后来浏览了几个国内的视频，大多数都是面向零基础的，而且面面俱到，讲的比较慢。因为自己也没打算把这个当正业，加上也有些Java和Swing的基础，了解下大概就可以先试试开发了吧。</p> \n <h4>2013-1-3</h4> \n <p>hostd for Android项目正式启动！目标是在Android下动态修改域名绑定，不需要修改hosts，不需要修改DNS服务器，也不需要重新切换APN，以用于开发环境和线上环境的快速切换。</p> \n <p>因为博主是个猴急的开发者，秉承快速原型的的原则，今天开始了一些开发的尝试。</p> \n <p>因为DNS服务器BlackHole要使用系统端口53，所以首先要确认其在Android上是否能够运行。部署服务艰难重重，记录如下：</p> \n <p>第一次：</p> \n <p>新建一个helloworld Android项目，在buildPath里加入依赖jar包，然后在MainActivity.onCreate()直接启动DNS服务器。尝试第一次，不成功：</p> \n <p>解决：使用adb logcat查看，发现产生了NoClassDefinedError，检查APK包，发现依赖jar没有打进去。再次检查buildPath，在&quot;Order and Export&quot;选项里把这些jar包都勾上，然后jar包被打到APK里。</p> \n <p>第二次：</p> \n <p>因为在BlackHole中使用了Spring，所以出现了问题：ClassPathXmlApplicationContext解析不到xml文件路径：提示找不到对应bean。</p> \n <p>解决：改用FileSystemXmlApplicationContext解析，并将xml存入临时目录/sdcard/spring.xml。结果大跌眼镜，抛出异常：</p> \n <pre class=\"brush: java; auto-links: false;\">Unable to validate using XSD: Your JAXP provider [org.apache.harmony.xml.parsers.DocumentBuilderFactoryImpl@461a0cd0] does not support XML Schema. Are you running on Java 1.4 with Apache Crimson? Upgrade to Apache Xerces (or Java 1.5) for full XSD support.</pre> \n <p>难道Android的xmlparser不支持xsd?感觉不太可能啊，猜测应该是Spinrg底层使用XML parser和Android不兼容(Android包里似乎使用了SAXParser)。于是放弃Spring，看看以后是不是用其他IoC框架了，比如Spring for Android?</p> \n <p>第三次：</p> \n <p>直接启动SocketServer，绑定53端口，进行尝试。</p> \n <p>问题如期而至，显示</p> \n <pre class=\"brush: java; auto-links: false;\">java.net.SocketException: Permission denied</pre> \n <p>解决：根据网络上的解决方案，在程序中插入这一段，理论上可以在运行到这里时，提示需要root权限：</p> \n <pre class=\"brush: java; auto-links: false;\">try {\n        Runtime.getRuntime().exec(&quot;su&quot;);\n    } catch (IOException e) {\n        e.printStackTrace();\n    }</pre> \n <p>结果： <br />没有出现提示，依然没有权限！</p> \n <p>第四次：</p> \n <p>继续搜索资料，发现模拟器没有root权限！作为一个玩安卓不刷机的人，还真不知道该怎么root。后来下载了一个<a href=\"http://ishare.iask.sina.com.cn/f/20228587.html\" rel=\"nofollow\">Root.apk</a>，尝试之，终于成功。</p> \n <p>后来分析，Android root的原理，就是将su替换成另外一个文件，并且使用Superuser来管理这些权限。真是曲折！</p>\n</div>","description":"2013-01-03 21:00","name":"BlackHole开发日志-尝试基于Android的DNS服务器","type":"text"},{"contents":"<h2>BlackHole开发日记-告一段落</h2><div class=\"BlogContent\">\n <h4>2013-1-4</h4> \n <p>后来发现Android下，SocketException是没有网络权限，BindException才是没有系统权限！</p> \n <p>尝试root，发现hosts什么的还是不能改，明天再搞吧！</p> \n <h4>2013-1-5</h4> \n <p>今天咨询了一个做Android的朋友，原来su只能赋予被外部执行的程序的权限，而app本身并不会因此获得权限。所以app中想要使用1024以下端口会失败。朋友他们执行需要root权限的操作，都是使用su加上外部命令来做。没有想象中的那么简单，而且Android环境不熟，开发起来各种调不通，很恼人，看来需要很多时间投入，最近也挺忙的，有大项目要上线了，因此hostd for Android暂时搁置，等有空了再搞吧。</p> \n <p>今天买了一个反和谐工具，了解到了gfw通过DNS污染来拦截的事情。可以使用BlackHole来做一个防止DNS污染的小工具？</p> \n <p>最近要做的东西好多啊，暂时就这样吧。BlackHole写了有三周了，业务时间每天没有间断过，过程中也有不少提升。找机会再更新吧。</p>\n</div>","description":"2013-01-05 20:27","name":"BlackHole开发日记-告一段落","type":"text"},{"contents":"<h2>BlackHole开发日志--防止DNS污染</h2><div class=\"BlogContent\">\n <h3>DNS污染原理</h3> \n <p>DNS污染是比DNS劫持更加难以防御的一种攻击，受攻击者访问网站时可被导向其他域名，例如某“不存在的网站”被导向了一个“不存在的IP地址”。</p> \n <p>DNS污染的原理如下：</p> \n <p>DNS查询也是一个经典的请求-回答模式。首先，客户端发起DNS查询，这是一个UDP包。路由器在转发IP包时，对其内容做解析，若发现其是使用53端口的UDP包，并且其内容符合某些特征(普通的DNS请求都是明文)，则从旁路直接返回一个伪造的应答，将其应答指向某个特定IP。因为这个返回速度非常快，所以先于正常请求到达客户端。而客户端收到一个返回包，就认为得到了答案，不再继续接收，而正确的请求结果就被忽略了！</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0225/221816_5mu8_190591.png\" alt=\"dns-cache-poison\" /></p> \n <p>一般防止DNS污染有几种方法：</p> \n <ul> \n  <li><p>修改系统hosts文件</p> <p>系统的hosts文件可以配置某个域名对于的IP地址，并且会优先于DNS服务器的响应，所以此方法稳定高效，缺点是host地址需要不断更新。</p> </li> \n  <li><p>改用TCP协议而不是DNS协议发送DNS请求</p> <p>DNS也支持TCP协议传输，而TCP协议没有收到污染，所以可以改用TCP作为DNS下层协议。缺点是TCP速度慢，并且DNS服务器支持度有限。代表工具：Tcp-DNS-proxy <a href=\"https://github.com/henices/Tcp-DNS-proxy\" rel=\"nofollow\">https://github.com/henices/Tcp-DNS-proxy</a></p> </li> \n  <li><p>使用IPv6地址发送DNS请求</p> <p>某些站点可以通过IPv6地址访问。代表工具：dnsproxycn <a href=\"http://code.google.com/p/dnsproxycn/\" rel=\"nofollow\">http://code.google.com/p/dnsproxycn/</a></p> </li> \n  <li><p>根据污染特征过滤伪造DNS答案</p> <p>先截获DNS污染结果，然后分析其特征，然后将判断为污染的DNS包过滤掉。代表工具：AntiDnsPollution <a href=\"http://www.williamlong.info/archives/2184.html\" rel=\"nofollow\">http://www.williamlong.info/archives/2184.html</a></p> </li> \n </ul> \n <h3>BlackHole解决方案</h3> \n <p>BlackHole解决方案是第4种：向一个不存在的地址发送DNS查询，正常情况下不会有应答；若触发DNS污染，则只会有伪造包返回。记录这个伪造包的特征(一般是A记录的IP地址)，加入黑名单，下次如果收到这些包，则直接过滤。</p> \n <p>其实开发BlackHole时不知道有AntiDnsPollution这款工具，完成了才知道，采取的方法不谋而合。只不过BlackHole做的更复杂一点，增加了一些功能：</p> \n <ul> \n  <li><p>DNS污染黑名单持久化</p> <p>所有污染IP都会存入&quot;安装路径/blacklist&quot;文件，每次重启可继续读入，也支持手工修改。</p> </li> \n  <li><p>可用IP导出host</p> <p>BlackHole会对IP地址做可达性判断(根据ICMP协议请求)，存在DNS污染的域名，若正确DNS地址中，同时有可达IP，则会产生一条&quot;IP domain&quot;的DNS记录到&quot;安装路径/safehost&quot;文件中，与hosts文件格式一致，可以粘贴进去，从而无须再启动BlackHole。</p> </li> \n  <li><p>支持多DNS服务器请求</p> <p>BlackHole可以同时向多个DNS服务器请求，并采用最先返回的正确结果作为答案返回；同时后台会继续接收响应，并根据最终答案中IP地址的可用性进行判断，去掉不可用的IP。你可以将BlackHole的转发DNS配置为：一个ISP提供的服务器，速度较快；另一个权威的DNS服务器，结果较可信。对于大多数请求，ISP提供的DNS可以满足需要，从而降低查找时间。同时如果在公司内网中使用，还可以将公司内部DNS服务器地址配置进去，这样可以保证内部配置的某些DNS的有效性。</p> </li> \n  <li><p>支持缓存</p> <p>BlackHole使用ehcache作为缓存，并且可以持久化，下次启动时可直接载入上次缓存结果。</p> </li> \n  <li><p>可配置</p> <p>BlackHole还是修改hosts文件的替代方案。通过修改&quot;config/zones&quot;可以自定义DNS拦截规则，支持通配符”*“。</p> </li> \n </ul> \n <p>BlackHole的源码地址：<a href=\"https://github.com/code4craft/blackhole\" rel=\"nofollow\">https://github.com/code4craft/blackhole</a></p>\n</div>","description":"2013-02-25 22:18","name":"BlackHole开发日志--防止DNS污染","type":"text"},{"contents":"<h2>BlackHole开发一段时间了，谈一点心得</h2><div class=\"BlogContent\">\n <p>一直想给自己的软件弄个主页，前几天在折腾django，入手挺简单，都是些基本概念，MVC之类。但是后来感觉用不到这么多功能。今天经@linker_lin 指点发现github可以为每个项目建一个独立的gitpages，完全可自定义html。于是兴趣上来，下载了一个boostrap，就开始自己鼓捣起页面来。</p> \n <p>CSS基本是边用边查，偶尔参考下boostrap的源码，搞定配色后，发现也不那么难看。翻页之前用hr标签，后来干脆抄boostrap首页用背景色岔开。</p> \n <p>然后因为github下载太慢，在自己的VPS上的nginx搞了个静态资源的下载。带宽虽然只有1M，先凑合用吧，总不能给个网盘地址这么不专业吧。总之，一套下来，总算搞定。地址：<a href=\"http://code4craft.github.com/blackhole/\" rel=\"nofollow\">http://code4craft.github.com/blackhole/</a></p> \n <p>整个项目开发下来，觉得挺有成就感的，因为用了好多高级的feature，比如git submodule、NIO、Actor模式等等，呵呵。开始学到很多东西，这跟平时工作做项目还是不一样的，因为基本从零开始，而且自己决定feature，技术也偏底层。</p> \n <p>前几天看了《大教堂与集市》这本书，软件宝贵的资源是用户。可惜目前也没有几个人用，毕竟也只是自己一时兴起的东西。</p> \n <p>发起一个开源项目不容易，维护一个开源项目更不容易，特别是这种“重复造轮子”的项目(当然，自以为还是有特色的)。中间总是断断续续，还好有一次博客上了oschina首页，带来了几个star。如果软件开发者没有持续学习和探索的态度，估计也坚持不下去吧。</p>\n</div>","description":"2013-03-05 21:18","name":"BlackHole开发一段时间了，谈一点心得","type":"text"},{"contents":"<h2>BlackHole开发日志--一次故障排查的经过，关于操作系统DNS重试机制</h2><div class=\"BlogContent\">\n <h3>出现故障</h3> \n <p>昨天下午的时候，在微博上有人私信我。原来是一个用户(应该是在oschina上找到了BlackHole)，在公司内网使用了BlackHole作为内部DNS Server(因为BlackHole配置比较简单嘛)，然后发现，在大规模访问量下，会出现浏览器破页的现象，而且越来越严重。</p> \n <p>当时第一反应很开心，自己鼓捣的这个东西确实派上了用场。后来跟他沟通，与我偶尔遇到的情况是一样的：浏览网页的时候偶尔会有DNS解析不到，使用nslookup结果无问题，但是在终端下ping显示找不到host。使用sudo killall -HUP mDNSResponder刷新系统缓存后，该请求解析正常。</p> \n <h3>初步检查</h3> \n <p>怀疑是操作系统缓存了错误的结果。因为BlackHole在实现的时候有一个trick的技巧：在转发请求的时候，因为发送和返回的设计是异步的，所以需要一个key来将请求和响应对应起来。因为使用了Map结构，所以担心条目太多导致内存泄漏，所以直接使用了DNS头的ID作为key，这个ID是一个16位的整数，空间足够小，不用担心泄漏问题。但是特殊情况下，如果ID冲突，甚至可能发生返回错误的响应的问题。</p> \n <p>但是后来进行了尝试，对某个请求，返回伪造的相应体，并分别尝试了question区伪造和answer区伪造两个方法。但是发现，操作系统能够检查出错误的响应体并进行过滤，然后再重试！于是，这个假设的故障其实是不存在的。</p> \n <h3>按部就班</h3> \n <p>感觉“蒙”的方法总是不准确，还是老老实实按部就班的来吧。个人觉得找bug最好的方法就是重现并记录现场，比没头苍蝇乱找，或者一遍一遍看代码靠谱多了。发现chrome自带了一个工具<a rel=\"nofollow\">net-internel</a>可以查看DNS缓存情况，打开之后发现，确实有部分DNS出现了<em>error: -105 (ERR_NAME_NOT_RESOLVED)</em>的错误。</p> \n <p>因为错误情况非常少且跟输入无关，靠debug是行不通了，只能靠log。在程序中将一个DNS query从接收到转发、返回都打印了log。经过测试发现，原来某些请求返回了空结果！</p> \n <p>原因是我模仿Servlet的ServletContext机制，使用了一个ThreadLocal来记录一些状态，其中就有一条是：ServerContext.hasRecord()，表示是否已经存在答案体。结果这个设计并未经过仔细推敲，里面存在一个重大问题：ThreadLocal是单个线程对应的上下文，而我在主方法中使用了线程池ThreadPoolExecutor，而实际上线程池的线程是复用的！也就是说我这次请求，会拿到另外请求的上下文，所以有些请求本来没有记录，却当作有记录，结果返回了空响应！而且因为这个ThreadLocal变量没有清理机制，所以后来会有越来越多的空响应。</p> \n <p>而DNS server返回空响应(有完整的header和question)也就相当于说，我正常处理了这条请求，但是这个domain是没有数据的，你下次别查了。操作系统的甄别能力是有限的，遇到这个空响应，它就傻傻的相信了，并且缓存了起来。</p> \n <p>至此故障成功定位。解决方案：去掉这个半成品的ServerContext，改为参数传递。改天详细研究一下Servlet的上下文保存机制才行。</p> \n <h3>总结：操作系统DNS缓存及重试机制</h3> \n <p>经过这次排查，也发现了操作系统DNS的一些机制：</p> \n <ul> \n  <li><p>操作系统能够在一定范围内识别不正确的DNS响应(DNS头ID、question区、answer区name错误)，并进行重试。</p> </li> \n  <li><p>操作系统会缓存空记录。</p> </li> \n  <li><p>某些浏览器(例如chrome)会在DNS返回空记录的情况下，让缓存立即过期。这相当于浏览器级别的重试机制。浏览器是能够清除操作系统缓存的。</p> </li> \n </ul> \n <p>经过这番折腾，BlackHole之前一直存在的一个问题也算是解决了。有人把它应用到企业内网，还是挺令人鼓舞的。</p>\n</div>","description":"2013-04-02 14:41","name":"BlackHole开发日志--一次故障排查的经过，关于操作系统DNS重试机制","type":"text"},{"contents":"<h2>BlackHole开发日记-使用三种不同IO模型实现一个DNS代理服务器</h2><div class=\"BlogContent\">\n <p>BlackHoleJ是一个DNS服务器。他的一个功能是，对于它解析不了的DNS请求，它将请求转发到另外一台DNS服务器，然后再将其响应返回给客户端，起到一个DNS代理的作用。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0427/224748_BHdL_190591.png\" alt=\"图解DNS代理\" /></p> \n <p>这个功能的实现经历了三个版本，也对应了三个经典的IO模型。</p> \n <span id=\"OSC_h3_1\"></span> \n <h3>BIO模型(Blocking I/O)</h3> \n <p>BlackHoleJ代理模式最开始的IO模型，实现很简单，当client请求过来时，新建一个线程处理，然后再线程中调用DatagramChannel发送UDP包，同时阻塞等待，最后接收到结果后返回。</p> \n <pre class=\"brush: java; auto-links: false;\">public byte[] forward(byte[] query) throws IOException {\n    DatagramChannel dc = null;\n    dc = DatagramChannel.open();\n    SocketAddress address = new InetSocketAddress(configure.getDnsHost(),\n            Configure.DNS_PORT);\n    dc.connect(address);\n    ByteBuffer bb = ByteBuffer.allocate(512);\n    bb.put(query);\n    bb.flip();\n    dc.send(bb, address);\n    bb.clear();\n    dc.receive(bb);\n    bb.flip();\n    byte[] copyOfRange = Arrays.copyOfRange(bb.array(), 0, 512);\n    return copyOfRange;\n}</pre> \n <p>其中dc.receive(bb)一步是阻塞的。因为请求外部DNS服务器往往耗时较长，所以为了达到快速响应，不得不开很多线程进行处理。同时每个线程都需要进行轮询dc.receive(bb)是否可用，会消耗更多CPU资源。</p> \n <span id=\"OSC_h3_2\"></span> \n <h3>Select模型(I/O multiplexing)</h3> \n <p>BlackHoleJ 1.1开始使用的IO模型。因为DNS使用UDP协议，而UDP其实是无连接的，所以所有请求以及响应复用一个DatagramChannel也毫无问题。同时预先使用DatagramChannel.bind(port)绑定某端口，那么对外部DNS服务器的转发和接收都可以使用这个端口。唯一需要做的就是通过DNS包的特征，来判断到底是哪个客户端的请求！而这个特征也很好选择，DNS包的headerId和question域即可满足需求。</p> \n <p>发送方的伪代码大概是这样：</p> \n <pre class=\"brush: java; auto-links: false;\">public byte[] forward(byte[] queryBytes) {\n    multiUDPReceiver.putForwardAnswer(query, forwardAnswer);\n    forward(queryBytes);\n    forwardAnswer.getLock.getCondition().await();\n    return answer.getAnswer();\n}</pre> \n <p>接收方是一个独立的线程，代码大概是这样的：</p> \n <pre class=\"brush: java; auto-links: false;\">public void receive() {\n    ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n    while (true) {\n        datagramChannel.receive(byteBuffer);\n        final byte[] answer = Arrays.copyOfRange(byteBuffer.array(), 0, 512);\n        getForwardAnswer(answer).setAnswer(answer);\n        getForwardAnswer(answer).getLock.getCondition().notify();\n    }\n}</pre> \n <p>这里forwardAnswer是一个包含了响应结果和一个锁的对象(这里用到了Java的Condition.wait&amp;notify机制，从而使阻塞线程交出控制权，避免更多CPU轮询)。还有一部分是multiUDPReceiver。这里multiUDPReceiver.putForwardAnswer(query, forwardAnswer)实际上是把forwardAnswer注册到一个Map里。</p> \n <p>这样做的好处是仅仅在一个线程检查原本的多路I/O是否就绪，也就是I/O multiplexing。这跟Linux下select模型是一样的。</p> \n <span id=\"OSC_h3_3\"></span> \n <h3>AIO模型(Asynchronous I/O)</h3> \n <p>BlackHoleJ 1.1.3-dev开始，使用了基于回调的AIO模型。这里建立了UDPConnectionResponser对象，里面封装了client的IP和来源端口号。每次收到外部DNS响应时，再根据响应内容找到这个client的IP和来源端口号，重新发送即可。</p> \n <p>这实际上就是封装了callback的异步IO。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0427/224842_Qlur_190591.png\" alt=\"AIO方式的DNS解析\" /></p> \n <p>发送方的伪代码大概是这样：</p> \n <pre class=\"brush: java; auto-links: false;\">public void forward(byte[] queryBytes) {\n    multiUDPReceiver.putForwardAnswer(query, forwardAnswer);\n    forward(queryBytes);\n}</pre> \n <p>接收方的代码大概是这样：</p> \n <pre class=\"brush: java; auto-links: false;\">public void receive() {\n    ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n    while (true) {\n        datagramChannel.receive(byteBuffer);\n        final byte[] answer = Arrays.copyOfRange(byteBuffer.array(), 0, 512);\n        getForwardAnswer(answer).getResponser().response(answer);\n    }\n}</pre> \n <p>这里getResponser().response()直接将结果返回给客户端。</p> \n <span id=\"OSC_h3_4\"></span> \n <h3>测试：</h3> \n <p>使用queryperf进行了测试，使用AIO模型之后，仅仅单线程就达到了40000qps，比1.1.2效率高出了25%，而CPU开销却有了降低。</p>\n</div>","description":"2013-04-27 22:49","name":"BlackHole开发日记-使用三种不同IO模型实现一个DNS代理服务器","type":"text"},{"contents":"<h2>BlackHole开发日记--使用hostd为移动设备切换域名</h2><div class=\"BlogContent\">\n <p> lz的有个朋友最近在做移动开发，聊到移动设备上要切换开发和线上环境比较麻烦。在PC上我们一般修改hosts，但是在移动设备上修改hosts不太方便(需要ROOT、越狱等，修改起来也不方便)。因为之前做过一个DNS服务器BlackHoleJ，所以就萌生了做一个手机改hosts的想法。 </p> \n <p> 最终方案是在PC上启动一个DNS服务器和一个Web服务器。DNS服务器维护一个对应IP的域名配置表，Web服务供移动设备访问，可以修改和管理域名，修改后Web服务器获取客户端的IP，并通知DNS服务器，更新对于这个IP的域名配置。因为BlackHoleJ也有支持企业内网的案例，所以企业内网部署一次，多个终端都可使用。 </p> \n <p> 前前后后折腾了一个月，于是就诞生了<a href=\"http://code4craft.github.io/hostd/\" target=\"_blank\" rel=\"nofollow\">Hostd</a>。 </p> \n <p> 使用Hostd，需要做几件事： </p> \n <ol> \n  <li> <p> <span style=\"line-height:1.5;font-size:10pt;\">在你的内网部署一个Hostd，包括DNS服务器和Web服务器(点这里<a href=\"http://code4craft.github.io/hostd/manage.html\" target=\"_blank\" rel=\"nofollow\">查看教程</a>)，推荐使用有固定IP的机器部署，这样客户端就不用频繁修改了！这里还建议为这台机器分配一个好记的域名，例如： hostd.us，修改/usr/local/blackhole/conf/zones即可进行域名配置。</span> </p> </li> \n  <li> <p> 将要使用Hostd的终端设备的DNS服务器地址修改为Hostd所在IP，如果你是网管，当然可以直接配置DHCP，这样用户就不用手动配置了！ </p> </li> \n  <li> 打开你终端设备的浏览器，访问http://<span>hostd.us(假设你已经绑定了域名)即可！Hostd的<span>Web部分使用了Bootstrap，理论上可以做到响应式的布局，</span>你可以访问<a href=\"http://code4craft.github.io/hostd/demo.html\" target=\"_blank\" rel=\"nofollow\">http://code4craft.github.io/hostd/demo.html</a>&nbsp;进行Web页面的操作演示...js是现学的，勿吐槽...</span> <p> <br /> </p> </li> \n </ol> \n <p> 希望对大家有用！ </p>\n</div>","description":"2013-06-03 09:49","name":"BlackHole开发日记--使用hostd为移动设备切换域名","type":"text"}],"name":"BlackHoleJ","type":"dir"},{"contents":[{"contents":"<h2>关于Struts2的碎碎念</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>一：安全，还是安全</h2> \n <p>我入行比较晚，那会Spring MVC什么的都很流行了，一直觉得struts2作为一个Web MVC框架实在太笨重了点。所以虽然之前一直在用，但是其实没有真正研究过。</p> \n <p>今天公司又遇到一个比较严重的struts的安全问题，最后检查了很久，换最新版也无效。但是因为公司一直在用strtus2，作为一个爱着自己工作的人(逃)，还是决定大致了解一下struts2的源码了。</p> \n <p>直接读代码难免一头雾水，这里推荐一本书《Struts2技术内幕》，有书上的理论作指导就容易得多。这本书讲的挺详细，同时在设计思想上也有不少着力，非常值得一读。</p> \n <p>看了一部分代码后，仔细调试了一下，确认了这个是一个比较严重的安全问题，不知道是否已被官方发现，但是确实在最新版2.3.15.3中仍存在。已经发了邮件给官方，希望能得到一个好的解决方案。</p> \n <p>但是本文的主要的目的不在这里。本文就是理一下struts2的里里外外，不至于遇到问题一头雾水，就足够了。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二：struts2概览</h2> \n <p>struts2结构图如下(自己画的，可能不严谨)：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1115/001209_ikf2_190591.jpg\" alt=\"struts2\" /></p> \n <p>OGNL是底层的表达式引擎，也是安全方面广为诟病的地方。</p> \n <p>XWork是个什么东西呢？它可以理解为一个请求-响应模式的通用框架(不仅仅局限于Web)，这个Action就是一个命令。而struts2可以说是XWork在web领域的一个特定实现。</p> \n <p>XWork是包括Action/Interceptor/Result几个大部分，还有用于执行流程的ActionProxy和ActionInvoker，以及处理数据的ActionContext和ValueStack。XWork的执行流程如下(这里引用了《Struts2技术内幕》的图)：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1115/002314_eEkN_190591.png\" alt=\"xwork\" /></p> \n <span id=\"OSC_h2_3\"></span> \n <h2>三：关于框架的设计思想</h2> \n <p>今天说到在读struts代码，jFinal的作者<a href=\"http://my.oschina.net/jfinal\" target=\"_blank\" rel=\"nofollow\">@jFinal</a> 说struts代码很烂。</p> \n <p>可能我功力不够，倒是没觉得代码很烂，struts2的代码层次化、结构化、扩展性其实都做得不错，比如动态插件机制，比如Result是一个接口，里面包含了一个excute()方法用于决定渲染方式等。但是设计思想上，可能与当前的趋势不符了。</p> \n <p>struts2有个很重要的设计思想：解耦。它希望框架不要侵入业务，包括servlet API里的request/response，尽量让大家写一个POJO就好了。这个POJO脱离了框架，甚至是在其他领域都是可用的。其实在如今web大行其道的时代，其实也没有人会需要无侵入的框架进行迁移，这种设计也不知该说超前还是过时了，但是反而会带来一些不便。</p> \n <p>相反，我觉得框架就该限定领域，好的框架应该提供必要的约束，清晰勾勒出这个领域开发的一种方式，而不是一味追求通用性。这一点我觉得Spring MVC就做的好一些，大家的接受程度也会比较高。场景越确定，框架能做的事越多，开发就越方便，比如jFinal这种框架。</p> \n <p>对于struts，我只能说可能当年的web还未一统天下，大家仍有不同场景的需求吧。</p> \n <p>PS:Web框架是个很大很热的话题，博主一家之言，大家听听就好。</p> \n <p>参考资料：</p> \n <ol> \n  <li>《Struts2技术内幕》<a href=\"http://book.douban.com/subject/7154446/\" rel=\"nofollow\">http://book.douban.com/subject/7154446/</a></li> \n </ol>\n</div>","description":"2013-11-15 00:55","name":"关于Struts2的碎碎念","type":"text"},{"contents":"<h2>小轮子一枚-高仿express的Java服务器</h2><div class=\"BlogContent\">\n <p>之前做了个Java项目<a href=\"https://github.com/code4craft/mocksocks\" rel=\"nofollow\">MockSocks</a>，要做UI，用Swing写实在是又low又费劲，跟前端同事聊起node-webkit，觉得很不错。但是我大部分业务都在Java上，于是就涉及到Java与js通信问题。</p> \n <p>当然最常用的解决方案就是用Java写一个Web后端。但是这样解决太重，大部分时间都要花费在web的配置上，最终还要使用一个容器去启动它，程序流程也无法由我来控制了。</p> \n <p>其实挺喜欢JMX的控制方式，只是用其他语言连接它成本有点高。于是就想仿照JMX的方式写一个Web Server，同时可嵌入到应用中。直接使用Jetty又太原生态了，URL路由/参数映射和转换总是要做的，于是参考了express的语法，就有了一个非常小的Web框架<a href=\"https://github.com/code4craft/express.java\" rel=\"nofollow\">express.java</a>。</p> \n <p>本来开始雄心勃勃的要用netty自己写一个，但是后来遇到尴尬的地方：自己写一套HttpMessage类，设计API其实挺麻烦的，设计得好更是需要时间。如果要重用HttpServletRequest/Response呢，实现起来又太费劲。于是后来还是直接用Jetty写了，就不重复造轮子了。</p> \n <p>Web框架已经到了汗牛充栋的地步，所以也没想跟谁谁比，完成的是自己的需求就够了。这东西不支持任何servlet规范(HttpServletRequest/Response两个对象基于servlet 3.0)，要的就是简单。</p> \n <p>这个WebServer可以在程序内启动，由<code>UrlRouter</code>来完成路由，并路由到对应的<code>Controller</code>上。比较大的特色就是支持动态增加Controller和映射，这样对于新增是非常方便的。例如我有个service里有个状态<code>count</code>，那么我可以这么写：</p> \n <pre class=\"brush: java; auto-links: false;\">public class ServiceMonitor {\n\nprivate int count;\n\nprivate WebServer webServer;\n\npublic ServiceMonitor(WebServer webServer) {\n    this.webServer = webServer;\n    monitor();\n}\n\nprivate void monitor() {\n    webServer.get(&quot;/service/count&quot;, new AjaxController() {\n        @Override\n        public Object ajax(ParamMap params) {\n            return ResultMap.create().put(&quot;count&quot;, count);\n        }\n    });\n}\n\npublic static void main(String[] args) throws Exception {\n    WebServer server = WebServer.jettyServer().port(8080);\n    ServiceMonitor serviceMonitor = new ServiceMonitor(server);\n    server.start();\n    for (int i = 0; i &lt; 1000; i++) {\n        serviceMonitor.count = i;\n        Thread.sleep(1000);\n    }\n}\n}</pre> \n <p>当然这样分散式分配其实会带来一些url的管理问题，不过小项目呢，应该是更方便了。没有想过用这个写web应用，所以目前的定位就是这样子了。</p>\n</div>","description":"2013-11-17 21:32","name":"小轮子一枚-高仿express的Java服务器","type":"text"},{"contents":"<h2>Struts2一个[安全问题]的分析报告</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>一：起因</h2> \n <p>最近公司代码被扫出有一个xss漏洞，检查之后，发现大致是这样一个页面：</p> \n <pre class=\"brush: java; auto-links: false;\">public class DemoAction extends ActionSupport {\n\n    private int id;\n\n        @Override\n        public String execute() throws Exception {\n                return &quot;success&quot;;\n        }\n\n    public int getId() {\n        return id;\n    }\n\n    public void setId(int id) {\n        this.id = id;\n    }\n}</pre> \n <p>模板用的是freemarker，大致是这样子：</p> \n <pre class=\"brush: html; auto-links: false;\">&lt;html class=&quot;G_N&quot;&gt;\n&lt;head&gt;\n\n\n&lt;/head&gt;\n&lt;body id=&quot;top&quot;&gt;\n\n${id}\n&lt;/body&gt;\n&lt;/html&gt;</pre> \n <p>如果我们访问url<code>/demo?id=&lt;script&gt;alert(&quot;xss!&quot;)&lt;/script&gt;</code>，会发现id的参数原封不动的打印到了页面上，就会出现反射型xss!</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二：问题流程</h2> \n <p>分析漏洞原因前，先要稍微看一下struts结构(自己画的，可能不严谨)：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1115/001209_ikf2_190591.jpg\" alt=\"struts2\" /></p> \n <p>OGNL是底层的表达式引擎，是联系起上下文和模板输出的桥梁。</p> \n <p>XWork是个什么东西呢？它可以理解为一个请求-响应模式的通用框架(不仅仅局限于Web)，这个Action就是一个命令。而struts2可以说是XWork在web领域的一个特定实现。</p> \n <p>XWork包括Action/Interceptor/Result几个大部分，还有用于执行流程的ActionProxy和ActionInvoker，以及处理数据的ActionContext和ValueStack。</p> \n <p>所以参数的转换和注入是在XWork里进行。Struts的主要执行流程在<code>DefaultActionInvocation</code>里。大致解释一下流程：</p> \n <p>当Struts捕获到参数时，会交由ognl进行参数转换。我们都知道Struts是通过setter方法进行的参数注入，更进一步的，它是通过ognl表达式来查找方法，并进行属性注入，代码在<code>OgnlRuntime.setProperty</code>里。</p> \n <p>那么如果注入不成功呢？<code>OgnlRuntime</code>会抛出<code>MethodFailedException</code>，然后<code>ConversionErrorInterceptor</code>会将<code>原始参数</code>注入到<code>invocation.getStack()</code>中去，而最终freemarker会读取这个原始数据，并打印到页面上(<code>FreemarkerResult</code>)！这个时候，无论字段最终值是什么都不重要了，因为在ognl的Stack里，它已经用原始值给override了！插一句，其实这个值貌似是为了debug用的，会返回名字为&quot;input&quot;的result，这样会返回找不到方法的404页面，但是公司使用的貌似不太好用，仍然会正常返回！</p> \n <pre class=\"brush: java; auto-links: false;\">if (fakie != null) {\n    // if there were some errors, put the original (fake) values in place right before the result\n    stack.getContext().put(ORIGINAL_PROPERTY_OVERRIDE, fakie);\n    invocation.addPreResultListener(new PreResultListener() {\n        public void beforeResult(ActionInvocation invocation, String resultCode) {\n            Map&lt;Object, Object&gt; fakie = (Map&lt;Object, Object&gt;) invocation.getInvocationContext().get(ORIGINAL_PROPERTY_OVERRIDE);\n\n            if (fakie != null) {\n                   //注入\n                invocation.getStack().setExprOverrides(fakie);\n            }\n        }\n    });\n}</pre> \n <span id=\"OSC_h2_3\"></span> \n <h2>三：求解</h2> \n <p>那么怎么解决这个问题呢？本着回馈社区的精神，给Struts2官方发了一封邮件，并上传了demo到<a href=\"https://github.com/code4craft/xssdemo\" rel=\"nofollow\">https://github.com/code4craft/xssdemo</a>。然后过了一天有个叫Lukasz Lenart的大叔程序员回复我了，老外还是很客气的，回答也很及时(算上时差)。首先确认了问题的存在，然后说这不是一个bug，你可以用${id?html}来进行输出转义。我觉得这个解决方案虽然管用，但是是比较反直观的，因为一般人都会直觉上因为这里只是读取Action中的getter取值，既然是基本类型，哪会还需要转义？本来想喷回去的，又搜了一下这个Lukasz Lenart的来历，然后出来这么个：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1118/212211_F15d_190591.jpg\" alt=\"lukasz\" /></p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1118/215911_jxug_190591.jpeg\" alt=\"s\" /></p> \n <p>被lead亮瞎了！亲力亲为，这才是开源项目的氛围嘛！</p> \n <p>不过呢，即使大神&amp;作者都发话了，我还是希望有框架内的方案，或许去掉<code>ConversionErrorInterceptor</code>是个不错的主意？怎么自定义呢？貌似没办法自定义单个interceptor，但是可以定义一个stack。怎么定义stack?看看struts-core包里的struts-default.xml就知道了！(PS:自定义interceptor是Struts里很有用的技巧，大家不妨自己研究一下)。修改过的代码：<a href=\"https://github.com/code4craft/xssdemo/blob/master/src/main/resources/config/struts/struts.xml\" rel=\"nofollow\">https://github.com/code4craft/xssdemo/blob/master/src/main/resources/config/struts/struts.xml</a></p> \n <p>本文中的解决方案存在风险，请使用之前先进行测试！</p> \n <p>参考资料：</p> \n <ol> \n  <li>《Struts2技术内幕》<a href=\"http://book.douban.com/subject/7154446/\" rel=\"nofollow\">http://book.douban.com/subject/7154446/</a></li> \n </ol>\n</div>","description":"2013-11-18 22:06","name":"Struts2一个[安全问题]的分析报告","type":"text"},{"contents":"<h2>Spring的IoC容器与上帝类</h2><div class=\"BlogContent\">\n <p>最近在准备一个分享，加上正好架构方面要做一个模块化的东西，就顺便学一下Spring了。SSH说起来都是老掉牙的东西，但是目前还是主流，公司也正在用，所以以后会花一些时间在这几个东西的学习上。</p> \n <p>关于IoC的原理和简单实现，我觉得@黄勇的博文<a href=\"http://my.oschina.net/huangyong/blog/158992\" rel=\"nofollow\">《IOC 实现原理》</a>写得已经很好了，用不到100行代码就实现了一个简单的IoC容器。本文完全是基于你已经在使用Spring，想做进一步了解或定制这个场景，所以不评价IoC容器的优劣。本文基于Spring2.5.6。</p> \n <p>Spring的容器类又叫BeanFactory，也有一个更高级的接口，ApplicationContext。后者我们用得更多。而ApplicationContext我们主要用两个实现：XmlWebApplicationContext和ClassPathXmlApplicationContext。前者在web环境使用，后者在主动加载时使用。</p> \n <p>跟@黄勇的例子比，我觉得Spring容器最大的不同是：它不是一个单例，也不是静态类。这就意味着，我可以有多个ApplicationContext。那么可能有人问那Spring是如何注入的呢？答案是注入在初始化bean之后，注入的bean也仅限于同一容器，而不同容器之间的bean则划清了界限。所以在Spring里，其实是不存在上帝类的，而是存在一个个&quot;国家”，由不同的容器进行管理。</p> \n <p>现在我们有需求就是有一些同级的jar包独立开发，然后要统一部署，很可能出现bean冲突的情况，而使用上帝类就会有局限性了。我写了一个扩展，为每个jar包限定一个容器，并用到了Spring的双亲委托机制，主要实现方式是load不同的xml。代码在这里：<a href=\"https://github.com/code4craft/tavern\" rel=\"nofollow\">https://github.com/code4craft/tavern</a></p>\n</div>","description":"2013-12-10 22:53","name":"Spring的IoC容器与上帝类","type":"text"},{"contents":"<h2>1000行代码读懂Spring（一）- 实现一个基本的IoC容器</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>引言</h2> \n <p>最近在读Spring源码，但是Spring代码层次嵌套太多，读起来有很大跳跃性，我有个朋友甚至开玩笑说，读Spring得拿纸笔，把方法和层次都写下来。</p> \n <p>其实Spring我已经接触很久了，记得大学有个老师说过：“学一门技术，最好是先思考一下，如果是你，会怎么实现，再带着问题去学习它”。也有人把程序员与画家做比较，画家有门基本功叫临摹，我想程序员是不是也可以用这样的方式，学习一下世界顶级的项目的编程方法？</p> \n <p>于是就有了<a href=\"https://github.com/code4craft/tiny-spring\" rel=\"nofollow\"><code>tiny-spring</code></a>。这个项目是从我的使用场景出发，理解Spring的功能，并且一步一步完善出来的。类和方法命名基本都是照搬Spring的，包括一些配置格式都相同。这个项目我会控制在1000行以内，但是会尽量覆盖Spring的IoC和AOP核心功能。</p> \n <p><code>tiny-spring</code>是逐步进行构建的，里程碑版本我都使用了git tag来管理。例如，最开始的tag是<code>step-1-container-register-and-get</code>，那么可以使用</p> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-1-container-register-and-get</pre> \n <p>来获得这一版本。</p> \n <p>这次主要是学习IoC部分，以下是各版本的记录：</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>1.step1-最基本的容器</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-1-container-register-and-get</pre> \n <p>IoC最基本的角色有两个：容器(<code>BeanFactory</code>)和Bean本身。这里使用<code>BeanDefinition</code>来封装了bean对象，这样可以保存一些额外的元信息。测试代码：</p> \n <pre class=\"brush: java; auto-links: false;\">// 1.初始化beanfactory\nBeanFactory beanFactory = new BeanFactory();\n\n// 2.注入bean\nBeanDefinition beanDefinition = new BeanDefinition(new HelloWorldService());\nbeanFactory.registerBeanDefinition(&quot;helloWorldService&quot;, beanDefinition);\n\n// 3.获取bean\nHelloWorldService helloWorldService = (HelloWorldService) beanFactory.getBean(&quot;helloWorldService&quot;);\nhelloWorldService.helloWorld();</pre> \n <span id=\"OSC_h2_3\"></span> \n <h2>2.step2-将bean创建放入工厂</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-2-abstract-beanfactory-and-do-bean-initilizing-in-it</pre> \n <p>step1中的bean是初始化好之后再set进去的，实际使用中，我们希望容器来管理bean的创建。于是我们将bean的初始化放入BeanFactory中。为了保证扩展性，我们使用Extract Interface的方法，将<code>BeanFactory</code>替换成接口，而使用<code>AbstractBeanFactory</code>和<code>AutowireCapableBeanFactory</code>作为其实现。“AutowireCapable&quot;的意思是“可自动装配的”，为我们后面注入属性做准备。</p> \n <pre class=\"brush: java; auto-links: false;\">// 1.初始化beanfactory\nBeanFactory beanFactory = new AutowireCapableBeanFactory();\n\n// 2.注入bean\nBeanDefinition beanDefinition = new BeanDefinition();\nbeanDefinition.setBeanClassName(&quot;us.codecraft.tinyioc.HelloWorldService&quot;);\nbeanFactory.registerBeanDefinition(&quot;helloWorldService&quot;, beanDefinition);\n\n// 3.获取bean\nHelloWorldService helloWorldService = (HelloWorldService) beanFactory.getBean(&quot;helloWorldService&quot;);\nhelloWorldService.helloWorld();</pre> \n <span id=\"OSC_h2_4\"></span> \n <h2>3.step3-为bean注入属性</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-3-inject-bean-with-property</pre> \n <p>这一步，我们想要为bean注入属性。我们选择将属性注入信息保存成<code>PropertyValue</code>对象，并且保存到<code>BeanDefinition</code>中。这样在初始化bean的时候，我们就可以根据PropertyValue来进行bean属性的注入。Spring本身使用了setter来进行注入，这里为了代码简洁，我们使用Field的形式来注入。</p> \n <pre class=\"brush: java; auto-links: false;\">// 1.初始化beanfactory\nBeanFactory beanFactory = new AutowireCapableBeanFactory();\n\n// 2.bean定义\nBeanDefinition beanDefinition = new BeanDefinition();\nbeanDefinition.setBeanClassName(&quot;us.codecraft.tinyioc.HelloWorldService&quot;);\n\n// 3.设置属性\nPropertyValues propertyValues = new PropertyValues();\npropertyValues.addPropertyValue(new PropertyValue(&quot;text&quot;, &quot;Hello World!&quot;));\nbeanDefinition.setPropertyValues(propertyValues);\n\n// 4.生成bean\nbeanFactory.registerBeanDefinition(&quot;helloWorldService&quot;, beanDefinition);\n\n// 5.获取bean\nHelloWorldService helloWorldService = (HelloWorldService) beanFactory.getBean(&quot;helloWorldService&quot;);\nhelloWorldService.helloWorld();</pre> \n <span id=\"OSC_h2_5\"></span> \n <h2>4.step4-读取xml配置来初始化bean</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-4-config-beanfactory-with-xml</pre> \n <p>这么大一坨初始化代码让人心烦。这里的<code>BeanDefinition</code>只是一些配置，我们还是用xml来初始化吧。我们定义了<code>BeanDefinitionReader</code>初始化bean，它有一个实现是<code>XmlBeanDefinitionReader</code>。</p> \n <pre class=\"brush: java; auto-links: false;\">// 1.读取配置\nXmlBeanDefinitionReader xmlBeanDefinitionReader = new XmlBeanDefinitionReader(new ResourceLoader());\nxmlBeanDefinitionReader.loadBeanDefinitions(&quot;tinyioc.xml&quot;);\n\n// 2.初始化BeanFactory并注册bean\nBeanFactory beanFactory = new AutowireCapableBeanFactory();\nfor (Map.Entry&lt;String, BeanDefinition&gt; beanDefinitionEntry : xmlBeanDefinitionReader.getRegistry().entrySet()) {\n        beanFactory.registerBeanDefinition(beanDefinitionEntry.getKey(), beanDefinitionEntry.getValue());\n}\n\n// 3.获取bean\nHelloWorldService helloWorldService = (HelloWorldService) beanFactory.getBean(&quot;helloWorldService&quot;);\nhelloWorldService.helloWorld();</pre> \n <span id=\"OSC_h2_6\"></span> \n <h2>5.step5-为bean注入bean</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-5-inject-bean-to-bean</pre> \n <p>使用xml配置之后，似乎里我们熟知的Spring更近了一步！但是现在有一个大问题没有解决：我们无法处理bean之间的依赖，无法将bean注入到bean中，所以它无法称之为完整的IoC容器！如何实现呢？我们定义一个<code>BeanReference</code>，来表示这个属性是对另一个bean的引用。这个在读取xml的时候初始化，并在初始化bean的时候，进行解析和真实bean的注入。</p> \n <pre class=\"brush: java; auto-links: false;\">for (PropertyValue propertyValue : mbd.getPropertyValues().getPropertyValues()) {\n    Field declaredField = bean.getClass().getDeclaredField(propertyValue.getName());\n    declaredField.setAccessible(true);\n    Object value = propertyValue.getValue();\n    if (value instanceof BeanReference) {\n        BeanReference beanReference = (BeanReference) value;\n        value = getBean(beanReference.getName());\n    }\n    declaredField.set(bean, value);\n}</pre> \n <p>同时为了解决循环依赖的问题，我们使用lazy-init的方式，将createBean的事情放到<code>getBean</code>的时候才执行，是不是一下子方便很多？这样在注入bean的时候，如果该属性对应的bean找不到，那么就先创建！因为总是先创建后注入，所以不会存在两个循环依赖的bean创建死锁的问题。</p> \n <pre class=\"brush: java; auto-links: false;\">// 1.读取配置\nXmlBeanDefinitionReader xmlBeanDefinitionReader = new XmlBeanDefinitionReader(new ResourceLoader());\nxmlBeanDefinitionReader.loadBeanDefinitions(&quot;tinyioc.xml&quot;);\n\n// 2.初始化BeanFactory并注册bean\nAbstractBeanFactory beanFactory = new AutowireCapableBeanFactory();\nfor (Map.Entry&lt;String, BeanDefinition&gt; beanDefinitionEntry : xmlBeanDefinitionReader.getRegistry().entrySet()) {\n    beanFactory.registerBeanDefinition(beanDefinitionEntry.getKey(), beanDefinitionEntry.getValue());\n}\n\n// 3.初始化bean\nbeanFactory.preInstantiateSingletons();\n\n// 4.获取bean\nHelloWorldService helloWorldService = (HelloWorldService) beanFactory.getBean(&quot;helloWorldService&quot;);\nhelloWorldService.helloWorld();</pre> \n <span id=\"OSC_h2_7\"></span> \n <h2>6.step6-ApplicationContext登场</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-6-invite-application-context</pre> \n <p>现在BeanFactory的功能齐全了，但是使用起来有点麻烦。于是我们引入熟悉的<code>ApplicationContext</code>接口，并在<code>AbstractApplicationContext</code>的<code>refresh()</code>方法中进行bean的初始化工作。</p> \n <pre class=\"brush: java; auto-links: false;\">ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;tinyioc.xml&quot;);\nHelloWorldService helloWorldService = (HelloWorldService) applicationContext.getBean(&quot;helloWorldService&quot;);\nhelloWorldService.helloWorld();</pre> \n <p>是不是非常熟悉？至此为止，我们的tiny-spring的IoC部分可说完工了。这部分的类、方法命名和作用，都是对应Spring中相应的组件。虽然代码量只有400多行，但是已经有了基本的IoC功能！</p> \n <span id=\"OSC_h2_8\"></span> \n <h2>项目地址</h2> \n <p>最后补充一下项目地址：<a href=\"https://github.com/code4craft/tiny-spring\" rel=\"nofollow\">https://github.com/code4craft/tiny-spring</a></p>\n</div>","description":"2014-01-13 14:04","name":"1000行代码读懂Spring（一）- 实现一个基本的IoC容器","type":"text"},{"contents":"<h2>1000行代码读懂Spring（二）- 在Spring中实现AOP</h2><div class=\"BlogContent\">\n <span id=\"OSC_h2_1\"></span> \n <h2>关于AOP</h2> \n <p>AOP是Spring核心功能之一。今天就用tiny-spring来实现一个AOP。具体功能会包括：</p> \n <ol> \n  <li>读取AspectJ格式的Pointcut描述。</li> \n  <li>使用JDK动态代理以及CGLib两种方式进行AOP织入。</li> \n </ol> \n <p>AOP分为配置(Pointcut，Advice)，织入(Weave)两部分工作，当然还有一部分是将AOP整合到整个容器的生命周期中。</p> \n <p>AOP相关概念较多，我不会一一列举，但是会在每一步对概念做一点解释。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>7.step7-使用JDK动态代理实现AOP织入</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-7-method-interceptor-by-jdk-dynamic-proxy</pre> \n <p>织入（weave）相对简单，我们先从它开始。Spring AOP的织入点是<code>AopProxy</code>，它包含一个方法<code>Object getProxy()</code>来获取代理后的对象。</p> \n <p>在Spring AOP中，我觉得最重要的两个角色，就是我们熟悉的<code>MethodInterceptor</code>和<code>MethodInvocation</code>（这两个角色都是AOP联盟的标准），它们分别对应AOP中两个基本角色：<code>Advice</code>和<code>Joinpoint</code>。Advice定义了在切点指定的逻辑，而Joinpoint则代表切点。</p> \n <pre class=\"brush: java; auto-links: false;\">public interface MethodInterceptor extends Interceptor {\n\n    Object invoke(MethodInvocation invocation) throws Throwable;\n}</pre> \n <p>Spring的AOP只支持方法级别的调用，所以其实在AopProxy里，我们只需要将MethodInterceptor放入对象的方法调用即可。</p> \n <p>我们称被代理对象为<code>TargetSource</code>，而<code>AdvisedSupport</code>就是保存TargetSource和MethodInterceptor的元数据对象。这一步我们先实现一个基于JDK动态代理的<code>JdkDynamicAopProxy</code>，它可以对接口进行代理。于是我们就有了基本的织入功能。</p> \n <pre class=\"brush: java; auto-links: false;\">@Test\n    public void testInterceptor() throws Exception {\n        // --------- helloWorldService without AOP\n        ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;tinyioc.xml&quot;);\n        HelloWorldService helloWorldService = (HelloWorldService) applicationContext.getBean(&quot;helloWorldService&quot;);\n        helloWorldService.helloWorld();\n\n        // --------- helloWorldService with AOP\n        // 1. 设置被代理对象(Joinpoint)\n        AdvisedSupport advisedSupport = new AdvisedSupport();\n        TargetSource targetSource = new TargetSource(helloWorldService, HelloWorldServiceImpl.class,\n                HelloWorldService.class);\n        advisedSupport.setTargetSource(targetSource);\n\n        // 2. 设置拦截器(Advice)\n        TimerInterceptor timerInterceptor = new TimerInterceptor();\n        advisedSupport.setMethodInterceptor(timerInterceptor);\n\n        // 3. 创建代理(Proxy)\n        JdkDynamicAopProxy jdkDynamicAopProxy = new JdkDynamicAopProxy(advisedSupport);\n        HelloWorldService helloWorldServiceProxy = (HelloWorldService) jdkDynamicAopProxy.getProxy();\n\n        // 4. 基于AOP的调用\n        helloWorldServiceProxy.helloWorld();\n\n    }</pre> \n <span id=\"OSC_h2_3\"></span> \n <h2>8.step8-使用AspectJ管理切面</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-8-invite-pointcut-and-aspectj</pre> \n <p>完成了织入之后，我们要考虑另外一个问题：对什么类以及什么方法进行AOP？对于“在哪切”这一问题的定义，我们又叫做“Pointcut”。Spring中关于Pointcut包含两个角色：<code>ClassFilter</code>和<code>MethodMatcher</code>，分别是对类和方法做匹配。Pointcut有很多种定义方法，例如类名匹配、正则匹配等，但是应用比较广泛的应该是和<code>AspectJ</code>表达式的方式。</p> \n <p><code>AspectJ</code>是一个“对Java的AOP增强”。它最早是其实是一门语言，我们跟写Java代码一样写它，然后静态编译之后，就有了AOP的功能。下面是一段AspectJ代码：</p> \n <pre class=\"brush: java; auto-links: false;\">aspect PointObserving {\n    private Vector Point.observers = new Vector();\n\n    public static void addObserver(Point p, Screen s) {\n        p.observers.add(s);\n    }\n    public static void removeObserver(Point p, Screen s) {\n        p.observers.remove(s);\n    }\n    ...\n}</pre> \n <p>这种方式无疑太重了，为了AOP，还要适应一种语言？所以现在使用也不多，但是它的<code>Pointcut</code>表达式被Spring借鉴了过来。于是我们实现了一个<code>AspectJExpressionPointcut</code>：</p> \n <pre class=\"brush: java; auto-links: false;\">@Test\n    public void testMethodInterceptor() throws Exception {\n        String expression = &quot;execution(* us.codecraft.tinyioc.*.*(..))&quot;;\n        AspectJExpressionPointcut aspectJExpressionPointcut = new AspectJExpressionPointcut();\n        aspectJExpressionPointcut.setExpression(expression);\n        boolean matches = aspectJExpressionPointcut.getMethodMatcher().matches(HelloWorldServiceImpl.class.getDeclaredMethod(&quot;helloWorld&quot;),HelloWorldServiceImpl.class);\n        Assert.assertTrue(matches);\n    }</pre> \n <span id=\"OSC_h2_4\"></span> \n <h2>9.step9-将AOP融入Bean的创建过程</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-9-auto-create-aop-proxy</pre> \n <p>万事俱备，只欠东风！现在我们有了Pointcut和Weave技术，一个AOP已经算是完成了，但是它还没有结合到Spring中去。怎么进行结合呢？Spring给了一个巧妙的答案：使用<code>BeanPostProcessor</code>。</p> \n <p>BeanPostProcessor是BeanFactory提供的，在Bean初始化过程中进行扩展的接口。只要你的Bean实现了<code>BeanPostProcessor</code>接口，那么Spring在初始化时，会优先找到它们，并且在Bean的初始化过程中，调用这个接口，从而实现对BeanFactory核心无侵入的扩展。</p> \n <p>那么我们的AOP是怎么实现的呢？我们知道，在AOP的xml配置中，我们会写这样一句话：</p> \n <pre class=\"brush: xml; auto-links: false;\">&lt;aop:aspectj-autoproxy/&gt;</pre> \n <p>它其实相当于：</p> \n <pre class=\"brush: xml; auto-links: false;\">&lt;bean id=&quot;autoProxyCreator&quot; class=&quot;org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator&quot;&gt;&lt;/bean&gt;</pre> \n <p><code>AspectJAwareAdvisorAutoProxyCreator</code>就是AspectJ方式实现织入的核心。它其实是一个BeanPostProcessor。在这里它会扫描所有Pointcut，并对bean做织入。</p> \n <p>为了简化xml配置，我在tiny-spring中直接使用Bean的方式，而不是用aop前缀进行配置：</p> \n <pre class=\"brush: xml; auto-links: false;\">&lt;bean id=&quot;autoProxyCreator&quot; class=&quot;us.codecraft.tinyioc.aop.AspectJAwareAdvisorAutoProxyCreator&quot;&gt;&lt;/bean&gt;\n\n    &lt;bean id=&quot;timeInterceptor&quot; class=&quot;us.codecraft.tinyioc.aop.TimerInterceptor&quot;&gt;&lt;/bean&gt;\n\n    &lt;bean id=&quot;aspectjAspect&quot; class=&quot;us.codecraft.tinyioc.aop.AspectJExpressionPointcutAdvisor&quot;&gt;\n        &lt;property name=&quot;advice&quot; ref=&quot;timeInterceptor&quot;&gt;&lt;/property&gt;\n        &lt;property name=&quot;expression&quot; value=&quot;execution(* us.codecraft.tinyioc.*.*(..))&quot;&gt;&lt;/property&gt;\n    &lt;/bean&gt;</pre> \n <p><code>TimerInterceptor</code>实现了<code>MethodInterceptor</code>（实际上Spring中还有<code>Advice</code>这样一个角色，为了简单，就直接用MethodInterceptor了）。</p> \n <p>至此，一个AOP基本完工。</p> \n <span id=\"OSC_h2_5\"></span> \n <h2>10.step10-使用CGLib进行类的织入</h2> \n <pre class=\"brush: java; auto-links: false;\">git checkout step-10-invite-cglib-and-aopproxy-factory</pre> \n <p>前面的JDK动态代理只能对接口进行代理，对于类则无能为力。这里我们需要一些字节码操作技术。这方面大概有几种选择：<code>ASM</code>，<code>CGLib</code>和<code>javassist</code>，后两者是对<code>ASM</code>的封装。Spring中使用了CGLib。</p> \n <p>在这一步，我们还要定义一个工厂类<code>ProxyFactory</code>，用于根据TargetSource类型自动创建代理，这样就需要在调用者代码中去进行判断。</p> \n <p>另外我们实现了<code>Cglib2AopProxy</code>，使用方式和<code>JdkDynamicAopProxy</code>是完全相同的。</p> \n <p><em>有一个细节是CGLib创建的代理是没有注入属性的， <br />Spring的解决方式是：CGLib仅作代理，任何属性都保存在TargetSource中，使用MethodInterceptor=&gt;TargetSource的方式进行调用。</em></p> \n <p>至此，AOP部分完工，Spring的核心也基本成型。除去import语句，<code>main</code>下面一共是1026行。下篇博文会对Spring进行一个整体的分析。</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>项目地址</h2> \n <p>依然附上项目地址：<a href=\"https://github.com/code4craft/tiny-spring\" rel=\"nofollow\">https://github.com/code4craft/tiny-spring</a></p>\n</div>","description":"2014-01-20 16:58","name":"1000行代码读懂Spring（二）- 在Spring中实现AOP","type":"text"}],"name":"web framework","type":"dir"},{"contents":[{"contents":"<h2>小酒一杯品源码-DbUtils代码解读</h2><div class=\"BlogContent\">\n <p>ORM一直是Web开发一个热点话题，DbUtils则是给出了一个相当简洁的答案。DbUtils的嵌套也不深，而且主动的API调用也非常符合程序员的思维(Hibernate和iBatis这种隐藏了大多数细节的框架，连找到个入口都要费半天劲)。</p> \n <p>话说最常用的CRUD，使用JDBC最痛的无非是将ResultSet转换为JavaBean。DbUtils则是正好命中这个要害，使用<code>ResultSetHandler</code>机制来解决这个问题。</p> \n <p>之前用过Spring JDBC Template，差不多也是这个机制。<code>DbUtils</code>的亮点则是<code>BeanHandler</code>，可以无需手写转换函数，自动根据class生成一个handler。</p> \n <p><code>BeanProcessor</code>的核心代码做了几件事：</p> \n <ul> \n  <li><p>提取Bean的字段信息，结果集的字段信息，并作映射；</p> </li> \n  <li><p>对Bean的字段做类型转换</p> </li> \n </ul> \n <p>字段映射的代码：</p> \n <pre class=\"brush: java; auto-links: false;\">protected int[] mapColumnsToProperties(ResultSetMetaData rsmd,\n        PropertyDescriptor[] props) throws SQLException {\n\n    int cols = rsmd.getColumnCount();\n    int[] columnToProperty = new int[cols + 1];\n    Arrays.fill(columnToProperty, PROPERTY_NOT_FOUND);\n\n    for (int col = 1; col &lt;= cols; col++) {\n        String columnName = rsmd.getColumnLabel(col);\n        if (null == columnName || 0 == columnName.length()) {\n          columnName = rsmd.getColumnName(col);\n        }\n        String propertyName = columnToPropertyOverrides.get(columnName);\n        if (propertyName == null) {\n            propertyName = columnName;\n        }\n        for (int i = 0; i &lt; props.length; i++) {\n\n            if (propertyName.equalsIgnoreCase(props[i].getName())) {\n                columnToProperty[col] = i;\n                break;\n            }\n        }\n    }\n\n    return columnToProperty;\n}</pre> \n <p>这里<code>ResultSetMetaData</code>和<code>PropertyDescriptor</code>分别是JDBC和Bean API里获取的元信息。</p> \n <p>对字段做类型转换的代码比较多，主要方法是<code>callSetter</code>。</p> \n <pre class=\"brush: java; auto-links: false;\">private void callSetter(Object target, PropertyDescriptor prop, Object value)\n        throws SQLException {\n\n    Method setter = prop.getWriteMethod();\n\n    if (setter == null) {\n        return;\n    }\n\n    Class&lt;?&gt;[] params = setter.getParameterTypes();\n    // convert types for some popular ones\n    if (value instanceof java.util.Date) {\n        final String targetType = params[0].getName();\n        if (&quot;java.sql.Date&quot;.equals(targetType)) {\n            value = new java.sql.Date(((java.util.Date) value).getTime());\n        } else if (&quot;java.sql.Time&quot;.equals(targetType)) {\n            value = new java.sql.Time(((java.util.Date) value).getTime());\n        } else if (&quot;java.sql.Timestamp&quot;.equals(targetType)) {\n            value = new java.sql.Timestamp(((java.util.Date) value).getTime());\n        }\n    }\n\n    // Don't call setter if the value object isn't the right type\n    if (this.isCompatibleType(value, params[0])) {\n        setter.invoke(target, new Object[]{value});\n    } else {\n        throw new SQLException(\n                &quot;Cannot set &quot; + prop.getName() + &quot;: incompatible types, cannot convert &quot;\n                        + value.getClass().getName() + &quot; to &quot; + params[0].getName());\n        // value cannot be null here because isCompatibleType allows null\n    }\n\n}</pre> \n <p>这里省略了一些异常的捕获。<code>this.isCompatibleType</code>方法里有一些关于基本类型和装箱类型的转换。</p> \n <pre class=\"brush: java; auto-links: false;\">private boolean isCompatibleType(Object value, Class&lt;?&gt; type) {\n    // Do object check first, then primitives\n    if (value == null || type.isInstance(value)) {\n        return true;\n\n    } else if (type.equals(Integer.TYPE) &amp;&amp; value instanceof Integer) {\n        return true;\n\n    } else if (type.equals(Long.TYPE) &amp;&amp; value instanceof Long) {\n        return true;\n\n    } else if (type.equals(Double.TYPE) &amp;&amp; value instanceof Double) {\n        return true;\n\n    } else if (type.equals(Float.TYPE) &amp;&amp; value instanceof Float) {\n        return true;\n\n    } else if (type.equals(Short.TYPE) &amp;&amp; value instanceof Short) {\n        return true;\n\n    } else if (type.equals(Byte.TYPE) &amp;&amp; value instanceof Byte) {\n        return true;\n\n    } else if (type.equals(Character.TYPE) &amp;&amp; value instanceof Character) {\n        return true;\n\n    } else if (type.equals(Boolean.TYPE) &amp;&amp; value instanceof Boolean) {\n        return true;\n\n    }\n    return false;\n\n}</pre> \n <p>至此，一个ResultSet至Bean的转换就完成了，还是相当简洁的。</p>\n</div>","description":"2013-09-10 22:11","name":"小酒一杯品源码-DbUtils代码解读","type":"text"}],"name":"dao","type":"dir"},{"contents":[{"contents":"<h2>Java反射基准测试</h2><div class=\"BlogContent\">\n <p>以前一直听说Java中使用反射后，效率会大大下降，但是没有直接的数据说明这个问题，于是写了一个测试程序。以下分别为：直接调用反射、缓存反射的method以及直接方法调用。</p> \n <pre class=\"brush: java; auto-links: false;\">public void refctorGet(TestClass[] objects) throws Exception {\n    for (int i = 0; i &lt; count; i++) {\n        Method declaredMethod = TestClass.class\n                .getDeclaredMethod(&quot;getName&quot;);\n        declaredMethod.invoke(objects[i]);\n    }\n}\n\npublic void refctorGetCache(TestClass[] objects) throws Exception {\n    Method declaredMethod = TestClass.class.getDeclaredMethod(&quot;getName&quot;);\n    for (int i = 0; i &lt; count; i++) {\n        declaredMethod.invoke(objects[i]);\n    }\n}\n\npublic void directGet(TestClass[] objects) throws Exception {\n    for (int i = 0; i &lt; count; i++) {\n        objects[i].getName();\n    }\n}</pre> \n <p>对这几个方法分别设置数量为1,000,000和10,000,000，跑了10次，取平均值如下(JDK版本 HotSpot 1.7.0_04-ea,CPU:Intel 2.3G Core i5)：</p> \n <table> \n  <tbody> \n   <tr> \n    <td>Method</td> \n    <td>Time (1,000,000 objects)</td> \n    <td>Time (10,000,000 objects)</td> \n   </tr> \n   <tr> \n    <td>refctorGet</td> \n    <td>1075</td> \n    <td>10558</td> \n   </tr> \n   <tr> \n    <td>refctorGetCache</td> \n    <td>10</td> \n    <td>71</td> \n   </tr> \n   <tr> \n    <td>directGet</td> \n    <td>1</td> \n    <td>8</td> \n   </tr> \n  </tbody> \n </table> \n <p>可以看到，直接方法访问比反射快得多(1000倍)。如果将method缓存起来，每次调用仅仅使用declaredMethod.invoke的话，开销则会小不少(快100倍)。</p>\n</div>","description":"2013-01-06 20:40","name":"Java反射基准测试","type":"text"},{"contents":"<h2>Java里阻塞线程的三种实现方法</h2><div class=\"BlogContent\">\n <p>在日常开发中，我们有时会遇到遇到多线程处理任务的情况，JDK里提供了便利的ThreadPoolExecutor以及其包装的工具类Executors。但是我们知道ExecutorService.excute(Runnable r)是异步的，超过线程池处理能力的线程会被加入到执行队列里。有时候为了保证任务提交的顺序性，我们不希望有这个执行队列，在线程池满的时候，则把主线程阻塞。那么，怎么实现呢？</p> \n <p>最直接的想法是继承ThreadPoolExecutor，重载excute()方法，加入线程池是否已满的检查，若线程池已满，则等待直到上一个任务执行完毕。这里ThreadPoolExecutor提供了一个afterExecute(Runnable r, Throwable t)方法，每个任务执行结束时会调用这个方法。 <br />同时，我们会用到concurrent包的ReentrantLock以及Condition.wait/notify方法。以下是实现代码(代码来自：<a href=\"http://www.cnblogs.com/steeven/archive/2005/12/08/293219.html\" rel=\"nofollow\">http://www.cnblogs.com/steeven/archive/2005/12/08/293219.html</a>)：</p> \n <pre class=\"brush: java; auto-links: false;\">private ReentrantLock pauseLock = new ReentrantLock();\n private Condition unpaused = pauseLock.newCondition();\n @Override\n public void execute(Runnable command) {\n  pauseLock.lock();\n  try {\n   while (getPoolSize()==getMaximumPoolSize() &amp;&amp; getQueue().remainingCapacity()==0)\n    unpaused.await();\n   super.execute(command);//放到lock外面的话，在压力测试下会有漏网的！\n  } catch (InterruptedException e) {\n   log.warn(this, e);\n  } finally {\n   pauseLock.unlock();\n  }\n }\n @Override\n protected void afterExecute(Runnable r, Throwable t) {\n  super.afterExecute(r,t);\n  try{\n   pauseLock.lock();\n   unpaused.signal();\n  }finally{\n   pauseLock.unlock();\n  }\n }</pre> \n <p>当然，有些熟悉JDK源码的人会说，自己实现这个太费劲了，不喜欢！有没有比较简单的方法呢？</p> \n <p>这里介绍一下vela同学的方法： <br /><a href=\"http://vela.diandian.com/post/2012-07-24/40031283329\" rel=\"nofollow\">http://vela.diandian.com/post/2012-07-24/40031283329</a></p> \n <p>研究ThreadPoolExecutor.excute()源码会发现，它调用了BlockingQueue.offer()来实现多余任务的入队。BlockingQueue有两个方法：BlockingQueue.offer()和BlockingQueue.put()，前者在队列满时不阻塞，直接失败，后者在队列满时阻塞。那么，问题就很简单了，继承某个BlockingQueue，然后将offer()重写，改成调用put()就搞定了！最短的代码量，也能起到很好的效果哦！</p> \n <pre class=\"brush: java; auto-links: false;\">package com.diandian.framework.concurrent;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.LinkedBlockingQueue;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\npublic class ExecutorsEx {\n\n    /**\n     * 创建一个堵塞队列\n     * \n     * @param threadSize\n     * @return\n     */\n    public static ExecutorService newFixedThreadPool(int threadSize) {\n        return new ThreadPoolExecutor(threadSize, threadSize, 0L, TimeUnit.MILLISECONDS,\n                new LinkedBlockingQueue&lt;Runnable&gt;(1) {\n\n                    private static final long serialVersionUID = -9028058603126367678L;\n\n                    @Override\n                    public boolean offer(Runnable e) {\n                        try {\n                            put(e);\n                            return true;\n                        } catch (InterruptedException ie) {\n                            Thread.currentThread().interrupt();\n                        }\n                        return false;\n                    }\n                });\n    }\n}</pre> \n <p>当然这个方法有一点让人不快的地方，因为它与我们熟知的OO基本原则之一–里氏替换原则冲突了，即子类的方法与父类的方法有不同的行为。毕竟都是实现了BlockingQueue接口，offer()方法的行为被改变了。虽然只是一个匿名类，但是对于某些OOP的拥趸来说总有些不爽的地方吧！</p> \n <p>没关系，我们还有JDK默认的解决方法：使用RejectedExecutionHandler。当ThreadPoolExecutor.excute执行失败时，会调用的RejectedExecutionHandler，这就是ThreadPoolExecutor的可定制的失败策略机制。JDK默认提供了4种失败策略： <br />AbortPolicy(中止)、CallersRunPolicy(调用者运行)、DiscardPolicy(丢弃)、DiscardOldestPolicy(丢弃最旧的)。 <br />其中值得说的是CallersRunPolicy，它会在excute失败后，尝试使用主线程(就是调用excute方法的线程)去执行它，这样就起到了阻塞的效果！于是一个完完全全基于JDK的方法诞生了：</p> \n <pre class=\"brush: java; auto-links: false;\">public static ExecutorService newBlockingExecutorsUseCallerRun(int size) {\n    return new ThreadPoolExecutor(size, size, 0L, TimeUnit.MILLISECONDS, new SynchronousQueue&lt;Runnable&gt;(),\n            new ThreadPoolExecutor.CallerRunsPolicy());\n}</pre> \n <p>当然这个方法有一个问题：这样加上主线程，总是会比参数的size线程多上一个。要么在函数开始就把size-1，要么，我们可以尝试自己实现一个RejectedExecutionHandler:</p> \n <pre class=\"brush: java; auto-links: false;\">public static ExecutorService newBlockingExecutorsUseCallerRun(int size) {\n    return new ThreadPoolExecutor(size, size, 0L, TimeUnit.MILLISECONDS, new SynchronousQueue&lt;Runnable&gt;(),\n            new RejectedExecutionHandler() {\n\n                @Override\n                public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {\n                    try {\n                        executor.getQueue().put(r);\n                    } catch (InterruptedException e) {\n                        throw new RuntimeException(e);\n                    }\n                }\n            });\n}</pre> \n <p>怎么样，这下是不是感觉挺好了呢？</p> \n <p>2013年9月22日更新：</p> \n <p>事实证明，除了JDK的CallerRunsPolicy方案，其他的方案都存在一个隐患：</p> \n <p>如果线程仍在执行，此时显式调用<code>ExecutorService.shutdown()</code>方法，会因为还有一个线程阻塞没有入队，而此时线程已经停止了，而这个元素才刚刚入队，最终会导致<code>RejectedExecutionException</code>。</p>\n</div>","description":"2013-03-18 18:55","name":"Java里阻塞线程的三种实现方法","type":"text"}],"name":"JDK","type":"dir"},{"contents":[{"contents":"<h2>Java NIO学习笔记之一-资料整理</h2><div class=\"BlogContent\">\n <p>最近要用Java写一个socks proxy，本来基于jsocks改了改，但是jsocks的BIO和线程模型到了高并发下简直惨不忍睹。想了一下，最后决定用NIO重写一个socks proxy了，为了方便，可能会忽略掉socks5的认证部分。</p> \n <p>说来惭愧，用Java这么久了，对NIO的理解完全停留在IO模型的概念上，一直没有真正写过一个意义上的NIO程序，所以趁机详细学习一下。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>NIO核心API</h2> \n <p><a href=\"http://weibo.com/haoel\" rel=\"nofollow\">@左耳朵耗子</a>写过一篇关于NIO Selector的分析<a href=\"http://blog.csdn.net/haoel/article/details/2224055\" rel=\"nofollow\">http://blog.csdn.net/haoel/article/details/2224055</a>。耗子一直是我的偶像，这篇文章页写的不错，这里就不重复描述了，引用一下：</p> \n <span id=\"OSC_h3_2\"></span> \n <h3>Channel</h3> \n <p>包含数据且用于读写的线形表结构。其中还提供了一个特殊类用于内存映射文件的I/O操作。</p> \n <span id=\"OSC_h3_3\"></span> \n <h3>Charset</h3> \n <p>它提供Unicode字符串影射到字节序列以及逆映射的操作。</p> \n <span id=\"OSC_h3_4\"></span> \n <h3>Buffer</h3> \n <p>包含socket，file和pipe三种管道，都是全双工的通道。</p> \n <span id=\"OSC_h3_5\"></span> \n <h3>Selector</h3> \n <p>多个异步I/O操作集中到一个或多个线程中（可以被看成是Unix中select()函数的面向对象版本）。</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>一些开源项目中的NIO</h2> \n <p>我觉得学习NIO最好的方式就是看一些开源项目的实现。<a href=\"http://weibo.com/u/1271519972\" rel=\"nofollow\">@武汉伢袁志俊</a>写过一个系列：<a href=\"http://blog.csdn.net/cutesource/article/details/6192016\" rel=\"nofollow\">http://blog.csdn.net/cutesource/article/details/6192016</a></p> \n <p>下篇文章从Buffer开始，系统的学习一下。</p>\n</div>","description":"2013-09-06 14:22","name":"Java NIO学习笔记之一-资料整理","type":"text"},{"contents":"<h2>Java NIO学习笔记之二-图解ByteBuffer</h2><div class=\"BlogContent\">\n <p>ByteBuffer前前后后看过好几次了，实际使用也用了一些，总觉得条理不够清晰。</p> \n <p>《程序员的思维修炼》一本书讲过，主动学习，要比单纯看资料效果来的好，所以干脆写个详细点的文章来记录一下。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>概述</h2> \n <p>ByteBuffer是NIO里用得最多的Buffer，它包含两个实现方式：<code>HeapByteBuffer</code>是基于Java堆的实现，而<code>DirectByteBuffer</code>则使用了<code>unsafe</code>的API进行了堆外的实现。这里只说HeapByteBuffer。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>使用</h2> \n <p>ByteBuffer最核心的方法是<code>put(byte)</code>和<code>get()</code>。分别是往ByteBuffer里写一个字节，和读一个字节。</p> \n <p>值得注意的是，ByteBuffer的读写模式是分开的，正常的应用场景是：往ByteBuffer里写一些数据，然后flip()，然后再读出来。</p> \n <p>这里插两个Channel方面的对象，以便更好的理解Buffer。</p> \n <p><code>ReadableByteChannel</code>是一个从Channel中读取数据，并保存到ByteBuffer的接口，它包含一个方法：</p> \n <pre class=\"brush: java; auto-links: false;\">public int read(ByteBuffer dst) throws IOException;</pre> \n <p><code>WritableByteChannel</code>则是从ByteBuffer中读取数据，并输出到Channel的接口：</p> \n <pre class=\"brush: java; auto-links: false;\">public int write(ByteBuffer src) throws IOException;</pre> \n <p>那么，一个ByteBuffer的使用过程是这样的：</p> \n <pre class=\"brush: java; auto-links: false;\">byteBuffer = ByteBuffer.allocate(N);\n//读取数据，写入byteBuffer\nreadableByteChannel.read(byteBuffer);\n//变读为写\nbyteBuffer.flip();\n//读取byteBuffer，写入数据\nwritableByteChannel.write(byteBuffer);</pre> \n <p>看到这里，一般都不太明白flip()干了什么事，先从ByteBuffer结构说起：</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>ByteBuffer内部字段</h2> \n <span id=\"OSC_h3_4\"></span> \n <h3>byte[] buff</h3> \n <p>buff即内部用于缓存的数组。</p> \n <span id=\"OSC_h3_5\"></span> \n <h3>position</h3> \n <p>当前读取的位置。</p> \n <span id=\"OSC_h3_6\"></span> \n <h3>mark</h3> \n <p>为某一读过的位置做标记，便于某些时候回退到该位置。</p> \n <span id=\"OSC_h3_7\"></span> \n <h3>capacity</h3> \n <p>初始化时候的容量。</p> \n <span id=\"OSC_h3_8\"></span> \n <h3>limit</h3> \n <p>读写的上限，limit&lt;=capacity。</p> \n <span id=\"OSC_h2_9\"></span> \n <h2>图解</h2> \n <span id=\"OSC_h3_10\"></span> \n <h3>put</h3> \n <p>写模式下，往buffer里写一个字节，并把postion移动一位。写模式下，一般limit与capacity相等。 <br /><img src=\"http://static.oschina.net/uploads/space/2013/0906/145012_wNAE_190591.png\" alt=\"bytebuffer-put\" /></p> \n <span id=\"OSC_h3_11\"></span> \n <h3>flip</h3> \n <p>写完数据，需要开始读的时候，将postion复位到0，并将limit设为当前postion。 <br /><img src=\"http://static.oschina.net/uploads/space/2013/0906/145641_qTuf_190591.png\" alt=\"bytebuffer-flip\" /></p> \n <span id=\"OSC_h3_12\"></span> \n <h3>get</h3> \n <p>从buffer里读一个字节，并把postion移动一位。上限是limit，即写入数据的最后位置。 <br /><img src=\"http://static.oschina.net/uploads/space/2013/0906/145049_jHFW_190591.png\" alt=\"bytebuffer-get\" /></p> \n <span id=\"OSC_h3_13\"></span> \n <h3>clear</h3> \n <p>将position置为0，并不清除buffer内容。 <br /><img src=\"http://static.oschina.net/uploads/space/2013/0906/145130_5UA5_190591.png\" alt=\"bytebuffer-clear\" /></p> \n <p>mark相关的方法主要是<code>mark()</code>(标记)和<code>reset()</code>(回到标记)，比较简单，就不画图了。</p>\n</div>","description":"2013-09-06 14:59","name":"Java NIO学习笔记之二-图解ByteBuffer","type":"text"}],"name":"nio","type":"dir"},{"contents":[{"contents":"<h2>一次线上OOM故障排查经过</h2><div class=\"BlogContent\">\n <p>本文是一次线上OOM故障排查的经过，内容比较基础但是真实，主要是记录一下，没有OOM排查经验的同学也可以参考。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>现象</h2> \n <p>我们之前有一个计算作业。最近经常出现不稳定，无法正常响应的情况。具体表现是：各种连接超时，从mysql、mongodb和zookeeper到netty，能超时的都超时过了。其他看不到太多有效的异常。</p> \n <p>所以我们首先怀疑的是网络问题，打电话跟运维确认，运维说网络问题的可能性几乎为0，因为我们的机器是虚机，宿主机上的其他设备都运转正常。程序问题的可能性更大。继续从应用日志和tomcat的catalina.out中查找日志，发现有一些OutOfMemoryError异常。实际上，出现这个异常就代表内存不够了。</p> \n <p>我们使用cat（公司的Java监控平台，已开源<a href=\"https://github.com/dianping/cat\" rel=\"nofollow\">https://github.com/dianping/cat</a>）查看堆使用的情况，看到如下的东西：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2014/0305/093930_DljD_190591.png\" alt=\"cat oom\" /></p> \n <p>Memory Free已经接近了0，同时产生了大量的fullgc。</p> \n <p>回到之前的连接timeout，我们知道，Java的连接timeout，除了网络传输的时间，也包括了Java程序处理的时间，所以OOM导致timeout也不奇怪了。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>工具和排查</h2> \n <p>之前JVM分析做的很少，在同事的帮助下，结合一点资料，完成了基本的分析。</p> \n <p>首先可用的是</p> \n <pre class=\"brush: java; auto-links: false;\">jmap -histo PID</pre> \n <p>这个命令会将内存中最终保存的对象列出来。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2014/0305/095032_407L_190591.png\" alt=\"jmap-histo\" /></p> \n <p>其中”[“表示数组，例如”[B&quot;是byte[]，具体可以看<code>Class.getName()</code>的Javadoc。</p> \n <p>但是这个只能粗略定位原因，如果要仔细分析，需要知道是哪些个对象持有了它，这个时候，就需要dump内存下来，再离线分析了。</p> \n <p>dump内存的命令是：</p> \n <pre class=\"brush: java; auto-links: false;\">jmap -dump:format=b,file=/home/admin/dump.bin PID</pre> \n <p>此操作异常耗时，我跟运维在假死的机器上尝试了几次，竟然把tomcat进程干掉了，使用时还是小心为妙…跟同事讨论，认为<code>jmap -dump</code>实际上也是往运行的JVM实例发送一个dump请求，所以如果实例内存不足，dump很可能会失败。比较好的做法是先降低一部分负载（比如把线上的机器先切下线）再试。</p> \n <p>我这里使用<code>VisualVM</code>进行分析，大致效果如下：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2014/0305/095802_NpnZ_190591.png\" alt=\"visual-vm\" /></p> \n <p>这里选择“计算保留大小”。这个保留大小是递归计算实例之间的依赖，得到的总大小。因为去掉了循环依赖，所以并不完全准确，但是用于排查够了。选择保留大小最大的实例，一般就是罪魁祸首了！</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2014/0306/082920_2wI3_190591.png\" alt=\"visual-vm2\" /></p> \n <p>最后排查出的结果，是公司的RPC中间件使用了ThreadLocal来保存一个context，但是最后却没有释放。按照架构组的说明，升级了版本，问题解决！</p>\n</div>","description":"2014-03-05 10:02","name":"一次线上OOM故障排查经过","type":"text"}],"name":"JVM","type":"dir"},{"contents":[{"contents":"<h2>Netty那点事（一）概述</h2><div class=\"BlogContent\">\n <p>Netty和Mina是Java世界非常知名的通讯框架。它们都出自同一个作者，Mina诞生略早，属于Apache基金会，而Netty开始在Jboss名下，后来出来自立门户netty.io。关于Mina已有@FrankHui的<a href=\"http://my.oschina.net/ielts0909/blog/92716\" rel=\"nofollow\">Mina系列文章</a>，我正好最近也要做一些网络方面的开发，就研究一下Netty的源码，顺便分享出来了。</p> \n <p>Netty目前有两个分支：4.x和3.x。4.0分支重写了很多东西，并对项目进行了分包，规模比较庞大，入手会困难一些，而3.x版本则已经被广泛使用。本系列文章针对netty 3.7.0 final。3.x和4.0的区别可以参考这篇文章：<a href=\"http://www.oschina.net/translate/netty-4-0-new-and-noteworthy?print\" rel=\"nofollow\">http://www.oschina.net/translate/netty-4-0-new-and-noteworthy?print</a>。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>起：Netty是什么</h2> \n <p>大概用Netty的，无论新手还是老手，都知道它是一个“网络通讯框架”。所谓框架，基本上都是一个作用：基于底层API，提供更便捷的编程模型。那么&quot;通讯框架&quot;到底做了什么事情呢？回答这个问题并不太容易，我们不妨反过来看看，不使用netty，直接基于NIO编写网络程序，你需要做什么(以Server端TCP连接为例，这里我们使用Reactor模型)：</p> \n <ol> \n  <li>监听端口，建立Socket连接</li> \n  <li>建立线程，处理内容 \n   <ol> \n    <li>读取Socket内容，并对协议进行解析</li> \n    <li>进行逻辑处理</li> \n    <li>回写响应内容</li> \n    <li>如果是多次交互的应用(SMTP、FTP)，则需要保持连接多进行几次交互</li> \n   </ol> </li> \n  <li>关闭连接</li> \n </ol> \n <p>建立线程是一个比较耗时的操作，同时维护线程本身也有一些开销，所以我们会需要多线程机制，幸好JDK已经有很方便的多线程框架了，这里我们不需要花很多心思。</p> \n <p>此外，因为TCP连接的特性，我们还要使用连接池来进行管理：</p> \n <ol> \n  <li>建立TCP连接是比较耗时的操作，对于频繁的通讯，保持连接效果更好</li> \n  <li>对于并发请求，可能需要建立多个连接</li> \n  <li>维护多个连接后，每次通讯，需要选择某一可用连接</li> \n  <li>连接超时和关闭机制</li> \n </ol> \n <p>想想就觉得很复杂了！实际上，基于NIO直接实现这部分东西，即使是老手也容易出现错误，而使用Netty之后，你只需要关注逻辑处理部分就可以了。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>承：体验Netty</h2> \n <p>这里我们引用Netty的example包里的一个例子，一个简单的EchoServer，它接受客户端输入，并将输入原样返回。其主要代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">public void run() {\n    // Configure the server.\n    ServerBootstrap bootstrap = new ServerBootstrap(\n            new NioServerSocketChannelFactory(\n                    Executors.newCachedThreadPool(),\n                    Executors.newCachedThreadPool()));\n\n    // Set up the pipeline factory.\n    bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n        public ChannelPipeline getPipeline() throws Exception {\n            return Channels.pipeline(new EchoServerHandler());\n        }\n    });\n\n    // Bind and start to accept incoming connections.\n    bootstrap.bind(new InetSocketAddress(port));\n}</pre> \n <p>这里<code>EchoServerHandler</code>是其业务逻辑的实现者，大致代码如下：</p> \n <pre class=\"brush: java; auto-links: false;\">public class EchoServerHandler extends SimpleChannelUpstreamHandler {\n\n    @Override\n    public void messageReceived(\n            ChannelHandlerContext ctx, MessageEvent e) {\n        // Send back the received message to the remote peer.\n        e.getChannel().write(e.getMessage());\n    }\n}</pre> \n <p>还是挺简单的，不是吗？</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>转：Netty背后的事件驱动机制</h2> \n <p>完成了以上一段代码，我们算是与Netty进行了第一次亲密接触。如果想深入学习呢？</p> \n <p>首先推荐Netty的官方User Guide：<a href=\"http://netty.io/3.7/guide/\" rel=\"nofollow\">http://netty.io/3.7/guide/</a>。其次，阅读源码是了解一个开源工具非常好的手段，但是Java世界的框架大多追求大而全，功能完备，如果逐个阅读，难免迷失方向，Netty也并不例外。相反，抓住几个重点对象，理解其领域概念及设计思想，从而理清其脉络，相当于打通了任督二脉，以后的阅读就不再困难了。</p> \n <p>理解Netty的关键点在哪呢？我觉得，除了NIO的相关知识，另一个就是事件驱动的设计思想。什么叫事件驱动？我们回头看看<code>EchoServerHandler</code>的代码，其中的参数：<code>public void messageReceived(ChannelHandlerContext ctx, MessageEvent e)</code>，MessageEvent就是一个事件。这个事件携带了一些信息，例如这里<code>e.getMessage()</code>就是消息的内容，而<code>EchoServerHandler</code>则描述了处理这种事件的方式。一旦某个事件触发，相应的Handler则会被调用，并进行处理。这种事件机制在UI编程里广泛应用，而Netty则将其应用到了网络编程领域。</p> \n <p>在Netty里，所有事件都来自<code>ChannelEvent</code>接口，这些事件涵盖监听端口、建立连接、读写数据等网络通讯的各个阶段。而事件的处理者就是<code>ChannelHandler</code>，这样，不但是业务逻辑，连网络通讯流程中底层的处理，都可以通过实现<code>ChannelHandler</code>来完成了。事实上，Netty内部的连接处理、协议编解码、超时等机制，都是通过handler完成的。当博主弄明白其中的奥妙时，不得不佩服这种设计！</p> \n <p>下图描述了Netty进行事件处理的流程。<code>Channel</code>是连接的通道，是ChannelEvent的产生者，而<code>ChannelPipeline</code>可以理解为ChannelHandler的集合。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0921/174032_18rb_190591.png\" alt=\"event driven in Netty\" /></p> \n <span id=\"OSC_h2_4\"></span> \n <h2>合：开启Netty源码之门</h2> \n <p>理解了Netty的事件驱动机制，我们现在可以来研究Netty的各个模块了。Netty的包结构如下：</p> \n <pre class=\"brush: ruby; auto-links: false;\">org\n└── jboss\n    └── netty\n        ├── bootstrap 配置并启动服务的类\n        ├── buffer 缓冲相关类，对NIO Buffer做了一些封装\n        ├── channel 核心部分，处理连接\n        ├── container 连接其他容器的代码\n        ├── example 使用示例\n        ├── handler 基于handler的扩展部分，实现协议编解码等附加功能\n        ├── logging 日志\n        └── util 工具类</pre> \n <p>在这里面，<code>channel</code>和<code>handler</code>两部分比较复杂。我们不妨与Netty官方的结构图对照一下，来了解其功能。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0921/225721_R0w2_190591.png\" alt=\"components in Netty\" /></p> \n <p>具体的解释可以看这里：<a href=\"http://netty.io/3.7/guide/#architecture\" rel=\"nofollow\">http://netty.io/3.7/guide/#architecture</a>。图中可以看到，除了之前说到的事件驱动机制之外，Netty的核心功能还包括两部分：</p> \n <ul> \n  <li><p>Zero-Copy-Capable Rich Byte Buffer</p> <p>零拷贝的Buffer。为什么叫零拷贝？因为在数据传输时，最终处理的数据会需要对单个传输层的报文，进行组合或者拆分。NIO原生的ByteBuffer要做到这件事，需要对ByteBuffer内容进行拷贝，产生新的ByteBuffer，而Netty通过提供Composite(组合)和Slice(切分)两种Buffer来实现零拷贝。这部分代码在<code>org.jboss.netty.buffer</code>包中。</p> </li> \n  <li><p>Universal Communication API</p> <p>统一的通讯API。因为Java的Old I/O和New I/O，使用了互不兼容的API，而Netty则提供了统一的API(<code>org.jboss.netty.channel.Channel</code>)来封装这两种I/O模型。这部分代码在<code>org.jboss.netty.channel</code>包中。</p> </li> \n </ul> \n <p>此外，Protocol Support功能通过handler机制实现。</p> \n <p>接下来的文章，我们会根据模块，详细的对Netty源码进行分析。</p> \n <p>最后附上Netty那点事系列文章/代码的Github地址:<a href=\"https://github.com/code4craft/netty-learning\" rel=\"nofollow\">https://github.com/code4craft/netty-learning</a></p> \n <p>参考资料：</p> \n <ul> \n  <li><p>Netty 3.7 User Guide <a href=\"http://netty.io/3.7/guide/\" rel=\"nofollow\">http://netty.io/3.7/guide/</a></p> </li> \n  <li><p>What is Netty? <a href=\"http://ayedo.github.io/netty/2013/06/19/what-is-netty.html\" rel=\"nofollow\">http://ayedo.github.io/netty/2013/06/19/what-is-netty.html</a></p> </li> \n </ul> \n <span id=\"OSC_h2_5\"></span> \n <h2>Netty那点事系列文章索引</h2> \n <ul> \n  <li><p><a href=\"http://my.oschina.net/flashsword/blog/162936\" rel=\"nofollow\">Netty那点事（一）概述</a></p> </li> \n  <li><p><a href=\"http://my.oschina.net/flashsword/blog/164237\" rel=\"nofollow\">Netty那点事（二）Netty中的buffer</a></p> </li> \n  <li><p><a href=\"http://my.oschina.net/flashsword/blog/178561\" rel=\"nofollow\">Netty那点事（三）层层分析Netty中的Channel(上)</a></p> </li> \n  <li><p>文章及代码地址：<a href=\"https://github.com/code4craft/netty-learning\" rel=\"nofollow\">https://github.com/code4craft/netty-learning</a></p> </li> \n </ul>\n</div>","description":"2013-09-21 23:22","name":"Netty那点事（一）概述","type":"text"},{"contents":"<h2>Netty那点事（二）Netty中的buffer</h2><div class=\"BlogContent\">\n <p>上一篇文章我们概要介绍了Netty的原理及结构，下面几篇文章我们开始对Netty的各个模块进行比较详细的分析。Netty的结构最底层是buffer机制，这部分也相对独立，我们就先从buffer讲起。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>What: buffer二三事</h2> \n <p>buffer中文名又叫缓冲区，按照维基百科的解释，是&quot;在数据传输时，在内存里开辟的一块临时保存数据的区域”。它其实是一种化同步为异步的机制，可以解决数据传输的速率不对等以及不稳定的问题。</p> \n <p>根据这个定义，我们可以知道涉及I/O(特别是I/O写)的地方，基本会有buffer的存在。就Java来说，我们非常熟悉的Old I/O–<code>InputStream</code>&amp;<code>OutputStream</code>系列API，基本都是在内部使用到了buffer。Java课程老师就教过，必须调用<code>OutputStream.flush()</code>，才能保证数据写入生效！</p> \n <p>而NIO中则直接将buffer这个概念封装成了对象，其中最常用的大概是ByteBuffer了。于是使用方式变为了：将数据写入Buffer，flip()一下，然后将数据读出来。于是，buffer的概念更加深入人心了！</p> \n <p>Netty中的buffer也不例外。不同的是，Netty的buffer专为网络通讯而生，所以它又叫ChannelBuffer(好吧其实没有什么因果关系…)。我们下面就来讲讲Netty中的buffer。当然，关于Netty，我们必须讲讲它的所谓&quot;Zero-Copy-Capable&quot;机制。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>When &amp; Where: TCP/IP协议与buffer</h2> \n <p>TCP/IP协议是目前的主流网络协议。它是一个多层协议，最下层是物理层，最上层是应用层(HTTP协议等)，而在Java开发中，一般只接触TCP以上，即传输层和应用层的内容。这也是Netty的主要应用场景。</p> \n <p>TCP报文有个比较大的特点，就是它传输的时候，会先把应用层的数据项拆开成字节，然后按照自己的传输需要，选择合适数量的字节进行传输。什么叫&quot;自己的传输需要”？首先TCP包有最大长度限制，那么太大的数据项肯定是要拆开的。其次因为TCP以及下层协议会附加一些协议头信息，如果数据项太小，那么可能报文大部分都是没有价值的头信息，这样传输是很不划算的。因此有了收集一定数量的小数据，并打包传输的Nagle算法(这个东东在HTTP协议里会很讨厌，Netty里可以用setOption(“tcpNoDelay”, true)关掉它)。</p> \n <p>这么说可能太学院派了一点，我们举个例子吧：</p> \n <p>发送时，我们这样分3次写入('|'表示两个buffer的分隔):</p> \n <pre class=\"brush: java; auto-links: false;\">+-----+-----+-----+\n   | ABC | DEF | GHI |\n   +-----+-----+-----+</pre> \n <p>接收时，可能变成了这样:</p> \n <pre class=\"brush: java; auto-links: false;\">+----+-------+---+---+\n   | AB | CDEFG | H | I |\n   +----+-------+---+---+</pre> \n <p>很好懂吧？可是，说了这么多，跟buffer有个什么关系呢？别急，我们来看下面一部分。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>Why: buffer中的分层思想</h2> \n <p>我们先回到之前的<code>messageReceived</code>方法：</p> \n <pre class=\"brush: java; auto-links: false;\">public void messageReceived(\n        ChannelHandlerContext ctx, MessageEvent e) {\n    // Send back the received message to the remote peer.\n    transferredBytes.addAndGet(((ChannelBuffer) e.getMessage()).readableBytes());\n    e.getChannel().write(e.getMessage());\n}</pre> \n <p>这里<code>MessageEvent.getMessage()</code>默认的返回值是一个<code>ChannelBuffer</code>。我们知道，业务中需要的&quot;Message”，其实是一条应用层级别的完整消息，而一般的buffer工作在传输层，与&quot;Message&quot;是不能对应上的。那么这个ChannelBuffer是什么呢？</p> \n <p>来一个官方给的图，我想这个答案就很明显了：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0925/225747_kDAk_190591.png\" alt=\"virtual buffer in Netty\" /></p> \n <p>这里可以看到，TCP层HTTP报文被分成了两个ChannelBuffer，这两个Buffer对我们上层的逻辑(HTTP处理)是没有意义的。但是两个ChannelBuffer被组合起来，就成为了一个有意义的HTTP报文，这个报文对应的ChannelBuffer，才是能称之为&quot;Message&quot;的东西。这里用到了一个词&quot;Virtual Buffer”，也就是所谓的&quot;Zero-Copy-Capable Byte Buffer&quot;了。顿时觉得豁然开朗了有没有！</p> \n <p>我这里总结一下，<strong>如果说NIO的Buffer和Netty的ChannelBuffer最大的区别的话，就是前者仅仅是传输上的Buffer，而后者其实是传输Buffer和抽象后的逻辑Buffer的结合。</strong>延伸开来说，NIO仅仅是一个网络传输框架，而Netty是一个网络应用框架，包括网络以及应用的分层结构。</p> \n <p>当然，在Netty里，默认使用<code>ChannelBuffer</code>表示&quot;Message”，不失为一个比较实用的方法，但是<code>MessageEvent.getMessage()</code>是可以存放一个POJO的，这样子抽象程度又高了一些，这个我们在以后讲到<code>ChannelPipeline</code>的时候会说到。</p> \n <span id=\"OSC_h2_4\"></span> \n <h2>How: Netty中的ChannelBuffer及实现</h2> \n <p>好了，终于来到了代码实现部分。之所以啰嗦了这么多，因为我觉得，关于&quot;Zero-Copy-Capable Rich Byte Buffer”，理解为什么需要它，比理解它是怎么实现的，可能要更重要一点。</p> \n <p>我想可能很多朋友跟我一样，喜欢&quot;顺藤摸瓜&quot;式读代码–找到一个入口，然后顺着查看它的调用，直到理解清楚。很幸运，<code>ChannelBuffers</code>(注意有s!)就是这样一根&quot;藤”，它是所有ChannelBuffer实现类的入口，它提供了很多静态的工具方法来创建不同的Buffer，靠“顺藤摸瓜”式读代码方式，大致能把各种ChannelBuffer的实现类摸个遍。先列一下ChannelBuffer相关类图。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0925/081551_v8pK_190591.png\" alt=\"channel buffer in Netty\" /></p> \n <p>此外还有<code>WrappedChannelBuffer</code>系列也是继承自<code>AbstractChannelBuffer</code>，图放到了后面。</p> \n <span id=\"OSC_h3_5\"></span> \n <h3>ChannelBuffer中的readerIndex和writerIndex</h3> \n <p>开始以为Netty的ChannelBuffer是对NIO ByteBuffer的一个封装，其实不是的，<strong>它是把ByteBuffer重新实现了一遍</strong>。</p> \n <p>以最常用的<code>HeapChannelBuffer</code>为例，其底层也是一个byte[]，与ByteBuffer不同的是，它是可以同时进行读和写的，而不需要使用flip()进行读写切换。ChannelBuffer读写的核心代码在<code>AbstactChannelBuffer</code>里，这里通过readerIndex和writerIndex两个整数，分别指向当前读的位置和当前写的位置，并且，readerIndex总是小于writerIndex的。贴两段代码，让大家能看的更明白一点：</p> \n <pre class=\"brush: java; auto-links: false;\">public void writeByte(int value) {\n    setByte(writerIndex ++, value);\n}\n\npublic byte readByte() {\n    if (readerIndex == writerIndex) {\n        throw new IndexOutOfBoundsException(&quot;Readable byte limit exceeded: &quot;\n                + readerIndex);\n    }\n    return getByte(readerIndex ++);\n}\n\npublic int writableBytes() {\n    return capacity() - writerIndex;\n}\n\npublic int readableBytes() {\n    return writerIndex - readerIndex;\n}</pre> \n <p>我倒是觉得这样的方式非常自然，比单指针与flip()要更加好理解一些。AbstactChannelBuffer还有两个相应的mark指针<code>markedReaderIndex</code>和<code>markedWriterIndex</code>，跟NIO的原理是一样的，这里不再赘述了。</p> \n <span id=\"OSC_h3_6\"></span> \n <h3>字节序Endianness与HeapChannelBuffer</h3> \n <p>在创建Buffer时，我们注意到了这样一个方法：<code>public static ChannelBuffer buffer(ByteOrder endianness, int capacity);</code>，其中<code>ByteOrder</code>是什么意思呢？</p> \n <p>这里有个很基础的概念：字节序(ByteOrder/Endianness)。它规定了多余一个字节的数字(int啊long什么的)，如何在内存中表示。BIG_ENDIAN(大端序)表示高位在前，整型数<code>12</code>会被存储为<code>0 0 0 12</code>四字节，而LITTLE_ENDIAN则正好相反。可能搞C/C++的程序员对这个会比较熟悉，而Javaer则比较陌生一点，因为Java已经把内存给管理好了。但是在网络编程方面，根据协议的不同，不同的字节序也可能会被用到。目前大部分协议还是采用大端序，可参考<a href=\"http://tools.ietf.org/html/rfc1700\" rel=\"nofollow\">RFC1700</a>。</p> \n <p>了解了这些知识，我们也很容易就知道为什么会有<code>BigEndianHeapChannelBuffer</code>和<code>LittleEndianHeapChannelBuffer</code>了！</p> \n <span id=\"OSC_h3_7\"></span> \n <h3>DynamicChannelBuffer</h3> \n <p>DynamicChannelBuffer是一个很方便的Buffer，之所以叫Dynamic是因为它的长度会根据内容的长度来扩充，你可以像使用ArrayList一样，无须关心其容量。实现自动扩容的核心在于<code>ensureWritableBytes</code>方法，算法很简单：在写入前做容量检查，容量不够时，新建一个容量x2的buffer，跟ArrayList的扩容是相同的。贴一段代码吧(为了代码易懂，这里我删掉了一些边界检查，只保留主逻辑)：</p> \n <pre class=\"brush: java; auto-links: false;\">public void writeByte(int value) {\n    ensureWritableBytes(1);\n    super.writeByte(value);\n}\n\npublic void ensureWritableBytes(int minWritableBytes) {\n    if (minWritableBytes &lt;= writableBytes()) {\n        return;\n    }\n\n    int newCapacity = capacity();\n    int minNewCapacity = writerIndex() + minWritableBytes;\n    while (newCapacity &lt; minNewCapacity) {\n        newCapacity &lt;&lt;= 1;\n    }\n\n    ChannelBuffer newBuffer = factory().getBuffer(order(), newCapacity);\n    newBuffer.writeBytes(buffer, 0, writerIndex());\n    buffer = newBuffer;\n}</pre> \n <span id=\"OSC_h3_8\"></span> \n <h3>CompositeChannelBuffer</h3> \n <p><code>CompositeChannelBuffer</code>是由多个ChannelBuffer组合而成的，可以看做一个整体进行读写。这里有一个技巧：CompositeChannelBuffer并不会开辟新的内存并直接复制所有ChannelBuffer内容，而是直接保存了所有ChannelBuffer的引用，并在子ChannelBuffer里进行读写，从而实现了&quot;Zero-Copy-Capable&quot;了。来段简略版的代码吧：</p> \n <pre class=\"brush: java; auto-links: false;\">public class CompositeChannelBuffer{\n\n    //components保存所有内部ChannelBuffer\n    private ChannelBuffer[] components;\n    //indices记录在整个CompositeChannelBuffer中，每个components的起始位置\n    private int[] indices;\n    //缓存上一次读写的componentId\n    private int lastAccessedComponentId;\n\n    public byte getByte(int index) {\n        //通过indices中记录的位置索引到对应第几个子Buffer\n        int componentId = componentId(index);\n        return components[componentId].getByte(index - indices[componentId]);\n    }\n\n    public void setByte(int index, int value) {\n        int componentId = componentId(index);\n        components[componentId].setByte(index - indices[componentId], value);\n    }\n\n}</pre> \n <p>查找componentId的算法再次不作介绍了，大家自己实现起来也不会太难。值得一提的是，基于ChannelBuffer连续读写的特性，使用了顺序查找(而不是二分查找)，并且用<code>lastAccessedComponentId</code>来进行缓存。</p> \n <span id=\"OSC_h3_9\"></span> \n <h3>ByteBufferBackedChannelBuffer</h3> \n <p>前面说ChannelBuffer是自己的实现的，其实只说对了一半。<code>ByteBufferBackedChannelBuffer</code>就是封装了NIO ByteBuffer的类，用于实现堆外内存的Buffer(使用NIO的<code>DirectByteBuffer</code>)。当然，其实它也可以放其他的ByteBuffer的实现类。代码实现就不说了，也没啥可说的。</p> \n <span id=\"OSC_h3_10\"></span> \n <h3>WrappedChannelBuffer</h3> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0925/074748_oSkl_190591.png\" alt=\"virtual buffer in Netty\" /></p> \n <p><code>WrappedChannelBuffer</code>都是几个对已有ChannelBuffer进行包装，完成特定功能的类。代码不贴了，实现都比较简单，列一下功能吧。</p> \n <table> \n  <tbody> \n   <tr> \n    <td>类名</td> \n    <td>入口</td> \n    <td>功能</td> \n   </tr> \n   <tr> \n    <td>SlicedChannelBuffer</td> \n    <td>ChannelBuffer.slice()<br /> ChannelBuffer.slice(int,int)</td> \n    <td>某个ChannelBuffer的一部分</td> \n   </tr> \n   <tr> \n    <td>TruncatedChannelBuffer</td> \n    <td>ChannelBuffer.slice()<br /> ChannelBuffer.slice(int,int)</td> \n    <td>某个ChannelBuffer的一部分， 可以理解为其实位置为0的SlicedChannelBuffer</td> \n   </tr> \n   <tr> \n    <td>DuplicatedChannelBuffer</td> \n    <td>ChannelBuffer.duplicate()</td> \n    <td>与某个ChannelBuffer使用同样的存储， 区别是有自己的index</td> \n   </tr> \n   <tr> \n    <td>ReadOnlyChannelBuffer</td> \n    <td>ChannelBuffers <br />.unmodifiableBuffer(ChannelBuffer)</td> \n    <td>只读，你懂的</td> \n   </tr> \n  </tbody> \n </table> \n <p>可以看到，关于实现方面，Netty 3.7的buffer相关内容还是比较简单的，也没有太多费脑细胞的地方。</p> \n <p>而Netty 4.0之后就不同了。4.0，ChannelBuffer改名ByteBuf，成了单独项目buffer，并且为了性能优化，加入了BufferPool之类的机制，已经变得比较复杂了(本质倒没怎么变)。性能优化是个很复杂的事情，研究源码时，建议先避开这些东西，除非你对算法情有独钟。举个例子，Netty4.0里为了优化，将Map换成了Java 8里6000行的<a href=\"https://github.com/netty/netty/blob/master/common/src/main/java/io/netty/util/internal/chmv8/ConcurrentHashMapV8.java\" rel=\"nofollow\">ConcurrentHashMapV8</a>，你们感受一下…</p> \n <p>下篇文章我们开始讲Channel。</p> \n <p>参考资料：</p> \n <ul> \n  <li>TCP/IP协议 <a href=\"http://zh.wikipedia.org/zh-cn/TCP/IP%E5%8D%8F%E8%AE%AE\" rel=\"nofollow\">http://zh.wikipedia.org/zh-cn/TCP/IP%E5%8D%8F%E8%AE%AE</a></li> \n  <li>Data_buffer <a href=\"http://en.wikipedia.org/wiki/Data_buffer\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Data_buffer</a></li> \n  <li>Endianness <a href=\"http://en.wikipedia.org/wiki/Endianness\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Endianness</a></li> \n </ul> \n <span id=\"OSC_h2_11\"></span> \n <h2>Netty那点事系列文章索引</h2> \n <ul> \n  <li><p><a href=\"http://my.oschina.net/flashsword/blog/162936\" rel=\"nofollow\">Netty那点事（一）概述</a></p> </li> \n  <li><p><a href=\"http://my.oschina.net/flashsword/blog/164237\" rel=\"nofollow\">Netty那点事（二）Netty中的buffer</a></p> </li> \n  <li><p><a href=\"http://my.oschina.net/flashsword/blog/178561\" rel=\"nofollow\">Netty那点事（三）层层分析Netty中的Channel(上)</a></p> </li> \n  <li><p>文章及代码地址：<a href=\"https://github.com/code4craft/netty-learning\" rel=\"nofollow\">https://github.com/code4craft/netty-learning</a></p> </li> \n </ul>\n</div>","description":"2013-09-25 23:28","name":"Netty那点事（二）Netty中的buffer","type":"text"},{"contents":"<h2>【netty实战】使用netty构建一个socks proxy</h2><div class=\"BlogContent\">\n <p>最近在做的项目，需要自己搭建一个socks代理。netty4.0附带了一个socks代理的样例，但是3.x就没有这个东西了，碰巧使用的又是3.7，就只能自己摸索并实现一遍，也算是对netty和socks协议的一个熟悉。socks代理涉及到协议解析、server、client等功能，是一个比较复杂的网络程序，对于学习netty的使用也是非常好的例子。</p> \n <p>socks是在传输层之上的一层协议，主要功能是提供代理认证等功能。socks协议虽然是应用层协议(在TCP/IP4层协议栈里)，本身可以理解为一个信道，可以传输任何TCP/UDP内容。例如著名的科学上网软件就是基于socks协议，对通信内容进行加密实现的。</p> \n <p>TCP/IP协议栈的结构中，下层协议总会在上层协议内容之前加上自己的头。而socks协议稍微不同，其实它对比TCP协议，仅仅是多了验证部分，验证之后，完全是使用TCP来进行传输，而没有socks报文头。socks协议的具体内容可以参考<a href=\"http://www.ietf.org/rfc/rfc1928.txt\" rel=\"nofollow\">rfc1928</a>。这一点来说，其实将socks理解成与其他应用层协议平级也没什么问题。</p> \n <p>一个最基本的socks连接流程是这样的： <br /><img src=\"http://static.oschina.net/uploads/space/2013/1016/174446_CK7D_190591.png\" alt=\"socks\" /></p> \n <p>那么我们开始netty之旅吧。</p> \n <p>首先我们需要建立一个server：</p> \n <pre class=\"brush: java; auto-links: false;\">public void run() {\n\n    // 新建线程池\n    Executor executor = Executors.newCachedThreadPool();\n    Executor executorWorker = Executors.newCachedThreadPool();\n    ServerBootstrap sb = new ServerBootstrap(\n            new NioServerSocketChannelFactory(executor, executorWorker));\n\n    // 初始化代理部分使用的client\n    ClientSocketChannelFactory cf =\n            new NioClientSocketChannelFactory(executor, executorWorker);\n\n    //设置处理逻辑\n    sb.setPipelineFactory(\n            new SocksProxyPipelineFactory(cf));\n\n    // Start up the server.\n    sb.bind(new InetSocketAddress(1080));\n}</pre> \n <p>如你所见，主要的处理逻辑以SocksProxyPipelineFactory的形式提供。SocksProxyPipelineFactory的代码包括几部分：</p> \n <pre class=\"brush: java; auto-links: false;\">public class SocksProxyPipelineFactory implements ChannelPipelineFactory {\n\n    private final ClientSocketChannelFactory cf;\n\n    public SocksProxyPipelineFactory(ClientSocketChannelFactory cf) {\n        this.cf = cf;\n    }\n\n    @Override\n    public ChannelPipeline getPipeline() throws Exception {\n        ChannelPipeline pipeline = Channels.pipeline();\n        pipeline.addLast(SocksInitRequestDecoder.getName(),new SocksInitRequestDecoder());\n        pipeline.addLast(SocksMessageEncoder.getName(),new SocksMessageEncoder());\n        pipeline.addLast(SocksServerHandler.getName(),new SocksServerHandler(cf));\n        return pipeline;\n    }\n}</pre> \n <p>这里要详细解释一下几个handler的作用：</p> \n <p><code>ChannelUpstreamHandler</code>用于接收之后的处理，而<code>ChannelDownstreamHandler</code>则相反，用于写入数据之后的处理。这两个都可以附加到<code>ChannelPipeline</code>中。偷个懒，直接附上netty的ChannelPipeline中的一段很有爱的javadoc：</p> \n <pre class=\"brush: java; auto-links: false;\">I/O Request\n                                    via {@link Channel} or\n                                {@link ChannelHandlerContext}\n                                          |\n +----------------------------------------+---------------+\n |                  ChannelPipeline       |               |\n |                                       \\|/              |\n |  +----------------------+  +-----------+------------+  |\n |  | Upstream Handler  N  |  | Downstream Handler  1  |  |\n |  +----------+-----------+  +-----------+------------+  |\n |            /|\\                         |               |\n |             |                         \\|/              |\n |  +----------+-----------+  +-----------+------------+  |\n |  | Upstream Handler N-1 |  | Downstream Handler  2  |  |\n |  +----------+-----------+  +-----------+------------+  |\n |            /|\\                         .               |\n |             .                          .               |\n |     [ sendUpstream() ]        [ sendDownstream() ]     |\n |     [ + INBOUND data ]        [ + OUTBOUND data  ]     |\n |             .                          .               |\n |             .                         \\|/              |\n |  +----------+-----------+  +-----------+------------+  |\n |  | Upstream Handler  2  |  | Downstream Handler M-1 |  |\n |  +----------+-----------+  +-----------+------------+  |\n |            /|\\                         |               |\n |             |                         \\|/              |\n |  +----------+-----------+  +-----------+------------+  |\n |  | Upstream Handler  1  |  | Downstream Handler  M  |  |\n |  +----------+-----------+  +-----------+------------+  |\n |            /|\\                         |               |\n +-------------+--------------------------+---------------+\n               |                         \\|/\n +-------------+--------------------------+---------------+\n |             |                          |               |\n |     [ Socket.read() ]          [ Socket.write() ]      |\n |                                                        |\n |  Netty Internal I/O Threads (Transport Implementation) |\n +--------------------------------------------------------+</pre> \n <p><code>SocksInitRequestDecoder</code>用于对socks的请求进行解码。你可能会说，为什么没有SocksCmdRequest的解码？别急，netty的handler是可以动态添加的，这里我们先解码一个初始化的请求。SocksInitRequestDecoder是一个<code>ChannelUpstreamHandler</code>，即接收流的处理器。</p> \n <p><code>SocksMessageEncoder</code>是一个<code>ChannelDownstreamHandler</code>，即输出时的编码器，有了它，我们可以很开心的在channel.write()里直接传入一个对象，而无需自己去写buffer了。</p> \n <p><code>SocksServerHandler</code>是处理的重头。这里会根据请求的不同类型，做不同的处理。</p> \n <pre class=\"brush: java; auto-links: false;\">public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {\n    SocksRequest socksRequest = (SocksRequest) e.getMessage();\n    switch (socksRequest.getSocksRequestType()) {\n    case INIT:\n        //添加cmd解码器\n        ctx.getPipeline().addFirst(SocksCmdRequestDecoder.getName(), new SocksCmdRequestDecoder());\n        //简单起见，无需认证\n        ctx.getChannel().write(new SocksInitResponse(SocksMessage.AuthScheme.NO_AUTH));\n        break;\n    case AUTH:\n        ctx.getPipeline().addFirst(SocksCmdRequestDecoder.getName(), new SocksCmdRequestDecoder());\n        //直接成功\n        ctx.getChannel().write(new SocksAuthResponse(SocksMessage.AuthStatus.SUCCESS));\n        break;\n    case CMD:\n        SocksCmdRequest req = (SocksCmdRequest) socksRequest;\n        if (req.getCmdType() == SocksMessage.CmdType.CONNECT) {\n            //添加处理连接的handler\n            ctx.getPipeline().addLast(SocksServerConnectHandler.getName(), new SocksServerConnectHandler(cf));\n            ctx.getPipeline().remove(this);\n        } else {\n            ctx.getChannel().close();\n        }\n        break;\n    case UNKNOWN:\n        break;\n    }\n    super.messageReceived(ctx, e);\n}</pre> \n <p>前面两种INIT和AUTH就不做赘述了，后面当CMD为Connect时，添加一个处理连接的<code>SocksServerConnectHandler</code>，它会起到client与外部server的桥梁作用。</p> \n <p>这里我们先实现一个纯转发的handler-<code>OutboundHandler</code>:</p> \n <pre class=\"brush: java; auto-links: false;\">private class OutboundHandler extends SimpleChannelUpstreamHandler {\n\n    private final Channel inboundChannel;\n\n    OutboundHandler(Channel inboundChannel) {\n        this.inboundChannel = inboundChannel;\n    }\n\n    @Override\n    public void messageReceived(ChannelHandlerContext ctx, final MessageEvent e) throws Exception {\n        final ChannelBuffer msg = (ChannelBuffer) e.getMessage();\n        synchronized (trafficLock) {\n            inboundChannel.write(msg);\n\n        }\n    }\n}</pre> \n <p>它会把收到的内容，写入到<code>inboundChannel</code>中，其他转发的作用。最后就是我们的<code>SocksServerConnectHandler</code>了:</p> \n <pre class=\"brush: java; auto-links: false;\">public class SocksServerConnectHandler extends SimpleChannelUpstreamHandler {\n\n    private final ClientSocketChannelFactory cf;\n\n    private volatile Channel outboundChannel;\n\n    final Object trafficLock = new Object();\n\n    public SocksServerConnectHandler(ClientSocketChannelFactory cf) {\n        this.cf = cf;\n    }\n\n    @Override\n    public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {\n        final SocksCmdRequest socksCmdRequest = (SocksCmdRequest) e.getMessage();\n        final Channel inboundChannel = e.getChannel();\n        inboundChannel.setReadable(false);\n\n        // Start the connection attempt.\n        final ClientBootstrap cb = new ClientBootstrap(cf);\n        cb.setOption(&quot;keepAlive&quot;, true);\n        cb.setOption(&quot;tcpNoDelay&quot;, true);\n        cb.setPipelineFactory(new ChannelPipelineFactory() {\n            @Override\n            public ChannelPipeline getPipeline() throws Exception {\n                ChannelPipeline pipeline = Channels.pipeline();\n                // 外部server数据转发到client\n                pipeline.addLast(&quot;outboundChannel&quot;, new OutboundHandler(inboundChannel, &quot;out&quot;));\n                return pipeline;\n            }\n        });\n\n        ChannelFuture f = cb.connect(new InetSocketAddress(socksCmdRequest.getHost(), socksCmdRequest.getPort()));\n\n        outboundChannel = f.getChannel();\n        ctx.getPipeline().remove(getName());\n        f.addListener(new ChannelFutureListener() {\n            public void operationComplete(ChannelFuture future) throws Exception {\n                if (future.isSuccess()) {\n                    // client数据转发到外部server\n                    inboundChannel.getPipeline().addLast(&quot;inboundChannel&quot;, new OutboundHandler(outboundChannel, &quot;in&quot;));\n                    inboundChannel.write(new SocksCmdResponse(SocksMessage.CmdStatus.SUCCESS, socksCmdRequest\n                            .getAddressType()));\n                    inboundChannel.setReadable(true);\n                } else {\n                    inboundChannel.write(new SocksCmdResponse(SocksMessage.CmdStatus.FAILURE, socksCmdRequest\n                            .getAddressType()));\n                    inboundChannel.close();\n                }\n            }\n        });\n    }\n}</pre> \n <p>好了，完工！输入<code>curl --socks5 127.0.0.1:1080 http://www.oschina.net/</code>测试一下吧？但是测试时发现，怎么老是无法接收到响应？</p> \n <p>使用wiredshark抓包之后，发现对外请求完全正常，但是对客户端的响应，则完全没有http响应部分？</p> \n <p>一步步debug下去，才发现<code>SocksMessageEncoder</code>出了问题！</p> \n <pre class=\"brush: java; auto-links: false;\">@Override\nprotected Object encode(ChannelHandlerContext ctx, Channel channel, Object msg) throws Exception {\n    ChannelBuffer buffer = null;\n    if (msg instanceof SocksMessage) {\n        buffer = ChannelBuffers.buffer(DEFAULT_ENCODER_BUFFER_SIZE);\n        ((SocksMessage) msg).encodeAsByteBuf(buffer);\n    } \n    return buffer;\n}</pre> \n <p>这里只有SocksMessage才会被处理，其他的message全部被丢掉了！于是我们加上一行:</p> \n <pre class=\"brush: java; auto-links: false;\">@Override\nprotected Object encode(ChannelHandlerContext ctx, Channel channel, Object msg) throws Exception {\n    ChannelBuffer buffer = null;\n    if (msg instanceof SocksMessage) {\n        buffer = ChannelBuffers.buffer(DEFAULT_ENCODER_BUFFER_SIZE);\n        ((SocksMessage) msg).encodeAsByteBuf(buffer);\n    } else if (msg instanceof ChannelBuffer) {\n        //直接转发是ChannelBuffer类型\n        buffer = (ChannelBuffer) msg;\n    }\n    return buffer;\n}</pre> \n <p>至此，一个代理完成！点这里查看代码：<a href=\"https://github.com/code4craft/netty-learning/tree/master/learning-src/socksproxy\" rel=\"nofollow\">https://github.com/code4craft/netty-learning/tree/master/learning-src/socksproxy</a></p>\n</div>","description":"2013-10-16 17:48","name":"【netty实战】使用netty构建一个socks proxy","type":"text"},{"contents":"<h2>Netty那点事（三）Channel与Pipeline</h2><div class=\"BlogContent\">\n <p>Channel是理解和使用Netty的核心。Channel的涉及内容较多，这里我使用由浅入深的介绍方法。在这篇文章中，我们主要介绍Channel部分中Pipeline实现机制。为了避免枯燥，借用一下《盗梦空间》的“梦境”概念，希望大家喜欢。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>一层梦境：Channel实现概览</h2> \n <p>在Netty里，<code>Channel</code>是通讯的载体，而<code>ChannelHandler</code>负责Channel中的逻辑处理。</p> \n <p>那么<code>ChannelPipeline</code>是什么呢？我觉得可以理解为ChannelHandler的容器：一个Channel包含一个ChannelPipeline，所有ChannelHandler都会注册到ChannelPipeline中，并按顺序组织起来。</p> \n <p>在Netty中，<code>ChannelEvent</code>是数据或者状态的载体，例如传输的数据对应<code>MessageEvent</code>，状态的改变对应<code>ChannelStateEvent</code>。当对Channel进行操作时，会产生一个ChannelEvent，并发送到<code>ChannelPipeline</code>。ChannelPipeline会选择一个ChannelHandler进行处理。这个ChannelHandler处理之后，可能会产生新的ChannelEvent，并流转到下一个ChannelHandler。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/0921/174032_18rb_190591.png\" alt=\"channel pipeline\" /></p> \n <p>例如，一个数据最开始是一个<code>MessageEvent</code>，它附带了一个未解码的原始二进制消息<code>ChannelBuffer</code>，然后某个Handler将其解码成了一个数据对象，并生成了一个新的<code>MessageEvent</code>，并传递给下一步进行处理。</p> \n <p>到了这里，可以看到，其实Channel的核心流程位于<code>ChannelPipeline</code>中。于是我们进入ChannelPipeline的深层梦境里，来看看它具体的实现。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二层梦境：ChannelPipeline的主流程</h2> \n <p>Netty的ChannelPipeline包含两条线路：Upstream和Downstream。Upstream对应上行，接收到的消息、被动的状态改变，都属于Upstream。Downstream则对应下行，发送的消息、主动的状态改变，都属于Downstream。<code>ChannelPipeline</code>接口包含了两个重要的方法:<code>sendUpstream(ChannelEvent e)</code>和<code>sendDownstream(ChannelEvent e)</code>，就分别对应了Upstream和Downstream。</p> \n <p>对应的，ChannelPipeline里包含的ChannelHandler也包含两类：<code>ChannelUpstreamHandler</code>和<code>ChannelDownstreamHandler</code>。每条线路的Handler是互相独立的。它们都很简单的只包含一个方法：<code>ChannelUpstreamHandler.handleUpstream</code>和<code>ChannelDownstreamHandler.handleDownstream</code>。</p> \n <p>Netty官方的javadoc里有一张图(<code>ChannelPipeline</code>接口里)，非常形象的说明了这个机制(我对原图进行了一点修改，加上了<code>ChannelSink</code>，因为我觉得这部分对理解代码流程会有些帮助)：</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1109/075339_Kjw6_190591.png\" alt=\"channel pipeline\" /></p> \n <p>什么叫<code>ChannelSink</code>呢？ChannelSink包含一个重要方法<code>ChannelSink.eventSunk</code>，可以接受任意ChannelEvent。“sink&quot;的意思是&quot;下沉”，那么&quot;ChannelSink&quot;好像可以理解为&quot;Channel下沉的地方”？实际上，它的作用确实是这样，也可以换个说法：“处于末尾的万能Handler”。最初读到这里，也有些困惑，这么理解之后，就感觉简单许多。<strong>只有Downstream包含<code>ChannelSink</code></strong>，这里会做一些建立连接、绑定端口等重要操作。为什么UploadStream没有ChannelSink呢？我只能认为，一方面，不符合&quot;sink&quot;的意义，另一方面，也没有什么处理好做的吧！</p> \n <p>这里有个值得注意的地方：在一条“流”里，一个<code>ChannelEvent</code>并不会主动的&quot;流&quot;经所有的Handler，而是由<strong>上一个Handler显式的调用<code>ChannelPipeline.sendUp(Down)stream</code>产生，并交给下一个Handler处理</strong>。也就是说，每个Handler接收到一个ChannelEvent，并处理结束后，如果需要继续处理，那么它需要调用<code>sendUp(Down)stream</code>新发起一个事件。如果它不再发起事件，那么处理就到此结束，即使它后面仍然有Handler没有执行。这个机制可以保证最大的灵活性，当然对Handler的先后顺序也有了更严格的要求。</p> \n <p>顺便说一句，在Netty 3.x里，这个机制会导致大量的ChannelEvent对象创建，因此Netty 4.x版本对此进行了改进。twitter的<a href=\"https://github.com/twitter/finagle\" rel=\"nofollow\">finagle</a>框架实践中，就提到从Netty 3.x升级到Netty 4.x，可以大大降低GC开销。有兴趣的可以看看这篇文章：<a href=\"https://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead\" rel=\"nofollow\">https://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead</a></p> \n <p>下面我们从代码层面来对这里面发生的事情进行深入分析，这部分涉及到一些细节，需要打开项目源码，对照来看，会比较有收获。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>三层梦境：深入ChannelPipeline内部</h2> \n <span id=\"OSC_h3_4\"></span> \n <h3>DefaultChannelPipeline的内部结构</h3> \n <p><code>ChannelPipeline</code>的主要的实现代码在<code>DefaultChannelPipeline</code>类里。列一下DefaultChannelPipeline的主要字段：</p> \n <pre class=\"brush: java; auto-links: false;\">public class DefaultChannelPipeline implements ChannelPipeline {\n\n        private volatile Channel channel;\n        private volatile ChannelSink sink;\n        private volatile DefaultChannelHandlerContext head;\n        private volatile DefaultChannelHandlerContext tail;\n        private final Map&lt;String, DefaultChannelHandlerContext&gt; name2ctx =\n            new HashMap&lt;String, DefaultChannelHandlerContext&gt;(4);\n    }</pre> \n <p>这里需要介绍一下<code>ChannelHandlerContext</code>这个接口。顾名思义，ChannelHandlerContext保存了Netty与Handler相关的的上下文信息。而咱们这里的<code>DefaultChannelHandlerContext</code>，则是对<code>ChannelHandler</code>的一个包装。一个<code>DefaultChannelHandlerContext</code>内部，除了包含一个<code>ChannelHandler</code>，还保存了&quot;next&quot;和&quot;prev&quot;两个指针，从而形成一个双向链表。</p> \n <p>因此，在<code>DefaultChannelPipeline</code>中，我们看到的是对<code>DefaultChannelHandlerContext</code>的引用，而不是对<code>ChannelHandler</code>的直接引用。这里包含&quot;head&quot;和&quot;tail&quot;两个引用，分别指向链表的头和尾。而name2ctx则是一个按名字索引DefaultChannelHandlerContext用户的一个map，主要在按照名称删除或者添加ChannelHandler时使用。</p> \n <span id=\"OSC_h3_5\"></span> \n <h3>sendUpstream和sendDownstream</h3> \n <p>前面提到了，<code>ChannelPipeline</code>接口的两个重要的方法：<code>sendUpstream(ChannelEvent e)</code>和<code>sendDownstream(ChannelEvent e)</code>。<strong>所有事件</strong>的发起都是基于这两个方法进行的。<code>Channels</code>类有一系列<code>fireChannelBound</code>之类的<code>fireXXXX</code>方法，其实都是对这两个方法的facade包装。</p> \n <p>下面来看一下这两个方法的实现(对代码做了一些简化，保留主逻辑)：</p> \n <pre class=\"brush: java; auto-links: false;\">public void sendUpstream(ChannelEvent e) {\n        DefaultChannelHandlerContext head = getActualUpstreamContext(this.head);\n        head.getHandler().handleUpstream(head, e);\n    }\n\n    private DefaultChannelHandlerContext getActualUpstreamContext(DefaultChannelHandlerContext ctx) {\n        DefaultChannelHandlerContext realCtx = ctx;\n        while (!realCtx.canHandleUpstream()) {\n            realCtx = realCtx.next;\n            if (realCtx == null) {\n                return null;\n            }\n        }\n        return realCtx;\n    }</pre> \n <p>这里最终调用了<code>ChannelUpstreamHandler.handleUpstream</code>来处理这个ChannelEvent。有意思的是，这里我们看不到任何&quot;将Handler向后移一位&quot;的操作，但是我们总不能每次都用同一个Handler来进行处理啊？实际上，我们更为常用的是<code>ChannelHandlerContext.handleUpstream</code>方法(实现是<code>DefaultChannelHandlerContext.sendUpstream</code>方法)：</p> \n <pre class=\"brush: java; auto-links: false;\">public void sendUpstream(ChannelEvent e) {\n        DefaultChannelHandlerContext next = getActualUpstreamContext(this.next);\n        DefaultChannelPipeline.this.sendUpstream(next, e);\n    }</pre> \n <p>可以看到，这里最终仍然调用了<code>ChannelPipeline.sendUpstream</code>方法，但是<strong>它会将Handler指针后移</strong>。</p> \n <p>我们接下来看看<code>DefaultChannelHandlerContext.sendDownstream</code>:</p> \n <pre class=\"brush: java; auto-links: false;\">public void sendDownstream(ChannelEvent e) {\n        DefaultChannelHandlerContext prev = getActualDownstreamContext(this.prev);\n        if (prev == null) {\n            try {\n                getSink().eventSunk(DefaultChannelPipeline.this, e);\n            } catch (Throwable t) {\n                notifyHandlerException(e, t);\n            }\n        } else {\n            DefaultChannelPipeline.this.sendDownstream(prev, e);\n        }\n    }</pre> \n <p>与sendUpstream好像不大相同哦？这里有两点：一是到达末尾时，就如梦境二所说，会调用ChannelSink进行处理；二是这里指针是<strong>往前移</strong>的，所以我们知道了：</p> \n <p><strong>UpstreamHandler是从前往后执行的，DownstreamHandler是从后往前执行的。</strong>在ChannelPipeline里添加时需要注意顺序了！</p> \n <p>DefaultChannelPipeline里还有些机制，像添加/删除/替换Handler，以及<code>ChannelPipelineFactory</code>等，比较好理解，就不细说了。</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>回到现实：Pipeline解决的问题</h2> \n <p>好了，深入分析完代码，有点头晕了，我们回到最开始的地方，来想一想，Netty的Pipeline机制解决了什么问题？</p> \n <p>我认为至少有两点：</p> \n <p>一是提供了ChannelHandler的编程模型，基于ChannelHandler开发业务逻辑，基本不需要关心网络通讯方面的事情，专注于编码/解码/逻辑处理就可以了。Handler也是比较方便的开发模式，在很多框架中都有用到。</p> \n <p>二是实现了所谓的&quot;Universal Asynchronous API”。这也是Netty官方标榜的一个功能。用过OIO和NIO的都知道，这两套API风格相差极大，要从一个迁移到另一个成本是很大的。即使是NIO，异步和同步编程差距也很大。而Netty屏蔽了OIO和NIO的API差异，通过Channel提供对外接口，并通过ChannelPipeline将其连接起来，因此替换起来非常简单。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1124/001528_TBb5_190591.jpg\" alt=\"universal API\" /></p> \n <p>理清了ChannelPipeline的主流程，我们对Channel部分的大致结构算是弄清楚了。可是到了这里，我们依然对一个连接具体怎么处理没有什么概念，下篇文章，我们会分析一下，在Netty中，捷径如何处理连接的建立、数据的传输这些事情。</p> \n <p>PS: Pipeline这部分拖了两个月，终于写完了。中间写的实在缓慢，写个高质量(至少是自认为吧！)的文章不容易，但是仍不忍心这部分就此烂尾。中间参考了一些优秀的文章，还自己使用netty开发了一些应用。以后这类文章，还是要集中时间来写完好了。</p> \n <p>参考资料：</p> \n <ul> \n  <li>Sink <a href=\"http://en.wikipedia.org/wiki/Sink_(computing)\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Sink_(computing)</a></li> \n </ul>\n</div>","description":"2013-11-24 00:39","name":"Netty那点事（三）Channel与Pipeline","type":"text"},{"contents":"<h2>Netty那点事（四）Netty与Reactor模式</h2><div class=\"BlogContent\">\n <p><img src=\"http://static.oschina.net/uploads/space/2014/0208/164000_EQQb_190591.jpg\" alt=\"Reactors\" /></p> \n <span id=\"OSC_h2_1\"></span> \n <h2>一：Netty、NIO、多线程？</h2> \n <p>时隔很久终于又更新了！之前一直迟迟未动也是因为积累不够，后面比较难下手。过年期间<a href=\"http://weibo.com/lilinfeng\" rel=\"nofollow\">@李林锋hw</a>发布了一个Netty5.0架构剖析和源码解读 <a href=\"http://vdisk.weibo.com/s/C9LV9iVqH13rW/1391437855\" rel=\"nofollow\">http://vdisk.weibo.com/s/C9LV9iVqH13rW/1391437855</a>，看完也是收获不少。前面的文章我们分析了Netty的结构，这次咱们来分析最错综复杂的一部分-Netty中的多线程以及NIO的应用。</p> \n <p>理清NIO与Netty的关系之前，我们必须先要来看看Reactor模式。Netty是一个典型的多线程的Reactor模式的使用，理解了这部分，在宏观上理解Netty的NIO及多线程部分就不会有什么困难了。</p> \n <p>本篇文章依然针对Netty 3.7，不过因为也看过一点Netty 5的源码，所以会有一点介绍。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>二：Reactor，反应堆还是核电站？</h2> \n <span id=\"OSC_h3_3\"></span> \n <h3>1、Reactor的由来</h3> \n <p>Reactor是一种广泛应用在服务器端开发的设计模式。Reactor中文大多译为“反应堆”，我当初接触这个概念的时候，就感觉很厉害，是不是它的原理就跟“核反应”差不多？后来才知道其实没有什么关系，从Reactor的兄弟“Proactor”（多译为前摄器）就能看得出来，这两个词的中文翻译其实都不是太好，不够形象。实际上，Reactor模式又有别名“Dispatcher”或者“Notifier”，我觉得这两个都更加能表明它的本质。</p> \n <p>那么，Reactor模式究竟是个什么东西呢？这要从事件驱动的开发方式说起。我们知道，对于应用服务器，一个主要规律就是，CPU的处理速度是要远远快于IO速度的，如果CPU为了IO操作（例如从Socket读取一段数据）而阻塞显然是不划算的。好一点的方法是分为多进程或者线程去进行处理，但是这样会带来一些进程切换的开销，试想一个进程一个数据读了500ms，期间进程切换到它3次，但是CPU却什么都不能干，就这么切换走了，是不是也不划算？</p> \n <p>这时先驱们找到了事件驱动，或者叫回调的方式，来完成这件事情。这种方式就是，应用业务向一个中间人注册一个回调（event handler），当IO就绪后，就这个中间人产生一个事件，并通知此handler进行处理。<em>这种回调的方式，也体现了“好莱坞原则”（Hollywood principle）-“Don't call us, we'll call you”，在我们熟悉的IoC中也有用到。看来软件开发真是互通的！</em></p> \n <p>好了，我们现在来看Reactor模式。在前面事件驱动的例子里有个问题：我们如何知道IO就绪这个事件，谁来充当这个中间人？Reactor模式的答案是：由一个不断等待和循环的单独进程（线程）来做这件事，它接受所有handler的注册，并负责先操作系统查询IO是否就绪，在就绪后就调用指定handler进行处理，这个角色的名字就叫做Reactor。</p> \n <span id=\"OSC_h3_4\"></span> \n <h3>2、Reactor与NIO</h3> \n <p>Java中的NIO可以很好的和Reactor模式结合。关于NIO中的Reactor模式，我想没有什么资料能比Doug Lea大神（不知道Doug Lea？看看JDK集合包和并发包的作者吧）在<a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" rel=\"nofollow\">《Scalable IO in Java》</a>解释的更简洁和全面了。NIO中Reactor的核心是<code>Selector</code>，我写了一个简单的Reactor示例，这里我贴一个核心的Reactor的循环（这种循环结构又叫做<code>EventLoop</code>），剩余代码在<a href=\"https://github.com/code4craft/netty-learning/tree/master/learning-src/src/main/java/us/codecraft/netty/reactor\" rel=\"nofollow\">learning-src</a>目录下。</p> \n <pre class=\"brush: java; auto-links: false;\">public void run() {\n        try {\n            while (!Thread.interrupted()) {\n                selector.select();\n                Set selected = selector.selectedKeys();\n                Iterator it = selected.iterator();\n                while (it.hasNext())\n                    dispatch((SelectionKey) (it.next()));\n                selected.clear();\n            }\n        } catch (IOException ex) { /* ... */\n        }\n    }</pre> \n <span id=\"OSC_h3_5\"></span> \n <h3>3、与Reactor相关的其他概念</h3> \n <p>前面提到了Proactor模式，这又是什么呢？简单来说，Reactor模式里，操作系统只负责通知IO就绪，具体的IO操作（例如读写）仍然是要在业务进程里阻塞的去做的，而Proactor模式则更进一步，由操作系统将IO操作执行好（例如读取，会将数据直接读到内存buffer中），而handler只负责处理自己的逻辑，真正做到了IO与程序处理异步执行。所以我们一般又说Reactor是同步IO，Proactor是异步IO。</p> \n <p>关于阻塞和非阻塞、异步和非异步，以及UNIX底层的机制，大家可以看看这篇文章<a href=\"http://blog.csdn.net/historyasamirror/article/details/5778378\" rel=\"nofollow\">IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇）</a>，以及陶辉（《深入理解nginx》的作者）<a href=\"http://blog.csdn.net/russell_tao/article/details/17452997\" rel=\"nofollow\">《高性能网络编程》</a>的系列。</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>三：由Reactor出发来理解Netty</h2> \n <span id=\"OSC_h3_7\"></span> \n <h3>1、多线程下的Reactor</h3> \n <p>讲了一堆Reactor，我们回到Netty。在《Scalable IO in Java》中讲到了一种多线程下的Reactor模式。在这个模式里，mainReactor只有一个，负责响应client的连接请求，并建立连接，它使用一个NIO Selector；subReactor可以有一个或者多个，每个subReactor都会在一个独立线程中执行，并且维护一个独立的NIO Selector。</p> \n <p>这样的好处很明显，因为subReactor也会执行一些比较耗时的IO操作，例如消息的读写，使用多个线程去执行，则更加有利于发挥CPU的运算能力，减少IO等待时间。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1125/130828_uKWD_190591.jpeg\" alt=\"Multiple Reactors\" /></p> \n <span id=\"OSC_h3_8\"></span> \n <h3>2、Netty中的Reactor与NIO</h3> \n <p>好了，了解了多线程下的Reactor模式，我们来看看Netty吧（以下部分主要针对NIO，OIO部分更加简单一点，不重复介绍了）。Netty里对应mainReactor的角色叫做“Boss”，而对应subReactor的角色叫做&quot;Worker”。Boss负责分配请求，Worker负责执行，好像也很贴切！以TCP的Server端为例，这两个对应的实现类分别为<code>NioServerBoss</code>和<code>NioWorker</code>（Server和Client的Worker没有区别，因为建立连接之后，双方就是对等的进行传输了）。</p> \n <p>Netty 3.7中Reactor的EventLoop在<code>AbstractNioSelector.run()</code>中，它实现了<code>Runnable</code>接口。这个类是Netty NIO部分的核心。它的逻辑非常复杂，其中还包括一些对JDK Bug的处理（例如<code>rebuildSelector</code>），刚开始读的时候不需要深入那么细节。我精简了大部分代码，保留主干如下：</p> \n <pre class=\"brush: java; auto-links: false;\">abstract class AbstractNioSelector implements NioSelector {\n\n\n    //NIO Selector\n    protected volatile Selector selector;\n\n    //内部任务队列\n    private final Queue&lt;Runnable&gt; taskQueue = new ConcurrentLinkedQueue&lt;Runnable&gt;();\n\n    //selector循环\n    public void run() {\n        for (;;) {\n            try {\n                //处理内部任务队列\n                processTaskQueue();\n                //处理selector事件对应逻辑\n                process(selector);\n            } catch (Throwable t) {\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    // Ignore.\n                }\n            }\n        }\n    }\n\n    private void processTaskQueue() {\n        for (;;) {\n            final Runnable task = taskQueue.poll();\n            if (task == null) {\n                break;\n            }\n            task.run();\n        }\n    }\n\n    protected abstract void process(Selector selector) throws IOException;\n\n}</pre> \n <p>其中process是主要的处理事件的逻辑，例如在<code>AbstractNioWorker</code>中，处理逻辑如下：</p> \n <pre class=\"brush: java; auto-links: false;\">protected void process(Selector selector) throws IOException {\n        Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();\n        if (selectedKeys.isEmpty()) {\n            return;\n        }\n        for (Iterator&lt;SelectionKey&gt; i = selectedKeys.iterator(); i.hasNext();) {\n            SelectionKey k = i.next();\n            i.remove();\n            try {\n                int readyOps = k.readyOps();\n                if ((readyOps &amp; SelectionKey.OP_READ) != 0 || readyOps == 0) {\n                    if (!read(k)) {\n                        // Connection already closed - no need to handle write.\n                        continue;\n                    }\n                }\n                if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) {\n                    writeFromSelectorLoop(k);\n                }\n            } catch (CancelledKeyException e) {\n                close(k);\n            }\n\n            if (cleanUpCancelledKeys()) {\n                break; // break the loop to avoid ConcurrentModificationException\n            }\n        }\n    }</pre> \n <p>这不就是第二部分提到的selector经典用法了么？</p> \n <p>在4.0之后，作者觉得<code>NioSelector</code>这个叫法，以及区分<code>NioBoss</code>和<code>NioWorker</code>的做法稍微繁琐了点，干脆就将这些合并成了<code>NioEventLoop</code>，从此这两个角色就不做区分了。我倒是觉得新版本的会更优雅一点。</p> \n <span id=\"OSC_h3_9\"></span> \n <h3>3、Netty中的多线程</h3> \n <p>下面我们来看Netty的多线程部分。一旦对应的Boss或者Worker启动，就会分配给它们一个线程去一直执行。对应的概念为<code>BossPool</code>和<code>WorkerPool</code>。对于每个<code>NioServerSocketChannel</code>，Boss的Reactor有一个线程，而Worker的线程数由Worker线程池大小决定，但是默认最大不会超过CPU核数*2，当然，这个参数可以通过<code>NioServerSocketChannelFactory</code>构造函数的参数来设置。</p> \n <pre class=\"brush: java; auto-links: false;\">public NioServerSocketChannelFactory(\n            Executor bossExecutor, Executor workerExecutor,\n            int workerCount) {\n        this(bossExecutor, 1, workerExecutor, workerCount);\n    }</pre> \n <p>最后我们比较关心一个问题，我们之前<code>ChannlePipeline</code>中的ChannleHandler是在哪个线程执行的呢？答案是在Worker线程里执行的，并且会阻塞Worker的EventLoop。例如，在<code>NioWorker</code>中，读取消息完毕之后，会触发<code>MessageReceived</code>事件，这会使得Pipeline中的handler都得到执行。</p> \n <pre class=\"brush: java; auto-links: false;\">protected boolean read(SelectionKey k) {\n        ....\n\n        if (readBytes &gt; 0) {\n            // Fire the event.\n            fireMessageReceived(channel, buffer);\n        }\n\n        return true;\n    }</pre> \n <p>可以看到，对于处理事件较长的业务，并不太适合直接放到ChannelHandler中执行。那么怎么处理呢？我们在Handler部分会进行介绍。</p> \n <p>最后附上项目github地址，欢迎交流：<a href=\"https://github.com/code4craft/netty-learning\" rel=\"nofollow\">https://github.com/code4craft/netty-learning</a></p> \n <p>参考资料：</p> \n <ul> \n  <li>Scalable IO in Java <a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" rel=\"nofollow\">http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf</a></li> \n  <li>Netty5.0架构剖析和源码解读 <a href=\"http://vdisk.weibo.com/s/C9LV9iVqH13rW/1391437855\" rel=\"nofollow\">http://vdisk.weibo.com/s/C9LV9iVqH13rW/1391437855</a></li> \n  <li>Reactor pattern <a href=\"http://en.wikipedia.org/wiki/Reactor_pattern\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Reactor_pattern</a></li> \n  <li>Reactor - An Object Behavioral Pattern for Demultiplexing and Dispatching Handles for Synchronous Events <a href=\"http://www.cs.wustl.edu/~schmidt/PDF/reactor-siemens.pdf\" rel=\"nofollow\">http://www.cs.wustl.edu/~schmidt/PDF/reactor-siemens.pdf</a></li> \n  <li>高性能网络编程6–reactor反应堆与定时器管理 <a href=\"http://blog.csdn.net/russell_tao/article/details/17452997\" rel=\"nofollow\">http://blog.csdn.net/russell_tao/article/details/17452997</a></li> \n  <li>IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇）<a href=\"http://blog.csdn.net/historyasamirror/article/details/5778378\" rel=\"nofollow\">http://blog.csdn.net/historyasamirror/article/details/5778378</a></li> \n </ul> \n <p>题图来自：<a href=\"http://www.worldindustrialreporter.com/france-gives-green-light-to-tokamak-fusion-reactor/\" rel=\"nofollow\">http://www.worldindustrialreporter.com/france-gives-green-light-to-tokamak-fusion-reactor/</a></p>\n</div>","description":"2014-02-08 18:46","name":"Netty那点事（四）Netty与Reactor模式","type":"text"}],"name":"Netty","type":"dir"},{"contents":[{"contents":"<h2>HTTP权威指南-连接部分</h2><div class=\"BlogContent\">\n <h1><span style=\"font-size:14px;line-height:1.6em;\">最近买了一本《Http权威指南》，读了之后收获不少。把每章的读书心得都记下来，免得忘记，同时也可以分享一下。</span></h1> \n <div class=\"rich-content\"> \n  <h2>HTTP keep-alive</h2> \n  <p>HTTP keep-alive的源头可以追溯到HTTP 1.0之前，因为HTTP是无状态的，HTTP又基于TCP协议，TCP协议在建立新连接时，存在三次握手时延、TCP慢启动等问题，新建一个连接的延时会较大，于是厂家们就想要复用HTTP连接，于是keep-alive就成了事实标准，最终加入到了HTTP1.0规范中。keep-alive的意思是，在浏览同一站点的页面时，复用这个连接。持久化连接还可以提供管道化请求和响应(就是一下次发几次收几个)的支持。</p> \n  <p>官方文档&nbsp;<a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html\" rel=\"nofollow\">http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html</a></p> \n  <p>在HTTP1.1之后，连接默认都是持久的，除非在connction头里声明close。(待确认，RFC确实是这样写的，但是事实标准需要测试)</p> \n  <h2>盲中继和哑代理</h2> \n  <p>作为一个HTTP代理，盲中继就是不管HTTP报文内容是什么，都进行转发。但是转发Connection头时，如果带有keep-alive属性，那么代理并不会理解keep-alive的意思，在进行完一次事务(request-response)后，代理会将连接关闭。而此时，客户端和服务端都以为持久化连接已经建立了，还在傻傻的等着继续的发送，这个代理就“哑”了。</p> \n  <p>Netscape的解决方法是在头上写入Proxy-Connection，如果不懂的代理转发了它，则不会有影响；如果懂的代理，能够支持keep-alive属性，那么会把Proxy-Connection属性写入Connection中。这一属性目前仍在使用，使用Chrome测试了几个HTTP请求，request头中的字段都是Proxy-Connection: keep-alive，而response头中的字段都是Connection: keep-alive。其实可以想到，服务端返回response的时候，很可能也是返回的Proxy-Connection: keep-alive，而经过了某个代理的转换后，客户端拿到的就是Connection: keep-alive了。</p> \n  <h2>一些影响HTTP时延的机制</h2> \n  <p><strong>延迟确认</strong></p> \n  <p>为了确保数据的正确传输，TCP协议实现了自己的确认机制。做法是每次成功收到请求后，都会返回一个确认分组，一般这个确认分组会和返回报文放在一起。很多TCP协议栈都实现了一个“延迟确认”的功能，就是把多个确认分组攒起来，过100ms~200ms再发送过去。这样对于HTTP请求就会有个问题：HTTP请求是一个双峰值的请求，一旦response返回之后，就会有较长时间没有TCP分组返回，于是延迟确认就会找不到搭载分组。</p> \n  <p><strong>Nagle算法</strong></p> \n  <p>因为TCP头本身至少有40字节的首部，如果在一个TCP单元中只携带很少的内容，那么对带宽无疑就是一种浪费了。Nagle算法是将TCP包数据积攒和合并发送的算法。这个算法对于HTTP协议来说却有问题：很可能一个request内容不够塞满一个TCP包，Nagle算法则会一直等待包填充满再发送。这样会造成时延。解决方法就是参数TCP_NODELAY。</p> \n </div>\n</div>","description":"2012-09-24 11:24","name":"HTTP权威指南-连接部分","type":"text"},{"contents":"<h2>Java程序员学Ruby--从折腾开始</h2><div class=\"BlogContent\">\n <p> </p> \n <p> &nbsp; &nbsp; 这篇文章信息含量不高，基本上理解为吐槽+备忘就对了。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;最近想自己做一点东西，但是实在厌倦了J2EE世界里数不清的xml，也在寻求一种“高效的开发语言”。基本上说到高效和敏捷，大家都在推崇Ruby&nbsp;on&nbsp;Rails，所以抽周末的空来尝个鲜。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;学新语言，我一般喜欢先配置环境，弄几个短的snippet来看看，熟悉语法。于是就需要先配置环境。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;Ruby本身的安装还算简单，下载一个rvm，然后安装就可以了。安装后ruby本身的包和gems都会放在/opt/local/lib/ruby下。但是当我下载了一个Rails的app&nbsp;<a href=\"http://rabelapp.com/\" target=\"_blank\" rel=\"nofollow\">Rabel</a>，尝试部署并启动时，噩梦就开始了。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;gem是Ruby包管理的一个工具，跟Maven类似。但是Java崇尚Compile&nbsp;Once，Run&nbsp;anywhere，所有的依赖管理都管理具体项目。而gem则是管理本地运行环境的，使用gem&nbsp;install&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;gem_name可以将包安装到本地。这样虽然运行具体项目会痛苦一点，却也极大避免了多个项目的依赖冲突问题。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;脚本语言都有个功能：本地扩展(Native&nbsp;Extension)，跟Java里的JNI是一个意思。不过Java世界都崇尚pure&nbsp;Java，基本上依赖管理都是在jar包之间，完全是Maven可以搞定的。而脚本语言一般都秉承了UNIX世界的多模块混合的思想，经常使用本地扩展，例如xml解析，就使用libxml。安装本地库，就不是gem能搞定的事了。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;在mac下，最好安装一个port或者brew，不然得自己去make&nbsp;install之类的，很麻烦。port更加强大一些，但是会傻乎乎的下载重复的依赖。例如我要下载一个mysql-ruby的库，它会先下载mysql、再下载ruby，最后再下载这个库，而其实我只需要一个ruby扩展而已。当然port下载一些C语言的库是很有用的，如sqlite3、libxml之类，省去了编译和查找依赖的过程，这个过程对于Java程序员来说真是太痛苦了。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;在尝试使用rails&nbsp;server启动Rabel时，提示找不到nokogiri。使用gem&nbsp;install&nbsp;nokogiri安装之，发现缺少libxml依赖。后来使用port安装libxml之后，依然找不到。最后升级ruby版本之后，问题解决了。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;gems安装比较好的地方是，即使没有安装成功，它也会将临时文件保存在/opt/local/lib/ruby/gems/1.8/gems/gem_name目录下，供分析用。 </p> \n <p> &nbsp;&nbsp;&nbsp;&nbsp;搞了大半天，因为build的时候又相当长，实在让人难过。下周继续。 </p> \n <p></p> \n <p> <br /> </p>\n</div>","description":"2012-11-11 14:47","name":"Java程序员学Ruby--从折腾开始","type":"text"},{"contents":"<h2>python学习笔记</h2><div class=\"BlogContent\">\n <p>因为最近发现黑客都爱用python嘛，跟风学习一下。</p> \n <h3>UTF8支持</h3> \n <pre class=\"brush: java; auto-links: false;\"># -*- coding: utf-8 -*-\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')</pre> \n <h3>空值：</h3> \n <p>None</p> \n <h3>字符串：</h3> \n <p>python分为str和unicode、路径三种类型</p> \n <p>str: “”</p> \n <p>unicode: u””</p> \n <p>路径: r””</p> \n <p>去掉首位空白： str.strip()</p> \n <p>转化为str str(object)</p> \n <p>python里使用print时，不会进行隐式的类型转换，但是python可以用</p> \n <pre class=\"brush: java; auto-links: false;\">print &quot;&quot;,1,&quot;&quot;</pre> \n <p>形式，默认用空格隔开</p> \n <h3>异常堆栈打印</h3> \n <p>import traceback</p> \n <h3>list：</h3> \n <ul> \n  <li>新建 []</li> \n  <li>增加 append</li> \n  <li>弹出(顶部) pop</li> \n  <li>长度 len(list)</li> \n </ul> \n <h3>dict:</h3> \n <ul> \n  <li>遍历 for key in dict</li> \n  <li>包含 if key in dict</li> \n  <li>元素 dict[key]</li> \n  <li>不推荐get</li> \n  <li>删除 dict.pop</li> \n </ul> \n <h3>连接数据库：</h3> \n <p>MySQLdb和pymysql两种选择，据说pymysql更快更安全，没有内存泄漏。</p> \n <pre class=\"brush: java; auto-links: false;\">#import pymysql as MySQLdb\nMySQLdb.install_as_MySQLdb() #使用pymysql需要加上这一句\nconn = MySQLdb.connect(host='', user='',passwd='',db='')\ncursor=conn.cursor()\ncursor.execute('select * xxxx')\n#读取\nfor r in cursor:</pre> \n <h3>文件操作：</h3> \n <ul> \n  <li><p>读文件</p> <pre class=\"brush: java; auto-links: false;\">fileIn=file('filename','r')\nfor line in fileIn:</pre> </li> \n  <li><p>写文件</p> <pre class=\"brush: java; auto-links: false;\">fileOut=file('filename','r')\nfileOut.writelines(lines)</pre> </li> \n  <li><p>删除文件</p> <pre class=\"brush: java; auto-links: false;\">import os\nos.remove('filename')</pre> </li> \n </ul> \n <h3>正则表达式：</h3> \n <pre class=\"brush: java; auto-links: false;\">import re</pre> \n <ul> \n  <li>re.comile(r'')</li> \n  <li>匹配 matcher=re.search()</li> \n  <li>捕获组 matcher.group()</li> \n  <li>正则表达式语法基本同Java</li> \n </ul> \n <h3>图像处理：</h3> \n <p>可以使用pil库，easy_install即可</p> \n <pre class=\"brush: java; auto-links: false;\">import Image</pre> \n <ul> \n  <li>读取 Image.open('filename')</li> \n  <li>裁剪 image=image.crop(box) box为(左，上，右，下)的四元组，如(0,0,800,600)表示800*600的图</li> \n  <li>缩略图 image.thumbnail</li> \n </ul>\n</div>","description":"2013-01-24 18:25","name":"python学习笔记","type":"text"},{"contents":"<h2>玩转github之--神啊满足我的虚荣心吧</h2><div class=\"BlogContent\">\n <span id=\"OSC_h3_1\"></span> \n <h3>github版简历</h3> \n <p><a href=\"http://resume.github.io/\" rel=\"nofollow\">http://resume.github.io/</a>上有这个东东，但是样式太难看了。看到一个挺不错的模板<a href=\"https://github.com/hit9/GhResume\" rel=\"nofollow\">https://github.com/hit9/GhResume</a>，就给用上了。我的简历： <br /><a href=\"http://code4craft.github.io/GhResume/\" rel=\"nofollow\">http://code4craft.github.io/GhResume/</a></p> \n <span id=\"OSC_h3_2\"></span> \n <h3>关注star</h3> \n <p>最近做的项目在github每天会有几个star，出于虚荣心嘛，经常忍不住就会去看看，有人star了没？有人fork了没？</p> \n <p>每天看太麻烦了，干脆做成一个chrome插件，带桌面通知，有新star提醒，岂不开心？</p> \n <p>于是有了<a href=\"https://github.com/code4craft/exciting\" rel=\"nofollow\"><strong>exciting</strong></a>！ 哥也会做chrome插件了！液！</p>\n</div>","description":"2013-07-03 08:07","name":"玩转github之--神啊满足我的虚荣心吧","type":"text"},{"contents":"<h2>Qcon见闻整理</h2><div class=\"BlogContent\">\n <span id=\"OSC_h1_1\"></span> \n <h1>第一天</h1> \n <p>之前在并发编程网<a href=\"http://ifeve.com\" rel=\"nofollow\">http://ifeve.com</a>发过两篇关于netty的文章，就混进了编辑群，正好群主有两站Qcon上海的票，我又刚好在上海，就拿了一张票，请了天假，奔赴现场了。</p> \n <p>会议人依然很多，各个赞助商都在门口签到发送礼品，领了两个娃娃，正好给女儿。不得不说七牛在社区方面的工作还是很到位的，娃娃做的很用心，还送了一件挺不错的T恤。</p> \n <p><img src=\"http://static.oschina.net/uploads/space/2013/1101/211210_rzYo_190591.jpeg\" alt=\"toy\" /></p> \n <p>上午的keynote全部是英文演讲，虽然来的都是twitter、github的大牛，但是演讲内容太泛，除了瞻仰了风采之外，收获不算很大。twitter讲到了他们的RPC框架finagle，倒是可以研究一下。twitter的开源项目还是很受欢迎的，既有bootstrap，又有storm，这个finagle应该也不错。</p> \n <p>下午奔了几个会场。阿里外贸讲前端优化、SEO以及CDN中遇到的坑，感觉挺不错，都是宝贵的经验。豆瓣讲到自己的工程师文化，讲到工程师自发的维护code平台，自下而上的工具开发论相当不错。有个观点很新颖：团队工具最好由开发自己维护，不要用专人去负责，否则负责人为了刷存在感，总会开发些不实用的功能…</p> \n <p>code平台晚些会开源。</p> \n <p>听了几个报告，感想：其实所有技术人都有一个开源梦，极少数真是想藏着不给人看，多数是因为没有精力将代码提高到可开源水平(依赖内部工具、耦合业务代码、文档测试不全、代码质量不高)。开源对于公司来说，确实成本不小，在国内除了积累声望外也没有什么回报(极少有人反馈代码)。</p> \n <span id=\"OSC_h1_2\"></span> \n <h1>第二天</h1> \n <p>今天上午处理一些公司的事情，没有去成，错过了安全方面的讲座，挺可惜的。</p> \n <span id=\"OSC_h2_3\"></span> \n <h2>Apache Traffic Server</h2> \n <p>下午第一个听了阿里CDN团队的永豪对于Apache Traffic Server的讲解，偏运维方面，好多东西不懂，不过倒是知道了ATS这个东西。ATS采用多线程+事件机制，默认支持集群，比起nginx倒是方便了很多。阿里CDN团队还出过Tsar。他们在尝试将配置用lua实现(remap)，估计日后会合并到主干。可能在很多人眼里运维就是配一大堆配置文件的人，看日后会不会有改变。阿里在开源方面真算是走上了正轨，积累了业界声望，至少在我看来对于招收人才是非常有利的。</p> \n <span id=\"OSC_h2_4\"></span> \n <h2>深度学习</h2> \n <p>第二个听了百度IDL的首席科学家张潼带来的深度学习的介绍。其中细数了机器学习在企业的应用，干货挺多，至少对于我这个外行更是如此。大数据在企业分为三个方向：</p> \n <ul> \n  <li><p>Infrastructure</p> <p>数据研究的设施，像hadoop、storm、spark均属此类。也包括把数据拿到CPU/GPU上计算。</p> </li> \n  <li><p>Data analysis</p> <p>数据分析，建模、算法，参数调优等。</p> </li> \n  <li><p>System intergtation</p> <p>系统集成，最终将机器学习的结果整合到产品中，产生商业价值。</p> </li> \n </ul> \n <p>百度的机器学习主要用于CTR预估和语音以及图像的处理。百度的广告数据已经达到了千亿规模，用的是Logistic Regression。而图像和语音用的是深度学习，深度学习的精髓是最接近人的大脑，同时它可以从最原始的特征选择出最上层的特征，学习越多越抽象，而且这个最上层的特征通常是有意义的。这样同于特征提取，可能在一个星期内就完成人工十年都做不到的特征选择工作。百度这方面做的挺不错的，据说图片匹配已经超过google了。</p> \n <p>还有些分布式方面的内容，包括CPU与GPU的区别和任务分配模式，需要时倒是可以了解一下。</p> \n <span id=\"OSC_h2_5\"></span> \n <h2>Java 8</h2> \n <p>作为一个Java码农，不得不说Java8，于是去听了Oracle专家带来的J2SE的55个特性的讲座。当时顺便开了IDEA，边听边试，岂不快哉！</p> \n <p>说到Java8先说Lambda，关于Lambda我写过一篇博客，我觉得报告中有个说法很对：Allow you to treat code as data. 在VM层级是使用invokedynamic机制实现的。<a href=\"http://cr.openjdk.java.net/~briangoetz/lambda/lambda-translation.html\" rel=\"nofollow\">http://cr.openjdk.java.net/~briangoetz/lambda/lambda-translation.html</a></p> \n <p>另外并发方面支持Fork-Join了，集合类都增加了并发支持，有人说Java8是抄scala的，感觉倒有那么点意思…</p> \n <span id=\"OSC_h2_6\"></span> \n <h2>Moco</h2> \n <p>Moco这个框架之前就关注过，因为自己也计划写一个类似的东西。作者郑烨@dreamhead是个35岁的大龄码农，倒是挺有亲切感。Moco之前有说过，就是用Mockito的语法和JSON配置来实现一个webserver。后来拉了代码看了一下，作者是个与时俱进的Java Coder，用了guava/netty4.0/gradle等新玩意。</p> \n <p>作者写了10年博客，有个《你应该更新的Java知识》系列，可以去搜一下。</p> \n <p>有趣的时晚上报告的时候，与作者刚好坐到了旁边，但是反而不知道说什么了，码农嘛，有点不善言辞。</p> \n <span id=\"OSC_h2_7\"></span> \n <h2>鬼脚七夜话</h2> \n <p>鬼脚七夜话是晚上的座谈活动，实际上比起白天的报告，这个收获更大一些。最大的收获是学到了角色时间管理法。还有就是也了解了几个微信公众号，有点意思。鬼脚七说自己的经验是每天坚持写自媒体，写一年半年试试。想起当初自己写webmagic时29天的连续strike，还是挺有感触的。</p> \n <p>还有一个就是大牛一部分是技术，一部分是吹出来的，感谢蔡学镛独到的见解。</p> \n <p>晚上跟朋友谈起Java8，引出了函数式编程的话题，然后就被推荐学学Haskell。函数式编程有不可变对象和函数组成，有点意思，研究一下。</p> \n <span id=\"OSC_h1_8\"></span> \n <h1>第三天</h1> \n <p>第三天宝宝生病，去了趟医院才来。第一场听了鸟哥的Yax框架。我是鸟哥的粉丝，报告非常技术，符合技术人员的特质。</p> \n <p>下午的讲座就比较泛泛，不是很喜欢。虽然有鬼脚七和蔡学镛的讲座，但是比起前一天的鬼脚七夜话，各方面都差远了，感觉就是来宣传的。google glass的现场demo倒是有点意思，google glass2出了，支持近视眼镜，以后便宜了可以入一个。</p> \n <p>就这么多了，结束的时候稍微有点失落，不过补充了码农的能量，可以继续下去了。</p>\n</div>","description":"2013-11-01 21:12","name":"Qcon见闻整理","type":"text"},{"contents":"<h2>2013年总结</h2><div class=\"BlogContent\">\n <p>2013年是我跟老婆结婚第二年，也是工作第三年，女儿出生、买了房、工作顺利，一切都走上了正轨。</p> \n <span id=\"OSC_h2_1\"></span> \n <h2>生活</h2> \n <p>女儿出生是我今年第一大事。老婆一直想要我陪护，但是因为病房不足，所以还是一个人进了产房。7月21号下午4点，老婆被推进产房，当时她脸上满是焦急，和痛苦。期间我忐忑不安，但是老婆非常坚强的完成了顺产。当宝宝被推出来的时候，我的眼泪都忍不住了，只有感觉到浓浓的血缘之情。老婆你真棒！</p> \n <p>宝宝出生之后，工作的动力更大了，可能自己也成熟了不少吧。</p> \n <p>生活上的事情我做的也不多，还好有父母以及岳母的帮忙。宝宝到现在很健康，多亏了他们，当然，还有老婆。</p> \n <p>在父母的资助下，10月份的时候开始了买房之旅，折腾一个月终于敲定，每个月9k的房贷，也是个不小的压力。</p> \n <p>今年的生活上，我做的能打个70分，为我老婆打个90分。</p> \n <span id=\"OSC_h2_2\"></span> \n <h2>工作</h2> \n <p>今年工作算是持续进步的一年，也有了一些成果。</p> \n <p>今年读的书不多，但是读了好几个项目的源码：jafka、httpclient、jsoup、netty、struts、spring，最重要的是积累了一套自己阅读源码的方式。代码写的更漂亮了，也有一些深层思考了。</p> \n <p>写了84篇博客。几个源码解读系列博客，都得到不少朋友的支持，能给人创造价值，感觉是很不错的。其中自我感觉最好的是Netty系列，还没写完，可以继续完善。</p> \n <p>5月份开源的webmagic在oschina上收获了不少人气，在完善过程中也认识了不少朋友。现在都有一点知名了呢。这个项目明年会继续完善，并做一些大动作。</p> \n <p>为开源项目HttpClient提交patch成功，虽然难度不大，但是毕竟是个好的开始。</p> \n <p>工作上得到了领导的肯定，邮件项目和一些日常工作都有了比较好的成绩，应该能得到进一步发展。</p> \n <p>长期的目标是能自己出本书，但是自己积累还远远不够，需要继续坚持。</p> \n <p>今年的工作和学习能打个90分。</p>\n</div>","description":"2014-01-18 21:36","name":"2013年总结","type":"text"}],"name":"日常记录","type":"dir"}],"name":"blog","type":"dir"}